{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1id2ytqiv2ra",
        "outputId": "7606ddb2-60c4-4f43-e47c-bad727dd6d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/ATIML/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjdqgp3Z4ED0",
        "outputId": "d75bf711-6956-4d0f-ef6c-da5ff85d1f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ATIML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import time\n",
        "\n",
        "import os\n",
        "import string\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6kaeu_PwnNI",
        "outputId": "725b437b-c94f-4d77-8b1f-d2912474d2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "rootdir = '/content/drive/MyDrive/ATML/Datasets/TREC_4_5/'\n",
        "iterable_lines = []\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "      #print(\"Parsing through:\", os.path.join(subdir, file))\n",
        "      f = open((str(subdir)+\"/\"+str(file)), 'r', encoding=\"ISO-8859-1\")\n",
        "      lines = f.read()\n",
        "      f.close()\n",
        "      iterable_lines += [lines]"
      ],
      "metadata": {
        "id": "uKljm-iFwDms",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "processed_articles = []\n",
        "for i in iterable_lines:\n",
        "  processed_article = i.lower()\n",
        "  processed_article = re.sub(r\"\\[.*?\\]\", '', processed_article)\n",
        "  processed_article = re.sub(r\"https?://\\S+|www\\.\\S+\", '', processed_article)\n",
        "  processed_article = re.sub(r\"<.*?>+\", '', processed_article)\n",
        "  processed_article = re.sub(r\"[%s]\" % re.escape(string.punctuation), '', processed_article)\n",
        "  processed_article = re.sub(r\"\\n\", ' ', processed_article)\n",
        "  processed_article = re.sub(r\"\\w*\\d\\w*\", '', processed_article)\n",
        "  processed_article = re.sub(r\" +\", ' ', processed_article)\n",
        "  processed_articles += [processed_article]"
      ],
      "metadata": {
        "id": "hM52wpboh9SB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "tokenized_processed_articles = []\n",
        "\n",
        "for i in range(len(processed_articles)):\n",
        "  tokenized_processed_articles += [nltk.word_tokenize(processed_articles[i])]"
      ],
      "metadata": {
        "id": "7hCgG9MCiAD8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "tokenized_lemm_articles = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ATIML/lemm_doc.pkl\")"
      ],
      "metadata": {
        "id": "2Eyx4c0O5qhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenized_lemm_articles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoyfFlRb6uQ2",
        "outputId": "f7d8113a-e49f-44c9-ebc8-a8600124866c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_lemm_articles)]"
      ],
      "metadata": {
        "id": "MUjIcQvhiD35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(tagged_data, window=2, vector_size=256, min_count=3, workers=4, epochs = 100)\n",
        "# vector_size=100"
      ],
      "metadata": {
        "id": "7NnXO5hvlwOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('doc2vecmodel.pkl','wb') as f:\n",
        "  pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "zUJwa81nS8Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs = model.docvecs.most_similar(1121, topn=3)"
      ],
      "metadata": {
        "id": "RgCck6oCVWBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similar_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvEPCpmEVaZj",
        "outputId": "47b73282-cea3-40a6-ee02-38f86845ad6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1099, 0.6787018179893494), (1039, 0.6692175269126892), (568, 0.6618386507034302)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in similar_docs:\n",
        "  print(k[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT3pevn4WX8o",
        "outputId": "6d6326d1-7d2e-4521-867b-f940f381b6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1099\n",
            "1039\n",
            "568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(similar_docs)):\n",
        "    print(\n",
        "            \"Document:\"+str(similar_docs[i][0]) + \" Similarity Score:\"+str(\n",
        "                similar_docs[i][1]\n",
        "            ))\n",
        "    print(\"************************************************\")\n",
        "    print(\"************************************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbdrjiACVjFw",
        "outputId": "8065f54d-15a8-415b-b0f4-44760e533f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document:568 Similarity Score:0.6903170943260193\n",
            "************************************************\n",
            "************************************************\n",
            "Document:1039 Similarity Score:0.6863768100738525\n",
            "************************************************\n",
            "************************************************\n",
            "Document:1238 Similarity Score:0.6849675178527832\n",
            "************************************************\n",
            "************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in similar_docs:\n",
        "        print(\"Inside k\")\n",
        "        doc_number = k[0]\n",
        "        print(\"doc_number {}\".format(doc_number))\n",
        "        print(\"Key phrases for document \"+str(k[0])+\":\")\n",
        "\n",
        "        print(\"************************************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEsT9E5_VvGJ",
        "outputId": "c7d3cab4-5956-489a-db96-d4a4420df3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inside k\n",
            "doc_number 1099\n",
            "Key phrases for document 1099:\n",
            "************************************************\n",
            "Inside k\n",
            "doc_number 1039\n",
            "Key phrases for document 1039:\n",
            "************************************************\n",
            "Inside k\n",
            "doc_number 568\n",
            "Key phrases for document 568:\n",
            "************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"my_doc2vec_model.pkl\", 'rb') as f:  # the saved model that has been trained on version 3.8.3 (I can't provide - NDA)\n",
        "    model = pickle.dump(model)\n",
        "model.docvecs.most_similar(id)  # or model.dv.most_similar(id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1QxnAwLuNyuV",
        "outputId": "4a58d368-faa5-4619-dade-6999c3939206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b1cb239d2165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_doc2vec_model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# the saved model that has been trained on version 3.8.3 (I can't provide - NDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or model.dv.most_similar(id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_doc2vec_model.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import get_tmpfile\n",
        "fname = get_tmpfile(\"/content/drive/MyDrive/Colab Notebooks/ATIML/my_doc2vec_model\")\n",
        "model.save(fname)\n"
      ],
      "metadata": {
        "id": "3pQWlLX4DIjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec.load(fname)"
      ],
      "metadata": {
        "id": "NcqMjhckDWCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYwMNGDeH4Y0",
        "outputId": "041d6eb7-aed1-4a6e-ad2a-6befb598f220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2322"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.vector_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYdUkzWuWR65",
        "outputId": "bb335add-7c45-4cdc-b575-08160b8fa7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_init_constraints(tokenized_lemm_articles):\n",
        "  ml_init_constraints = []\n",
        "  cl_init_constraints = []\n",
        "  for doc_id in range(len(tokenized_lemm_articles)):\n",
        "    # Compare and print the most-similar, disimilar document\n",
        "    sim_doc = model.docvecs.most_similar(doc_id, topn=len(model.docvecs))[0]\n",
        "    if sim_doc[1] >= 0.8:\n",
        "      ml_init_constraints += [[doc_id, sim_doc]]\n",
        "    dissim_doc = model.docvecs.most_similar(doc_id, topn=len(model.docvecs))[-1]\n",
        "    if dissim_doc[1] <= 0.1:\n",
        "      cl_init_constraints += [[doc_id, dissim_doc]]\n",
        "  return ml_init_constraints, cl_init_constraints\n",
        "\n"
      ],
      "metadata": {
        "id": "XiOYyF0eHwPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the similiar and disimilar docs by sorting based on similarity values\n",
        "def sort_on_similarity(initial_constraints):\n",
        "  return sorted(initial_constraints, key=lambda tup: tup[1][1], reverse=True)\n",
        "\n",
        "#Extracting instances/docs after sorting based on similarity\n",
        "def extract_docs(ml_sim_sorted):\n",
        "  li=[]\n",
        "  for item in ml_sim_sorted:\n",
        "    li.append(((item[0], item[1][0])))\n",
        "  return li\n",
        "\n",
        "#sorting each tuple inside the list to follow ascending order\n",
        "#this is done to findout if there are duplicate tuples\n",
        "def inner_tuple_sort(extracted_docs):\n",
        "  sort_tuples = []\n",
        "  for element in extracted_docs:\n",
        "    sort_tuples.append(tuple(sorted(element)))\n",
        "  return sort_tuples\n",
        "\n",
        "#getting unique tuples preserving the order of tuples\n",
        "def unique(sequence):\n",
        "  seen = set()\n",
        "  return [x for x in sequence if not (tuple(x) in seen or seen.add(tuple(x)))]\n"
      ],
      "metadata": {
        "id": "fjMuw4oF4uyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize N\n",
        "N = 25\n",
        "\n",
        "ml_init_constraints , cl_init_constraints = get_init_constraints(tokenized_lemm_articles)\n",
        "\n",
        "ml_sim_sorted = sort_on_similarity(ml_init_constraints)\n",
        "extracted_ml_docs = extract_docs(ml_sim_sorted)\n",
        "sorted_ml_tuples = inner_tuple_sort(extracted_ml_docs)\n",
        "\n",
        "final_ml_constraints = unique(sorted_ml_tuples)[:N]\n",
        "\n",
        "cl_sim_sorted = sort_on_similarity(cl_init_constraints)\n",
        "extracted_cl_docs = extract_docs(cl_sim_sorted)\n",
        "sorted_cl_tuples = inner_tuple_sort(extracted_cl_docs)\n",
        "\n",
        "final_cl_constraints = unique(sorted_cl_tuples)[:N]\n",
        "\n",
        "print(final_ml_constraints)\n",
        "print(final_cl_constraints)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC06JECCEqEv",
        "outputId": "79282a7b-fb97-4dc3-bb30-cde9df4b568d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(494, 495), (495, 496), (494, 498), (33, 264), (1199, 1232), (194, 195), (928, 979), (1382, 1508), (1296, 1416), (1515, 1526), (986, 989), (34, 39), (247, 334), (264, 270), (511, 516), (183, 343), (1373, 1452), (188, 351), (1232, 1339), (669, 733), (280, 285), (34, 38), (326, 420), (1258, 1353), (173, 326)]\n",
            "[(678, 1520), (495, 995), (157, 1139), (681, 939), (209, 1311), (559, 1441), (791, 1464), (75, 978), (498, 995), (76, 1050), (65, 1480), (898, 2236), (4, 494), (602, 680), (169, 402), (687, 2083), (60, 734), (496, 995), (37, 1106), (708, 1480), (960, 1774), (1349, 2108), (314, 564), (145, 999), (299, 1125)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_ml_constraints)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIALpBu7mKFc",
        "outputId": "c9a8650c-11e5-46e1-b13d-3adb5f162abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(495, 498), (494, 495), (496, 498), (33, 264), (1199, 1232), (183, 343), (928, 979), (1232, 1339), (247, 334), (1017, 1025), (34, 39), (34, 38), (1373, 1452), (194, 195), (173, 326), (1004, 1007), (1343, 1443), (1296, 1308), (56, 58), (1339, 1381), (188, 351), (114, 189), (189, 349), (669, 733), (264, 270), (497, 498), (194, 359), (1320, 1351), (1346, 1381), (33, 113), (193, 194), (1353, 1381), (280, 285), (1787, 1857), (120, 277), (1296, 1416), (107, 183), (1258, 1356), (1515, 1518), (1346, 1386), (1355, 1515), (986, 989), (997, 1000), (2116, 2183), (1308, 1468), (35, 41), (503, 505), (1787, 1869), (1343, 1570), (274, 275)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('final_ml_constraints.pkl','wb') as f:\n",
        "  pickle.dump(final_ml_constraints, f)\n",
        "with open('final_cl_constraints.pkl','wb') as f:\n",
        "  pickle.dump(final_cl_constraints, f)"
      ],
      "metadata": {
        "id": "U0RJYr5ebG9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_ml_constraints = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ATIML/final_ml_constraints.pkl\")\n",
        "final_cl_constraints = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ATIML/final_ml_constraints.pkl\")"
      ],
      "metadata": {
        "id": "mv8JyInKbxD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec uses cosine sim between docs.Crosschecking here\n",
        "cosine_similarity(model.docvecs[0].reshape(1, -1), model.docvecs[2007].reshape(1, -1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itZVFQyQD32Z",
        "outputId": "56b4f195-6965-4fc5-b3c3-d920db02b8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59106445]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}