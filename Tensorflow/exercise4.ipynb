{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exercise4.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CHsnx2_XmX5v"},"source":["**Group Details:**\n","\n","\n","\n","1.   Janusz Feigel\n","2.   Bhavana Malla\n","3.   Brinda Rao  \n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RLJsckArBvKx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e45213cd-915c-46df-e98a-e0310d13f4e5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"HQrdB2RWtO8G","outputId":"640c8e71-ac21-406a-b379-90119b8cf6f1"},"source":["import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/Introduction to Deep Learning')\n","os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/Introduction to Deep Learning'"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"rnxN2_7UtUGY"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from datasets import MNISTDataset\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential,Model\n","from tensorflow.keras import layers\n","from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Input,Dropout,MaxPool2D, AvgPool2D, GlobalAveragePooling2D,concatenate, BatchNormalization,Add, ReLU,GlobalAvgPool2D\n","from keras import backend as K\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import SGD\n","import time\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TlNJflUm6lg"},"source":["logdir = os.path.join(\"logs\", \"linear\" + str(datetime.now()))\n","train_writer = tf.summary.create_file_writer(os.path.join(logdir, \"train\"))\n","test_writer = tf.summary.create_file_writer(os.path.join(logdir, \"test\"))\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","img_height = x_train.shape[1]\n","img_width = x_train.shape[2]\n","channels = x_train.shape[3]\n","num_classes = max(y_train) + 1\n","\n","epochs = 10\n","batch_size = 256\n","train_size = x_train.shape[0]\n","train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(train_size).repeat(epochs).batch(batch_size)         \n","\n","model = tf.keras.Sequential(\n","    [layers.Rescaling(1./255, input_shape=(img_height, img_width, channels)),\n","     layers.Conv2D(16, 5, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(32, 5, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(64, 3, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Flatten(),\n","     layers.Dense(128, activation='relu'),\n","     layers.Dense(num_classes)     \n","    ]\n",")\n","\n","model_large = tf.keras.Sequential(\n","    [layers.Rescaling(1./255, input_shape=(img_height, img_width, channels)),\n","     layers.Conv2D(16, 5, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(32, 5, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(64, 3, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(64, 3, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(64, 3, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Conv2D(64, 3, padding='same', activation='relu'),\n","     layers.MaxPooling2D(padding='same'),\n","     layers.Flatten(),\n","     layers.Dense(512, activation='relu'),\n","     layers.Dense(256, activation='relu'),\n","     layers.Dense(128, activation='relu'),\n","     layers.Dense(num_classes)     \n","    ]\n",")\n","\n","optimizer = keras.optimizers.Adam(learning_rate=0.001)\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","accuracy = keras.metrics.SparseCategoricalAccuracy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g9legw1HnIHC"},"source":["## **with tf.function and small model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFbdFpTum_It","outputId":"e515a9c0-a495-4dd4-a715-f046b8267d4f"},"source":["#with tf.function and small model\n","@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","    accuracy.update_state(y, logits)\n","    return loss_value\n","\n","i = 0\n","epoch = 1\n","times_tf_function = []\n","for step, (img_batch, lbl_batch) in enumerate(train_data):\n","    i += batch_size\n","    t1 = time.time()\n","    loss_value = train_step(img_batch, lbl_batch)\n","    t2 = time.time()\n","    times_tf_function.append(t2-t1)\n","\n","    \n","    if i / train_size > 1:\n","        train_acc = accuracy.result().numpy()\n","        accuracy.update_state(y_test, model(x_test, training=False))\n","        test_acc = accuracy.result().numpy()\n","        print(\"Epoch {} Train Accuracy: {} Test Accuracy: {} Train Loss: {}\".format(epoch, train_acc, test_acc, float(loss_value)))\n","\n","        with train_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", train_acc, step=epoch)\n","            tf.summary.scalar(\"loss\", float(loss_value), step=epoch)\n","\n","        with test_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", test_acc, step=epoch)\n","        i -= train_size\n","        epoch += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Train Accuracy: 0.37517938017845154 Test Accuracy: 0.39067068696022034 Train Loss: 1.5447204113006592\n","Epoch 2 Train Accuracy: 0.4451387822628021 Test Accuracy: 0.4541366994380951 Train Loss: 1.266302227973938\n","Epoch 3 Train Accuracy: 0.4868541657924652 Test Accuracy: 0.49237844347953796 Train Loss: 1.1267685890197754\n","Epoch 4 Train Accuracy: 0.5164341330528259 Test Accuracy: 0.5207375884056091 Train Loss: 1.0072190761566162\n","Epoch 5 Train Accuracy: 0.5395123362541199 Test Accuracy: 0.5425074696540833 Train Loss: 1.0147024393081665\n","Epoch 6 Train Accuracy: 0.5581461191177368 Test Accuracy: 0.5605168342590332 Train Loss: 1.0540354251861572\n","Epoch 7 Train Accuracy: 0.5740770697593689 Test Accuracy: 0.5757648348808289 Train Loss: 0.9022608995437622\n","Epoch 8 Train Accuracy: 0.5876740217208862 Test Accuracy: 0.5894011855125427 Train Loss: 0.7587568759918213\n","Epoch 9 Train Accuracy: 0.6002626419067383 Test Accuracy: 0.6017261147499084 Train Loss: 0.7776539921760559\n","Epoch 10 Train Accuracy: 0.6119762659072876 Test Accuracy: 0.6126750111579895 Train Loss: 0.9606587886810303\n"]}]},{"cell_type":"markdown","metadata":{"id":"2-lfb-gPnXyf"},"source":["## **without tf.function and small model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG_qm1lBnRBJ","outputId":"c06b3367-a738-4ce9-d787-73504030a327"},"source":["def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","    accuracy.update_state(y, logits)\n","    return loss_value\n","\n","times_without_tf_function = []\n","i = 0\n","epoch = 1\n","for step, (img_batch, lbl_batch) in enumerate(train_data):\n","    i += batch_size\n","    t1 = time.time()\n","    loss_value = train_step(img_batch, lbl_batch)\n","    t2 = time.time()\n","    times_without_tf_function.append(t2-t1)\n","\n","    \n","    if i / train_size > 1:\n","        train_acc = accuracy.result().numpy()\n","        accuracy.update_state(y_test, model(x_test, training=False))\n","        test_acc = accuracy.result().numpy()\n","        print(\"Epoch {} Train Accuracy: {} Test Accuracy: {} Train Loss: {}\".format(epoch, train_acc, test_acc, float(loss_value)))\n","\n","        with train_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", train_acc, step=epoch)\n","            tf.summary.scalar(\"loss\", float(loss_value), step=epoch)\n","            \n","        with test_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", test_acc, step=epoch)\n","        i -= train_size\n","        epoch += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Train Accuracy: 0.6198337078094482 Test Accuracy: 0.620635986328125 Train Loss: 0.6965063214302063\n","Epoch 2 Train Accuracy: 0.6294909715652466 Test Accuracy: 0.6303298473358154 Train Loss: 0.6904239058494568\n","Epoch 3 Train Accuracy: 0.6386036276817322 Test Accuracy: 0.6392061114311218 Train Loss: 0.6249908208847046\n","Epoch 4 Train Accuracy: 0.6469732522964478 Test Accuracy: 0.6475889086723328 Train Loss: 0.6162972450256348\n","Epoch 5 Train Accuracy: 0.6548692584037781 Test Accuracy: 0.6552839875221252 Train Loss: 0.6784425377845764\n","Epoch 6 Train Accuracy: 0.6620082259178162 Test Accuracy: 0.6623935699462891 Train Loss: 0.6900976300239563\n","Epoch 7 Train Accuracy: 0.6690909266471863 Test Accuracy: 0.6693556904792786 Train Loss: 0.6182703971862793\n","Epoch 8 Train Accuracy: 0.6756565570831299 Test Accuracy: 0.6758291721343994 Train Loss: 0.6098261475563049\n","Epoch 9 Train Accuracy: 0.6818665862083435 Test Accuracy: 0.6820537447929382 Train Loss: 0.6085209250450134\n","Epoch 10 Train Accuracy: 0.6879571676254272 Test Accuracy: 0.6880591511726379 Train Loss: 0.3603436350822449\n"]}]},{"cell_type":"markdown","metadata":{"id":"qAVsnqOBnab8"},"source":["## **with tf.function and large model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEOvdk_Snd-i","outputId":"7b8b84f1-3162-426e-a202-c164e416efa9"},"source":["@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model_large(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model_large.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model_large.trainable_weights))\n","    accuracy.update_state(y, logits)\n","    return loss_value\n","\n","i = 0\n","epoch = 1\n","times_tf_function_large = []\n","for step, (img_batch, lbl_batch) in enumerate(train_data):\n","    i += batch_size\n","    t1 = time.time()\n","    loss_value = train_step(img_batch, lbl_batch)\n","    t2 = time.time()\n","    times_tf_function_large.append(t2-t1)\n","\n","    \n","    if i / train_size > 1:\n","        train_acc = accuracy.result().numpy()\n","        accuracy.update_state(y_test, model_large(x_test, training=False))\n","        test_acc = accuracy.result().numpy()\n","        print(\"Epoch {} Train Accuracy: {} Test Accuracy: {} Train Loss: {}\".format(epoch, train_acc, test_acc, float(loss_value)))\n","\n","        with train_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", train_acc, step=epoch)\n","            tf.summary.scalar(\"loss\", float(loss_value), step=epoch)\n","\n","        with test_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", test_acc, step=epoch)\n","        i -= train_size\n","        epoch += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Train Accuracy: 0.578320324420929 Test Accuracy: 0.5731789469718933 Train Loss: 1.8740954399108887\n","Epoch 2 Train Accuracy: 0.554577112197876 Test Accuracy: 0.5516458749771118 Train Loss: 1.646367073059082\n","Epoch 3 Train Accuracy: 0.54250168800354 Test Accuracy: 0.5412863492965698 Train Loss: 1.3897863626480103\n","Epoch 4 Train Accuracy: 0.5372925996780396 Test Accuracy: 0.5367177724838257 Train Loss: 1.3687468767166138\n","Epoch 5 Train Accuracy: 0.535271942615509 Test Accuracy: 0.5350567698478699 Train Loss: 1.3128693103790283\n","Epoch 6 Train Accuracy: 0.5350314378738403 Test Accuracy: 0.5350092649459839 Train Loss: 1.1583517789840698\n","Epoch 7 Train Accuracy: 0.5359737873077393 Test Accuracy: 0.5361171364784241 Train Loss: 1.1415005922317505\n","Epoch 8 Train Accuracy: 0.5377365946769714 Test Accuracy: 0.5378825664520264 Train Loss: 1.1165262460708618\n","Epoch 9 Train Accuracy: 0.5399646759033203 Test Accuracy: 0.5401948094367981 Train Loss: 1.1555877923965454\n","Epoch 10 Train Accuracy: 0.5426419973373413 Test Accuracy: 0.5426916480064392 Train Loss: 1.058857798576355\n"]}]},{"cell_type":"markdown","metadata":{"id":"heHXY2AwnwRn"},"source":["## **without tf.function and large model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vi0kE8N6n0Zj","outputId":"f5ba58cb-3252-4ffe-a74e-0362c3f07b8a"},"source":["def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model_large(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model_large.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model_large.trainable_weights))\n","    accuracy.update_state(y, logits)\n","    return loss_value\n","\n","times_without_tf_function_large = []\n","i = 0\n","epoch = 1\n","for step, (img_batch, lbl_batch) in enumerate(train_data):\n","    i += batch_size\n","    t1 = time.time()\n","    loss_value = train_step(img_batch, lbl_batch)\n","    t2 = time.time()\n","    times_without_tf_function_large.append(t2-t1)\n","\n","    \n","    if i / train_size > 1:\n","        train_acc = accuracy.result().numpy()\n","        accuracy.update_state(y_test, model_large(x_test, training=False))\n","        test_acc = accuracy.result().numpy()\n","        print(\"Epoch {} Train Accuracy: {} Test Accuracy: {} Train Loss: {}\".format(epoch, train_acc, test_acc, float(loss_value)))\n","\n","        with train_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", train_acc, step=epoch)\n","            tf.summary.scalar(\"loss\", float(loss_value), step=epoch)\n","            \n","        with test_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", test_acc, step=epoch)\n","        i -= train_size\n","        epoch += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Train Accuracy: 0.545363187789917 Test Accuracy: 0.5454881191253662 Train Loss: 1.0921859741210938\n","Epoch 2 Train Accuracy: 0.5484636425971985 Test Accuracy: 0.5486729741096497 Train Loss: 0.8611825108528137\n","Epoch 3 Train Accuracy: 0.5516840815544128 Test Accuracy: 0.551855206489563 Train Loss: 1.0415751934051514\n","Epoch 4 Train Accuracy: 0.5549912452697754 Test Accuracy: 0.5551114082336426 Train Loss: 1.0378799438476562\n","Epoch 5 Train Accuracy: 0.5585325360298157 Test Accuracy: 0.5586409568786621 Train Loss: 0.8624688982963562\n","Epoch 6 Train Accuracy: 0.5621657967567444 Test Accuracy: 0.5623538494110107 Train Loss: 0.9058047533035278\n","Epoch 7 Train Accuracy: 0.5660796761512756 Test Accuracy: 0.5662655830383301 Train Loss: 0.8777292370796204\n","Epoch 8 Train Accuracy: 0.569894015789032 Test Accuracy: 0.570025622844696 Train Loss: 0.8953149318695068\n","Epoch 9 Train Accuracy: 0.5736650228500366 Test Accuracy: 0.5737859010696411 Train Loss: 0.9410263299942017\n","Epoch 10 Train Accuracy: 0.5774497389793396 Test Accuracy: 0.5774738788604736 Train Loss: 0.6090802550315857\n"]}]},{"cell_type":"markdown","metadata":{"id":"Epj5xZ9OorWV"},"source":["## **Comaprison b/w small and large models with and without tf.function decorator**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GG6ROc5nojnI","outputId":"d44a79d5-e944-4a3b-c931-f303d72ad70e"},"source":["print(\"With tf.function and small model a train step takes {}s\".format(np.mean(times_tf_function)))\n","print(\"Without tf.function and small model a train step takes {}s\".format(np.mean(times_without_tf_function)))\n","print(\"With tf.function and large model a train step takes {}s\".format(np.mean(times_tf_function_large)))\n","print(\"Without tf.function and large model a train step takes {}s\".format(np.mean(times_without_tf_function_large)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["With tf.function and small model a train step takes 0.013421702775398808s\n","Without tf.function and small model a train step takes 0.026557985079325087s\n","With tf.function and large model a train step takes 0.018656457092769314s\n","Without tf.function and large model a train step takes 0.033510945592468325s\n"]}]},{"cell_type":"markdown","metadata":{"id":"sXIy-0c4oLeC"},"source":["## **DenseNet**"]},{"cell_type":"code","metadata":{"id":"uMYcYSJdtUoD"},"source":["from keras.datasets import cifar10\n","def load_dataset_cifar():\n","  # load dataset\n","  (trainX, trainY), (testX, testY) = cifar10.load_data()\n","\t# one hot encode target values\n","  #trainY = to_categorical(trainY)\n","  #testY = to_categorical(testY)\n","  return trainX, trainY, testX, testY\n","\n","\n","def prepare_dataset(trainX, trainY, testX, testY):\n","\n","# Prepare the training dataset.\n","  train_dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n","  train_dataset = train_dataset.shuffle(buffer_size=50000).batch(128)\n","\n","#Prepare the test dataset\n","  test_dataset =  tf.data.Dataset.from_tensor_slices((testX, testY))\n","  test_dataset = test_dataset.batch(128)\n","\n","  return train_dataset,test_dataset\n","\n","def prep_pixels(train, test):\n","\t# convert from integers to floats\n","\ttrain_norm = train.astype('float32')\n","\ttest_norm = test.astype('float32')\n","\t# normalize to range 0-1\n","\ttrain_norm = train_norm / 255.0\n","\ttest_norm = test_norm / 255.0\n","\t# return normalized images\n","\treturn train_norm, test_norm\n","\n","def densenet(input_shape, n_classes, filters = 32):\n","    \n","    #batch norm + relu + conv\n","    def bn_rl_conv(x,filters,kernel=1,strides=1):\n","        \n","        x = BatchNormalization()(x)\n","        x = ReLU()(x)\n","        x = Conv2D(filters, kernel, kernel_initializer='he_normal', strides=strides,padding = 'same')(x)\n","        return x\n","    \n","    def dense_block(x, repetition):\n","        \n","        for _ in range(repetition):\n","            y = bn_rl_conv(x, 4*filters)\n","            y = Dropout(0.2)(y)\n","            y = bn_rl_conv(y, filters, 3)\n","            y = Dropout(0.2)(y)\n","            x = concatenate([y,x])\n","        return x\n","        \n","    def transition_layer(x):\n","        \n","        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )\n","        x = Dropout(0.2)(x)\n","        x = AvgPool2D(2, strides = 2, padding = 'same')(x)\n","        return x\n","    \n","    input = Input (input_shape)\n","    x = Conv2D(64, 7, strides = 2, padding = 'same')(input)\n","    x = MaxPool2D(3, strides = 2, padding = 'same')(x)\n","    \n","    for repetition in [6,12,24,16]:\n","        \n","        d = dense_block(x, repetition)\n","        x = transition_layer(d)\n","    x = GlobalAvgPool2D()(d)\n","    flat =Flatten()(x)\n","    output = Dense(n_classes, activation = 'softmax')(flat)\n","    \n","    model = Model(input, output)\n","    return model\n","\n","@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    opt.apply_gradients(zip(grads, model.trainable_weights))\n","    train_acc_metric.update_state(y, logits)\n","    return loss_value\n","    \n","@tf.function\n","def test_step(x, y):\n","    test_logits = model(x, training=False)\n","    test_acc_metric.update_state(y, test_logits)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6fImfjgtvJw"},"source":["\n","input_shape = 32, 32, 3\n","n_classes = 10\n","\n","# load dataset\n","trainX, trainY, testX, testY = load_dataset_cifar()\n","#prepare dataset\n","train_dataset,test_dataset = prepare_dataset(trainX, trainY, testX, testY)\n","# prepare pixel data\n","trainX, testX = prep_pixels(trainX, testX)\n","\n","datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n","        width_shift_range=0.1,  # randomly shift images horizontally\n","        height_shift_range=0.1,  # randomly shift images vertically\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","    # compute quantities required for featurewise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied)\n","\n","trainX = datagen.fit(trainX)\n","\n","# define model\n","model = densenet(input_shape,n_classes)\n","# compile model\n","opt = keras.optimizers.Adam(learning_rate=1e-3)\n","loss_fn = keras.losses.SparseCategoricalCrossentropy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMUc2vqyKZOC","outputId":"109abaf9-3a50-46e4-dc5e-b95a252e1874"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_11 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n","                                                                                                  \n"," conv2d_228 (Conv2D)            (None, 16, 16, 64)   9472        ['input_11[0][0]']               \n","                                                                                                  \n"," max_pooling2d_28 (MaxPooling2D  (None, 8, 8, 64)    0           ['conv2d_228[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," batch_normalization_165 (Batch  (None, 8, 8, 64)    256         ['max_pooling2d_28[0][0]']       \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_200 (ReLU)               (None, 8, 8, 64)     0           ['batch_normalization_165[0][0]']\n","                                                                                                  \n"," conv2d_229 (Conv2D)            (None, 8, 8, 128)    8320        ['re_lu_200[0][0]']              \n","                                                                                                  \n"," dropout_180 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_229[0][0]']             \n","                                                                                                  \n"," batch_normalization_166 (Batch  (None, 8, 8, 128)   512         ['dropout_180[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_201 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_166[0][0]']\n","                                                                                                  \n"," conv2d_230 (Conv2D)            (None, 8, 8, 32)     36896       ['re_lu_201[0][0]']              \n","                                                                                                  \n"," dropout_181 (Dropout)          (None, 8, 8, 32)     0           ['conv2d_230[0][0]']             \n","                                                                                                  \n"," concatenate_105 (Concatenate)  (None, 8, 8, 96)     0           ['dropout_181[0][0]',            \n","                                                                  'max_pooling2d_28[0][0]']       \n","                                                                                                  \n"," batch_normalization_167 (Batch  (None, 8, 8, 96)    384         ['concatenate_105[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_202 (ReLU)               (None, 8, 8, 96)     0           ['batch_normalization_167[0][0]']\n","                                                                                                  \n"," conv2d_231 (Conv2D)            (None, 8, 8, 128)    12416       ['re_lu_202[0][0]']              \n","                                                                                                  \n"," dropout_182 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_231[0][0]']             \n","                                                                                                  \n"," batch_normalization_168 (Batch  (None, 8, 8, 128)   512         ['dropout_182[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_203 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_168[0][0]']\n","                                                                                                  \n"," conv2d_232 (Conv2D)            (None, 8, 8, 32)     36896       ['re_lu_203[0][0]']              \n","                                                                                                  \n"," dropout_183 (Dropout)          (None, 8, 8, 32)     0           ['conv2d_232[0][0]']             \n","                                                                                                  \n"," concatenate_106 (Concatenate)  (None, 8, 8, 128)    0           ['dropout_183[0][0]',            \n","                                                                  'concatenate_105[0][0]']        \n","                                                                                                  \n"," batch_normalization_169 (Batch  (None, 8, 8, 128)   512         ['concatenate_106[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_204 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_169[0][0]']\n","                                                                                                  \n"," conv2d_233 (Conv2D)            (None, 8, 8, 128)    16512       ['re_lu_204[0][0]']              \n","                                                                                                  \n"," dropout_184 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_233[0][0]']             \n","                                                                                                  \n"," batch_normalization_170 (Batch  (None, 8, 8, 128)   512         ['dropout_184[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_205 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_170[0][0]']\n","                                                                                                  \n"," conv2d_234 (Conv2D)            (None, 8, 8, 32)     36896       ['re_lu_205[0][0]']              \n","                                                                                                  \n"," dropout_185 (Dropout)          (None, 8, 8, 32)     0           ['conv2d_234[0][0]']             \n","                                                                                                  \n"," concatenate_107 (Concatenate)  (None, 8, 8, 160)    0           ['dropout_185[0][0]',            \n","                                                                  'concatenate_106[0][0]']        \n","                                                                                                  \n"," batch_normalization_171 (Batch  (None, 8, 8, 160)   640         ['concatenate_107[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_206 (ReLU)               (None, 8, 8, 160)    0           ['batch_normalization_171[0][0]']\n","                                                                                                  \n"," conv2d_235 (Conv2D)            (None, 8, 8, 128)    20608       ['re_lu_206[0][0]']              \n","                                                                                                  \n"," dropout_186 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_235[0][0]']             \n","                                                                                                  \n"," batch_normalization_172 (Batch  (None, 8, 8, 128)   512         ['dropout_186[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_207 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_172[0][0]']\n","                                                                                                  \n"," conv2d_236 (Conv2D)            (None, 8, 8, 32)     36896       ['re_lu_207[0][0]']              \n","                                                                                                  \n"," dropout_187 (Dropout)          (None, 8, 8, 32)     0           ['conv2d_236[0][0]']             \n","                                                                                                  \n"," concatenate_108 (Concatenate)  (None, 8, 8, 192)    0           ['dropout_187[0][0]',            \n","                                                                  'concatenate_107[0][0]']        \n","                                                                                                  \n"," batch_normalization_173 (Batch  (None, 8, 8, 192)   768         ['concatenate_108[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_208 (ReLU)               (None, 8, 8, 192)    0           ['batch_normalization_173[0][0]']\n","                                                                                                  \n"," conv2d_237 (Conv2D)            (None, 8, 8, 128)    24704       ['re_lu_208[0][0]']              \n","                                                                                                  \n"," dropout_188 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_237[0][0]']             \n","                                                                                                  \n"," batch_normalization_174 (Batch  (None, 8, 8, 128)   512         ['dropout_188[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_209 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_174[0][0]']\n","                                                                                                  \n"," conv2d_238 (Conv2D)            (None, 8, 8, 32)     36896       ['re_lu_209[0][0]']              \n","                                                                                                  \n"," dropout_189 (Dropout)          (None, 8, 8, 32)     0           ['conv2d_238[0][0]']             \n","                                                                                                  \n"," concatenate_109 (Concatenate)  (None, 8, 8, 224)    0           ['dropout_189[0][0]',            \n","                                                                  'concatenate_108[0][0]']        \n","                                                                                                  \n"," batch_normalization_175 (Batch  (None, 8, 8, 224)   896         ['concatenate_109[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_210 (ReLU)               (None, 8, 8, 224)    0           ['batch_normalization_175[0][0]']\n","                                                                                                  \n"," conv2d_239 (Conv2D)            (None, 8, 8, 128)    28800       ['re_lu_210[0][0]']              \n","                                                                                                  \n"," dropout_190 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_239[0][0]']             \n","                                                                                                  \n"," batch_normalization_176 (Batch  (None, 8, 8, 128)   512         ['dropout_190[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_211 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_176[0][0]']\n","                                                                                                  \n"," conv2d_240 (Conv2D)            (None, 8, 8, 32)     36896       ['re_lu_211[0][0]']              \n","                                                                                                  \n"," dropout_191 (Dropout)          (None, 8, 8, 32)     0           ['conv2d_240[0][0]']             \n","                                                                                                  \n"," concatenate_110 (Concatenate)  (None, 8, 8, 256)    0           ['dropout_191[0][0]',            \n","                                                                  'concatenate_109[0][0]']        \n","                                                                                                  \n"," batch_normalization_177 (Batch  (None, 8, 8, 256)   1024        ['concatenate_110[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_212 (ReLU)               (None, 8, 8, 256)    0           ['batch_normalization_177[0][0]']\n","                                                                                                  \n"," conv2d_241 (Conv2D)            (None, 8, 8, 128)    32896       ['re_lu_212[0][0]']              \n","                                                                                                  \n"," dropout_192 (Dropout)          (None, 8, 8, 128)    0           ['conv2d_241[0][0]']             \n","                                                                                                  \n"," average_pooling2d_20 (AverageP  (None, 4, 4, 128)   0           ['dropout_192[0][0]']            \n"," ooling2D)                                                                                        \n","                                                                                                  \n"," batch_normalization_178 (Batch  (None, 4, 4, 128)   512         ['average_pooling2d_20[0][0]']   \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_213 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_178[0][0]']\n","                                                                                                  \n"," conv2d_242 (Conv2D)            (None, 4, 4, 128)    16512       ['re_lu_213[0][0]']              \n","                                                                                                  \n"," dropout_193 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_242[0][0]']             \n","                                                                                                  \n"," batch_normalization_179 (Batch  (None, 4, 4, 128)   512         ['dropout_193[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_214 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_179[0][0]']\n","                                                                                                  \n"," conv2d_243 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_214[0][0]']              \n","                                                                                                  \n"," dropout_194 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_243[0][0]']             \n","                                                                                                  \n"," concatenate_111 (Concatenate)  (None, 4, 4, 160)    0           ['dropout_194[0][0]',            \n","                                                                  'average_pooling2d_20[0][0]']   \n","                                                                                                  \n"," batch_normalization_180 (Batch  (None, 4, 4, 160)   640         ['concatenate_111[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_215 (ReLU)               (None, 4, 4, 160)    0           ['batch_normalization_180[0][0]']\n","                                                                                                  \n"," conv2d_244 (Conv2D)            (None, 4, 4, 128)    20608       ['re_lu_215[0][0]']              \n","                                                                                                  \n"," dropout_195 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_244[0][0]']             \n","                                                                                                  \n"," batch_normalization_181 (Batch  (None, 4, 4, 128)   512         ['dropout_195[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_216 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_181[0][0]']\n","                                                                                                  \n"," conv2d_245 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_216[0][0]']              \n","                                                                                                  \n"," dropout_196 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_245[0][0]']             \n","                                                                                                  \n"," concatenate_112 (Concatenate)  (None, 4, 4, 192)    0           ['dropout_196[0][0]',            \n","                                                                  'concatenate_111[0][0]']        \n","                                                                                                  \n"," batch_normalization_182 (Batch  (None, 4, 4, 192)   768         ['concatenate_112[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_217 (ReLU)               (None, 4, 4, 192)    0           ['batch_normalization_182[0][0]']\n","                                                                                                  \n"," conv2d_246 (Conv2D)            (None, 4, 4, 128)    24704       ['re_lu_217[0][0]']              \n","                                                                                                  \n"," dropout_197 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_246[0][0]']             \n","                                                                                                  \n"," batch_normalization_183 (Batch  (None, 4, 4, 128)   512         ['dropout_197[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_218 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_183[0][0]']\n","                                                                                                  \n"," conv2d_247 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_218[0][0]']              \n","                                                                                                  \n"," dropout_198 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_247[0][0]']             \n","                                                                                                  \n"," concatenate_113 (Concatenate)  (None, 4, 4, 224)    0           ['dropout_198[0][0]',            \n","                                                                  'concatenate_112[0][0]']        \n","                                                                                                  \n"," batch_normalization_184 (Batch  (None, 4, 4, 224)   896         ['concatenate_113[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_219 (ReLU)               (None, 4, 4, 224)    0           ['batch_normalization_184[0][0]']\n","                                                                                                  \n"," conv2d_248 (Conv2D)            (None, 4, 4, 128)    28800       ['re_lu_219[0][0]']              \n","                                                                                                  \n"," dropout_199 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_248[0][0]']             \n","                                                                                                  \n"," batch_normalization_185 (Batch  (None, 4, 4, 128)   512         ['dropout_199[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_220 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_185[0][0]']\n","                                                                                                  \n"," conv2d_249 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_220[0][0]']              \n","                                                                                                  \n"," dropout_200 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_249[0][0]']             \n","                                                                                                  \n"," concatenate_114 (Concatenate)  (None, 4, 4, 256)    0           ['dropout_200[0][0]',            \n","                                                                  'concatenate_113[0][0]']        \n","                                                                                                  \n"," batch_normalization_186 (Batch  (None, 4, 4, 256)   1024        ['concatenate_114[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_221 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_186[0][0]']\n","                                                                                                  \n"," conv2d_250 (Conv2D)            (None, 4, 4, 128)    32896       ['re_lu_221[0][0]']              \n","                                                                                                  \n"," dropout_201 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_250[0][0]']             \n","                                                                                                  \n"," batch_normalization_187 (Batch  (None, 4, 4, 128)   512         ['dropout_201[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_222 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_187[0][0]']\n","                                                                                                  \n"," conv2d_251 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_222[0][0]']              \n","                                                                                                  \n"," dropout_202 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_251[0][0]']             \n","                                                                                                  \n"," concatenate_115 (Concatenate)  (None, 4, 4, 288)    0           ['dropout_202[0][0]',            \n","                                                                  'concatenate_114[0][0]']        \n","                                                                                                  \n"," batch_normalization_188 (Batch  (None, 4, 4, 288)   1152        ['concatenate_115[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_223 (ReLU)               (None, 4, 4, 288)    0           ['batch_normalization_188[0][0]']\n","                                                                                                  \n"," conv2d_252 (Conv2D)            (None, 4, 4, 128)    36992       ['re_lu_223[0][0]']              \n","                                                                                                  \n"," dropout_203 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_252[0][0]']             \n","                                                                                                  \n"," batch_normalization_189 (Batch  (None, 4, 4, 128)   512         ['dropout_203[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_224 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_189[0][0]']\n","                                                                                                  \n"," conv2d_253 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_224[0][0]']              \n","                                                                                                  \n"," dropout_204 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_253[0][0]']             \n","                                                                                                  \n"," concatenate_116 (Concatenate)  (None, 4, 4, 320)    0           ['dropout_204[0][0]',            \n","                                                                  'concatenate_115[0][0]']        \n","                                                                                                  \n"," batch_normalization_190 (Batch  (None, 4, 4, 320)   1280        ['concatenate_116[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_225 (ReLU)               (None, 4, 4, 320)    0           ['batch_normalization_190[0][0]']\n","                                                                                                  \n"," conv2d_254 (Conv2D)            (None, 4, 4, 128)    41088       ['re_lu_225[0][0]']              \n","                                                                                                  \n"," dropout_205 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_254[0][0]']             \n","                                                                                                  \n"," batch_normalization_191 (Batch  (None, 4, 4, 128)   512         ['dropout_205[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_226 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_191[0][0]']\n","                                                                                                  \n"," conv2d_255 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_226[0][0]']              \n","                                                                                                  \n"," dropout_206 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_255[0][0]']             \n","                                                                                                  \n"," concatenate_117 (Concatenate)  (None, 4, 4, 352)    0           ['dropout_206[0][0]',            \n","                                                                  'concatenate_116[0][0]']        \n","                                                                                                  \n"," batch_normalization_192 (Batch  (None, 4, 4, 352)   1408        ['concatenate_117[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_227 (ReLU)               (None, 4, 4, 352)    0           ['batch_normalization_192[0][0]']\n","                                                                                                  \n"," conv2d_256 (Conv2D)            (None, 4, 4, 128)    45184       ['re_lu_227[0][0]']              \n","                                                                                                  \n"," dropout_207 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_256[0][0]']             \n","                                                                                                  \n"," batch_normalization_193 (Batch  (None, 4, 4, 128)   512         ['dropout_207[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_228 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_193[0][0]']\n","                                                                                                  \n"," conv2d_257 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_228[0][0]']              \n","                                                                                                  \n"," dropout_208 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_257[0][0]']             \n","                                                                                                  \n"," concatenate_118 (Concatenate)  (None, 4, 4, 384)    0           ['dropout_208[0][0]',            \n","                                                                  'concatenate_117[0][0]']        \n","                                                                                                  \n"," batch_normalization_194 (Batch  (None, 4, 4, 384)   1536        ['concatenate_118[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_229 (ReLU)               (None, 4, 4, 384)    0           ['batch_normalization_194[0][0]']\n","                                                                                                  \n"," conv2d_258 (Conv2D)            (None, 4, 4, 128)    49280       ['re_lu_229[0][0]']              \n","                                                                                                  \n"," dropout_209 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_258[0][0]']             \n","                                                                                                  \n"," batch_normalization_195 (Batch  (None, 4, 4, 128)   512         ['dropout_209[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_230 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_195[0][0]']\n","                                                                                                  \n"," conv2d_259 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_230[0][0]']              \n","                                                                                                  \n"," dropout_210 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_259[0][0]']             \n","                                                                                                  \n"," concatenate_119 (Concatenate)  (None, 4, 4, 416)    0           ['dropout_210[0][0]',            \n","                                                                  'concatenate_118[0][0]']        \n","                                                                                                  \n"," batch_normalization_196 (Batch  (None, 4, 4, 416)   1664        ['concatenate_119[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_231 (ReLU)               (None, 4, 4, 416)    0           ['batch_normalization_196[0][0]']\n","                                                                                                  \n"," conv2d_260 (Conv2D)            (None, 4, 4, 128)    53376       ['re_lu_231[0][0]']              \n","                                                                                                  \n"," dropout_211 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_260[0][0]']             \n","                                                                                                  \n"," batch_normalization_197 (Batch  (None, 4, 4, 128)   512         ['dropout_211[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_232 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_197[0][0]']\n","                                                                                                  \n"," conv2d_261 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_232[0][0]']              \n","                                                                                                  \n"," dropout_212 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_261[0][0]']             \n","                                                                                                  \n"," concatenate_120 (Concatenate)  (None, 4, 4, 448)    0           ['dropout_212[0][0]',            \n","                                                                  'concatenate_119[0][0]']        \n","                                                                                                  \n"," batch_normalization_198 (Batch  (None, 4, 4, 448)   1792        ['concatenate_120[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_233 (ReLU)               (None, 4, 4, 448)    0           ['batch_normalization_198[0][0]']\n","                                                                                                  \n"," conv2d_262 (Conv2D)            (None, 4, 4, 128)    57472       ['re_lu_233[0][0]']              \n","                                                                                                  \n"," dropout_213 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_262[0][0]']             \n","                                                                                                  \n"," batch_normalization_199 (Batch  (None, 4, 4, 128)   512         ['dropout_213[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_234 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_199[0][0]']\n","                                                                                                  \n"," conv2d_263 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_234[0][0]']              \n","                                                                                                  \n"," dropout_214 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_263[0][0]']             \n","                                                                                                  \n"," concatenate_121 (Concatenate)  (None, 4, 4, 480)    0           ['dropout_214[0][0]',            \n","                                                                  'concatenate_120[0][0]']        \n","                                                                                                  \n"," batch_normalization_200 (Batch  (None, 4, 4, 480)   1920        ['concatenate_121[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_235 (ReLU)               (None, 4, 4, 480)    0           ['batch_normalization_200[0][0]']\n","                                                                                                  \n"," conv2d_264 (Conv2D)            (None, 4, 4, 128)    61568       ['re_lu_235[0][0]']              \n","                                                                                                  \n"," dropout_215 (Dropout)          (None, 4, 4, 128)    0           ['conv2d_264[0][0]']             \n","                                                                                                  \n"," batch_normalization_201 (Batch  (None, 4, 4, 128)   512         ['dropout_215[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_236 (ReLU)               (None, 4, 4, 128)    0           ['batch_normalization_201[0][0]']\n","                                                                                                  \n"," conv2d_265 (Conv2D)            (None, 4, 4, 32)     36896       ['re_lu_236[0][0]']              \n","                                                                                                  \n"," dropout_216 (Dropout)          (None, 4, 4, 32)     0           ['conv2d_265[0][0]']             \n","                                                                                                  \n"," concatenate_122 (Concatenate)  (None, 4, 4, 512)    0           ['dropout_216[0][0]',            \n","                                                                  'concatenate_121[0][0]']        \n","                                                                                                  \n"," batch_normalization_202 (Batch  (None, 4, 4, 512)   2048        ['concatenate_122[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_237 (ReLU)               (None, 4, 4, 512)    0           ['batch_normalization_202[0][0]']\n","                                                                                                  \n"," conv2d_266 (Conv2D)            (None, 4, 4, 256)    131328      ['re_lu_237[0][0]']              \n","                                                                                                  \n"," dropout_217 (Dropout)          (None, 4, 4, 256)    0           ['conv2d_266[0][0]']             \n","                                                                                                  \n"," average_pooling2d_21 (AverageP  (None, 2, 2, 256)   0           ['dropout_217[0][0]']            \n"," ooling2D)                                                                                        \n","                                                                                                  \n"," batch_normalization_203 (Batch  (None, 2, 2, 256)   1024        ['average_pooling2d_21[0][0]']   \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_238 (ReLU)               (None, 2, 2, 256)    0           ['batch_normalization_203[0][0]']\n","                                                                                                  \n"," conv2d_267 (Conv2D)            (None, 2, 2, 128)    32896       ['re_lu_238[0][0]']              \n","                                                                                                  \n"," dropout_218 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_267[0][0]']             \n","                                                                                                  \n"," batch_normalization_204 (Batch  (None, 2, 2, 128)   512         ['dropout_218[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_239 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_204[0][0]']\n","                                                                                                  \n"," conv2d_268 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_239[0][0]']              \n","                                                                                                  \n"," dropout_219 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_268[0][0]']             \n","                                                                                                  \n"," concatenate_123 (Concatenate)  (None, 2, 2, 288)    0           ['dropout_219[0][0]',            \n","                                                                  'average_pooling2d_21[0][0]']   \n","                                                                                                  \n"," batch_normalization_205 (Batch  (None, 2, 2, 288)   1152        ['concatenate_123[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_240 (ReLU)               (None, 2, 2, 288)    0           ['batch_normalization_205[0][0]']\n","                                                                                                  \n"," conv2d_269 (Conv2D)            (None, 2, 2, 128)    36992       ['re_lu_240[0][0]']              \n","                                                                                                  \n"," dropout_220 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_269[0][0]']             \n","                                                                                                  \n"," batch_normalization_206 (Batch  (None, 2, 2, 128)   512         ['dropout_220[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_241 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_206[0][0]']\n","                                                                                                  \n"," conv2d_270 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_241[0][0]']              \n","                                                                                                  \n"," dropout_221 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_270[0][0]']             \n","                                                                                                  \n"," concatenate_124 (Concatenate)  (None, 2, 2, 320)    0           ['dropout_221[0][0]',            \n","                                                                  'concatenate_123[0][0]']        \n","                                                                                                  \n"," batch_normalization_207 (Batch  (None, 2, 2, 320)   1280        ['concatenate_124[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_242 (ReLU)               (None, 2, 2, 320)    0           ['batch_normalization_207[0][0]']\n","                                                                                                  \n"," conv2d_271 (Conv2D)            (None, 2, 2, 128)    41088       ['re_lu_242[0][0]']              \n","                                                                                                  \n"," dropout_222 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_271[0][0]']             \n","                                                                                                  \n"," batch_normalization_208 (Batch  (None, 2, 2, 128)   512         ['dropout_222[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_243 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_208[0][0]']\n","                                                                                                  \n"," conv2d_272 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_243[0][0]']              \n","                                                                                                  \n"," dropout_223 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_272[0][0]']             \n","                                                                                                  \n"," concatenate_125 (Concatenate)  (None, 2, 2, 352)    0           ['dropout_223[0][0]',            \n","                                                                  'concatenate_124[0][0]']        \n","                                                                                                  \n"," batch_normalization_209 (Batch  (None, 2, 2, 352)   1408        ['concatenate_125[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_244 (ReLU)               (None, 2, 2, 352)    0           ['batch_normalization_209[0][0]']\n","                                                                                                  \n"," conv2d_273 (Conv2D)            (None, 2, 2, 128)    45184       ['re_lu_244[0][0]']              \n","                                                                                                  \n"," dropout_224 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_273[0][0]']             \n","                                                                                                  \n"," batch_normalization_210 (Batch  (None, 2, 2, 128)   512         ['dropout_224[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_245 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_210[0][0]']\n","                                                                                                  \n"," conv2d_274 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_245[0][0]']              \n","                                                                                                  \n"," dropout_225 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_274[0][0]']             \n","                                                                                                  \n"," concatenate_126 (Concatenate)  (None, 2, 2, 384)    0           ['dropout_225[0][0]',            \n","                                                                  'concatenate_125[0][0]']        \n","                                                                                                  \n"," batch_normalization_211 (Batch  (None, 2, 2, 384)   1536        ['concatenate_126[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_246 (ReLU)               (None, 2, 2, 384)    0           ['batch_normalization_211[0][0]']\n","                                                                                                  \n"," conv2d_275 (Conv2D)            (None, 2, 2, 128)    49280       ['re_lu_246[0][0]']              \n","                                                                                                  \n"," dropout_226 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_275[0][0]']             \n","                                                                                                  \n"," batch_normalization_212 (Batch  (None, 2, 2, 128)   512         ['dropout_226[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_247 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_212[0][0]']\n","                                                                                                  \n"," conv2d_276 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_247[0][0]']              \n","                                                                                                  \n"," dropout_227 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_276[0][0]']             \n","                                                                                                  \n"," concatenate_127 (Concatenate)  (None, 2, 2, 416)    0           ['dropout_227[0][0]',            \n","                                                                  'concatenate_126[0][0]']        \n","                                                                                                  \n"," batch_normalization_213 (Batch  (None, 2, 2, 416)   1664        ['concatenate_127[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_248 (ReLU)               (None, 2, 2, 416)    0           ['batch_normalization_213[0][0]']\n","                                                                                                  \n"," conv2d_277 (Conv2D)            (None, 2, 2, 128)    53376       ['re_lu_248[0][0]']              \n","                                                                                                  \n"," dropout_228 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_277[0][0]']             \n","                                                                                                  \n"," batch_normalization_214 (Batch  (None, 2, 2, 128)   512         ['dropout_228[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_249 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_214[0][0]']\n","                                                                                                  \n"," conv2d_278 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_249[0][0]']              \n","                                                                                                  \n"," dropout_229 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_278[0][0]']             \n","                                                                                                  \n"," concatenate_128 (Concatenate)  (None, 2, 2, 448)    0           ['dropout_229[0][0]',            \n","                                                                  'concatenate_127[0][0]']        \n","                                                                                                  \n"," batch_normalization_215 (Batch  (None, 2, 2, 448)   1792        ['concatenate_128[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_250 (ReLU)               (None, 2, 2, 448)    0           ['batch_normalization_215[0][0]']\n","                                                                                                  \n"," conv2d_279 (Conv2D)            (None, 2, 2, 128)    57472       ['re_lu_250[0][0]']              \n","                                                                                                  \n"," dropout_230 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_279[0][0]']             \n","                                                                                                  \n"," batch_normalization_216 (Batch  (None, 2, 2, 128)   512         ['dropout_230[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_251 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_216[0][0]']\n","                                                                                                  \n"," conv2d_280 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_251[0][0]']              \n","                                                                                                  \n"," dropout_231 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_280[0][0]']             \n","                                                                                                  \n"," concatenate_129 (Concatenate)  (None, 2, 2, 480)    0           ['dropout_231[0][0]',            \n","                                                                  'concatenate_128[0][0]']        \n","                                                                                                  \n"," batch_normalization_217 (Batch  (None, 2, 2, 480)   1920        ['concatenate_129[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_252 (ReLU)               (None, 2, 2, 480)    0           ['batch_normalization_217[0][0]']\n","                                                                                                  \n"," conv2d_281 (Conv2D)            (None, 2, 2, 128)    61568       ['re_lu_252[0][0]']              \n","                                                                                                  \n"," dropout_232 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_281[0][0]']             \n","                                                                                                  \n"," batch_normalization_218 (Batch  (None, 2, 2, 128)   512         ['dropout_232[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_253 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_218[0][0]']\n","                                                                                                  \n"," conv2d_282 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_253[0][0]']              \n","                                                                                                  \n"," dropout_233 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_282[0][0]']             \n","                                                                                                  \n"," concatenate_130 (Concatenate)  (None, 2, 2, 512)    0           ['dropout_233[0][0]',            \n","                                                                  'concatenate_129[0][0]']        \n","                                                                                                  \n"," batch_normalization_219 (Batch  (None, 2, 2, 512)   2048        ['concatenate_130[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_254 (ReLU)               (None, 2, 2, 512)    0           ['batch_normalization_219[0][0]']\n","                                                                                                  \n"," conv2d_283 (Conv2D)            (None, 2, 2, 128)    65664       ['re_lu_254[0][0]']              \n","                                                                                                  \n"," dropout_234 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_283[0][0]']             \n","                                                                                                  \n"," batch_normalization_220 (Batch  (None, 2, 2, 128)   512         ['dropout_234[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_255 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_220[0][0]']\n","                                                                                                  \n"," conv2d_284 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_255[0][0]']              \n","                                                                                                  \n"," dropout_235 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_284[0][0]']             \n","                                                                                                  \n"," concatenate_131 (Concatenate)  (None, 2, 2, 544)    0           ['dropout_235[0][0]',            \n","                                                                  'concatenate_130[0][0]']        \n","                                                                                                  \n"," batch_normalization_221 (Batch  (None, 2, 2, 544)   2176        ['concatenate_131[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_256 (ReLU)               (None, 2, 2, 544)    0           ['batch_normalization_221[0][0]']\n","                                                                                                  \n"," conv2d_285 (Conv2D)            (None, 2, 2, 128)    69760       ['re_lu_256[0][0]']              \n","                                                                                                  \n"," dropout_236 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_285[0][0]']             \n","                                                                                                  \n"," batch_normalization_222 (Batch  (None, 2, 2, 128)   512         ['dropout_236[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_257 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_222[0][0]']\n","                                                                                                  \n"," conv2d_286 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_257[0][0]']              \n","                                                                                                  \n"," dropout_237 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_286[0][0]']             \n","                                                                                                  \n"," concatenate_132 (Concatenate)  (None, 2, 2, 576)    0           ['dropout_237[0][0]',            \n","                                                                  'concatenate_131[0][0]']        \n","                                                                                                  \n"," batch_normalization_223 (Batch  (None, 2, 2, 576)   2304        ['concatenate_132[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_258 (ReLU)               (None, 2, 2, 576)    0           ['batch_normalization_223[0][0]']\n","                                                                                                  \n"," conv2d_287 (Conv2D)            (None, 2, 2, 128)    73856       ['re_lu_258[0][0]']              \n","                                                                                                  \n"," dropout_238 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_287[0][0]']             \n","                                                                                                  \n"," batch_normalization_224 (Batch  (None, 2, 2, 128)   512         ['dropout_238[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_259 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_224[0][0]']\n","                                                                                                  \n"," conv2d_288 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_259[0][0]']              \n","                                                                                                  \n"," dropout_239 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_288[0][0]']             \n","                                                                                                  \n"," concatenate_133 (Concatenate)  (None, 2, 2, 608)    0           ['dropout_239[0][0]',            \n","                                                                  'concatenate_132[0][0]']        \n","                                                                                                  \n"," batch_normalization_225 (Batch  (None, 2, 2, 608)   2432        ['concatenate_133[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_260 (ReLU)               (None, 2, 2, 608)    0           ['batch_normalization_225[0][0]']\n","                                                                                                  \n"," conv2d_289 (Conv2D)            (None, 2, 2, 128)    77952       ['re_lu_260[0][0]']              \n","                                                                                                  \n"," dropout_240 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_289[0][0]']             \n","                                                                                                  \n"," batch_normalization_226 (Batch  (None, 2, 2, 128)   512         ['dropout_240[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_261 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_226[0][0]']\n","                                                                                                  \n"," conv2d_290 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_261[0][0]']              \n","                                                                                                  \n"," dropout_241 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_290[0][0]']             \n","                                                                                                  \n"," concatenate_134 (Concatenate)  (None, 2, 2, 640)    0           ['dropout_241[0][0]',            \n","                                                                  'concatenate_133[0][0]']        \n","                                                                                                  \n"," batch_normalization_227 (Batch  (None, 2, 2, 640)   2560        ['concatenate_134[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_262 (ReLU)               (None, 2, 2, 640)    0           ['batch_normalization_227[0][0]']\n","                                                                                                  \n"," conv2d_291 (Conv2D)            (None, 2, 2, 128)    82048       ['re_lu_262[0][0]']              \n","                                                                                                  \n"," dropout_242 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_291[0][0]']             \n","                                                                                                  \n"," batch_normalization_228 (Batch  (None, 2, 2, 128)   512         ['dropout_242[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_263 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_228[0][0]']\n","                                                                                                  \n"," conv2d_292 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_263[0][0]']              \n","                                                                                                  \n"," dropout_243 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_292[0][0]']             \n","                                                                                                  \n"," concatenate_135 (Concatenate)  (None, 2, 2, 672)    0           ['dropout_243[0][0]',            \n","                                                                  'concatenate_134[0][0]']        \n","                                                                                                  \n"," batch_normalization_229 (Batch  (None, 2, 2, 672)   2688        ['concatenate_135[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_264 (ReLU)               (None, 2, 2, 672)    0           ['batch_normalization_229[0][0]']\n","                                                                                                  \n"," conv2d_293 (Conv2D)            (None, 2, 2, 128)    86144       ['re_lu_264[0][0]']              \n","                                                                                                  \n"," dropout_244 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_293[0][0]']             \n","                                                                                                  \n"," batch_normalization_230 (Batch  (None, 2, 2, 128)   512         ['dropout_244[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_265 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_230[0][0]']\n","                                                                                                  \n"," conv2d_294 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_265[0][0]']              \n","                                                                                                  \n"," dropout_245 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_294[0][0]']             \n","                                                                                                  \n"," concatenate_136 (Concatenate)  (None, 2, 2, 704)    0           ['dropout_245[0][0]',            \n","                                                                  'concatenate_135[0][0]']        \n","                                                                                                  \n"," batch_normalization_231 (Batch  (None, 2, 2, 704)   2816        ['concatenate_136[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_266 (ReLU)               (None, 2, 2, 704)    0           ['batch_normalization_231[0][0]']\n","                                                                                                  \n"," conv2d_295 (Conv2D)            (None, 2, 2, 128)    90240       ['re_lu_266[0][0]']              \n","                                                                                                  \n"," dropout_246 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_295[0][0]']             \n","                                                                                                  \n"," batch_normalization_232 (Batch  (None, 2, 2, 128)   512         ['dropout_246[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_267 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_232[0][0]']\n","                                                                                                  \n"," conv2d_296 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_267[0][0]']              \n","                                                                                                  \n"," dropout_247 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_296[0][0]']             \n","                                                                                                  \n"," concatenate_137 (Concatenate)  (None, 2, 2, 736)    0           ['dropout_247[0][0]',            \n","                                                                  'concatenate_136[0][0]']        \n","                                                                                                  \n"," batch_normalization_233 (Batch  (None, 2, 2, 736)   2944        ['concatenate_137[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_268 (ReLU)               (None, 2, 2, 736)    0           ['batch_normalization_233[0][0]']\n","                                                                                                  \n"," conv2d_297 (Conv2D)            (None, 2, 2, 128)    94336       ['re_lu_268[0][0]']              \n","                                                                                                  \n"," dropout_248 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_297[0][0]']             \n","                                                                                                  \n"," batch_normalization_234 (Batch  (None, 2, 2, 128)   512         ['dropout_248[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_269 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_234[0][0]']\n","                                                                                                  \n"," conv2d_298 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_269[0][0]']              \n","                                                                                                  \n"," dropout_249 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_298[0][0]']             \n","                                                                                                  \n"," concatenate_138 (Concatenate)  (None, 2, 2, 768)    0           ['dropout_249[0][0]',            \n","                                                                  'concatenate_137[0][0]']        \n","                                                                                                  \n"," batch_normalization_235 (Batch  (None, 2, 2, 768)   3072        ['concatenate_138[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_270 (ReLU)               (None, 2, 2, 768)    0           ['batch_normalization_235[0][0]']\n","                                                                                                  \n"," conv2d_299 (Conv2D)            (None, 2, 2, 128)    98432       ['re_lu_270[0][0]']              \n","                                                                                                  \n"," dropout_250 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_299[0][0]']             \n","                                                                                                  \n"," batch_normalization_236 (Batch  (None, 2, 2, 128)   512         ['dropout_250[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_271 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_236[0][0]']\n","                                                                                                  \n"," conv2d_300 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_271[0][0]']              \n","                                                                                                  \n"," dropout_251 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_300[0][0]']             \n","                                                                                                  \n"," concatenate_139 (Concatenate)  (None, 2, 2, 800)    0           ['dropout_251[0][0]',            \n","                                                                  'concatenate_138[0][0]']        \n","                                                                                                  \n"," batch_normalization_237 (Batch  (None, 2, 2, 800)   3200        ['concatenate_139[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_272 (ReLU)               (None, 2, 2, 800)    0           ['batch_normalization_237[0][0]']\n","                                                                                                  \n"," conv2d_301 (Conv2D)            (None, 2, 2, 128)    102528      ['re_lu_272[0][0]']              \n","                                                                                                  \n"," dropout_252 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_301[0][0]']             \n","                                                                                                  \n"," batch_normalization_238 (Batch  (None, 2, 2, 128)   512         ['dropout_252[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_273 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_238[0][0]']\n","                                                                                                  \n"," conv2d_302 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_273[0][0]']              \n","                                                                                                  \n"," dropout_253 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_302[0][0]']             \n","                                                                                                  \n"," concatenate_140 (Concatenate)  (None, 2, 2, 832)    0           ['dropout_253[0][0]',            \n","                                                                  'concatenate_139[0][0]']        \n","                                                                                                  \n"," batch_normalization_239 (Batch  (None, 2, 2, 832)   3328        ['concatenate_140[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_274 (ReLU)               (None, 2, 2, 832)    0           ['batch_normalization_239[0][0]']\n","                                                                                                  \n"," conv2d_303 (Conv2D)            (None, 2, 2, 128)    106624      ['re_lu_274[0][0]']              \n","                                                                                                  \n"," dropout_254 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_303[0][0]']             \n","                                                                                                  \n"," batch_normalization_240 (Batch  (None, 2, 2, 128)   512         ['dropout_254[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_275 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_240[0][0]']\n","                                                                                                  \n"," conv2d_304 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_275[0][0]']              \n","                                                                                                  \n"," dropout_255 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_304[0][0]']             \n","                                                                                                  \n"," concatenate_141 (Concatenate)  (None, 2, 2, 864)    0           ['dropout_255[0][0]',            \n","                                                                  'concatenate_140[0][0]']        \n","                                                                                                  \n"," batch_normalization_241 (Batch  (None, 2, 2, 864)   3456        ['concatenate_141[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_276 (ReLU)               (None, 2, 2, 864)    0           ['batch_normalization_241[0][0]']\n","                                                                                                  \n"," conv2d_305 (Conv2D)            (None, 2, 2, 128)    110720      ['re_lu_276[0][0]']              \n","                                                                                                  \n"," dropout_256 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_305[0][0]']             \n","                                                                                                  \n"," batch_normalization_242 (Batch  (None, 2, 2, 128)   512         ['dropout_256[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_277 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_242[0][0]']\n","                                                                                                  \n"," conv2d_306 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_277[0][0]']              \n","                                                                                                  \n"," dropout_257 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_306[0][0]']             \n","                                                                                                  \n"," concatenate_142 (Concatenate)  (None, 2, 2, 896)    0           ['dropout_257[0][0]',            \n","                                                                  'concatenate_141[0][0]']        \n","                                                                                                  \n"," batch_normalization_243 (Batch  (None, 2, 2, 896)   3584        ['concatenate_142[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_278 (ReLU)               (None, 2, 2, 896)    0           ['batch_normalization_243[0][0]']\n","                                                                                                  \n"," conv2d_307 (Conv2D)            (None, 2, 2, 128)    114816      ['re_lu_278[0][0]']              \n","                                                                                                  \n"," dropout_258 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_307[0][0]']             \n","                                                                                                  \n"," batch_normalization_244 (Batch  (None, 2, 2, 128)   512         ['dropout_258[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_279 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_244[0][0]']\n","                                                                                                  \n"," conv2d_308 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_279[0][0]']              \n","                                                                                                  \n"," dropout_259 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_308[0][0]']             \n","                                                                                                  \n"," concatenate_143 (Concatenate)  (None, 2, 2, 928)    0           ['dropout_259[0][0]',            \n","                                                                  'concatenate_142[0][0]']        \n","                                                                                                  \n"," batch_normalization_245 (Batch  (None, 2, 2, 928)   3712        ['concatenate_143[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_280 (ReLU)               (None, 2, 2, 928)    0           ['batch_normalization_245[0][0]']\n","                                                                                                  \n"," conv2d_309 (Conv2D)            (None, 2, 2, 128)    118912      ['re_lu_280[0][0]']              \n","                                                                                                  \n"," dropout_260 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_309[0][0]']             \n","                                                                                                  \n"," batch_normalization_246 (Batch  (None, 2, 2, 128)   512         ['dropout_260[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_281 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_246[0][0]']\n","                                                                                                  \n"," conv2d_310 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_281[0][0]']              \n","                                                                                                  \n"," dropout_261 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_310[0][0]']             \n","                                                                                                  \n"," concatenate_144 (Concatenate)  (None, 2, 2, 960)    0           ['dropout_261[0][0]',            \n","                                                                  'concatenate_143[0][0]']        \n","                                                                                                  \n"," batch_normalization_247 (Batch  (None, 2, 2, 960)   3840        ['concatenate_144[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_282 (ReLU)               (None, 2, 2, 960)    0           ['batch_normalization_247[0][0]']\n","                                                                                                  \n"," conv2d_311 (Conv2D)            (None, 2, 2, 128)    123008      ['re_lu_282[0][0]']              \n","                                                                                                  \n"," dropout_262 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_311[0][0]']             \n","                                                                                                  \n"," batch_normalization_248 (Batch  (None, 2, 2, 128)   512         ['dropout_262[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_283 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_248[0][0]']\n","                                                                                                  \n"," conv2d_312 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_283[0][0]']              \n","                                                                                                  \n"," dropout_263 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_312[0][0]']             \n","                                                                                                  \n"," concatenate_145 (Concatenate)  (None, 2, 2, 992)    0           ['dropout_263[0][0]',            \n","                                                                  'concatenate_144[0][0]']        \n","                                                                                                  \n"," batch_normalization_249 (Batch  (None, 2, 2, 992)   3968        ['concatenate_145[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_284 (ReLU)               (None, 2, 2, 992)    0           ['batch_normalization_249[0][0]']\n","                                                                                                  \n"," conv2d_313 (Conv2D)            (None, 2, 2, 128)    127104      ['re_lu_284[0][0]']              \n","                                                                                                  \n"," dropout_264 (Dropout)          (None, 2, 2, 128)    0           ['conv2d_313[0][0]']             \n","                                                                                                  \n"," batch_normalization_250 (Batch  (None, 2, 2, 128)   512         ['dropout_264[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_285 (ReLU)               (None, 2, 2, 128)    0           ['batch_normalization_250[0][0]']\n","                                                                                                  \n"," conv2d_314 (Conv2D)            (None, 2, 2, 32)     36896       ['re_lu_285[0][0]']              \n","                                                                                                  \n"," dropout_265 (Dropout)          (None, 2, 2, 32)     0           ['conv2d_314[0][0]']             \n","                                                                                                  \n"," concatenate_146 (Concatenate)  (None, 2, 2, 1024)   0           ['dropout_265[0][0]',            \n","                                                                  'concatenate_145[0][0]']        \n","                                                                                                  \n"," batch_normalization_251 (Batch  (None, 2, 2, 1024)  4096        ['concatenate_146[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_286 (ReLU)               (None, 2, 2, 1024)   0           ['batch_normalization_251[0][0]']\n","                                                                                                  \n"," conv2d_315 (Conv2D)            (None, 2, 2, 512)    524800      ['re_lu_286[0][0]']              \n","                                                                                                  \n"," dropout_266 (Dropout)          (None, 2, 2, 512)    0           ['conv2d_315[0][0]']             \n","                                                                                                  \n"," average_pooling2d_22 (AverageP  (None, 1, 1, 512)   0           ['dropout_266[0][0]']            \n"," ooling2D)                                                                                        \n","                                                                                                  \n"," batch_normalization_252 (Batch  (None, 1, 1, 512)   2048        ['average_pooling2d_22[0][0]']   \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_287 (ReLU)               (None, 1, 1, 512)    0           ['batch_normalization_252[0][0]']\n","                                                                                                  \n"," conv2d_316 (Conv2D)            (None, 1, 1, 128)    65664       ['re_lu_287[0][0]']              \n","                                                                                                  \n"," dropout_267 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_316[0][0]']             \n","                                                                                                  \n"," batch_normalization_253 (Batch  (None, 1, 1, 128)   512         ['dropout_267[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_288 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_253[0][0]']\n","                                                                                                  \n"," conv2d_317 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_288[0][0]']              \n","                                                                                                  \n"," dropout_268 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_317[0][0]']             \n","                                                                                                  \n"," concatenate_147 (Concatenate)  (None, 1, 1, 544)    0           ['dropout_268[0][0]',            \n","                                                                  'average_pooling2d_22[0][0]']   \n","                                                                                                  \n"," batch_normalization_254 (Batch  (None, 1, 1, 544)   2176        ['concatenate_147[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_289 (ReLU)               (None, 1, 1, 544)    0           ['batch_normalization_254[0][0]']\n","                                                                                                  \n"," conv2d_318 (Conv2D)            (None, 1, 1, 128)    69760       ['re_lu_289[0][0]']              \n","                                                                                                  \n"," dropout_269 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_318[0][0]']             \n","                                                                                                  \n"," batch_normalization_255 (Batch  (None, 1, 1, 128)   512         ['dropout_269[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_290 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_255[0][0]']\n","                                                                                                  \n"," conv2d_319 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_290[0][0]']              \n","                                                                                                  \n"," dropout_270 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_319[0][0]']             \n","                                                                                                  \n"," concatenate_148 (Concatenate)  (None, 1, 1, 576)    0           ['dropout_270[0][0]',            \n","                                                                  'concatenate_147[0][0]']        \n","                                                                                                  \n"," batch_normalization_256 (Batch  (None, 1, 1, 576)   2304        ['concatenate_148[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_291 (ReLU)               (None, 1, 1, 576)    0           ['batch_normalization_256[0][0]']\n","                                                                                                  \n"," conv2d_320 (Conv2D)            (None, 1, 1, 128)    73856       ['re_lu_291[0][0]']              \n","                                                                                                  \n"," dropout_271 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_320[0][0]']             \n","                                                                                                  \n"," batch_normalization_257 (Batch  (None, 1, 1, 128)   512         ['dropout_271[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_292 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_257[0][0]']\n","                                                                                                  \n"," conv2d_321 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_292[0][0]']              \n","                                                                                                  \n"," dropout_272 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_321[0][0]']             \n","                                                                                                  \n"," concatenate_149 (Concatenate)  (None, 1, 1, 608)    0           ['dropout_272[0][0]',            \n","                                                                  'concatenate_148[0][0]']        \n","                                                                                                  \n"," batch_normalization_258 (Batch  (None, 1, 1, 608)   2432        ['concatenate_149[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_293 (ReLU)               (None, 1, 1, 608)    0           ['batch_normalization_258[0][0]']\n","                                                                                                  \n"," conv2d_322 (Conv2D)            (None, 1, 1, 128)    77952       ['re_lu_293[0][0]']              \n","                                                                                                  \n"," dropout_273 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_322[0][0]']             \n","                                                                                                  \n"," batch_normalization_259 (Batch  (None, 1, 1, 128)   512         ['dropout_273[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_294 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_259[0][0]']\n","                                                                                                  \n"," conv2d_323 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_294[0][0]']              \n","                                                                                                  \n"," dropout_274 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_323[0][0]']             \n","                                                                                                  \n"," concatenate_150 (Concatenate)  (None, 1, 1, 640)    0           ['dropout_274[0][0]',            \n","                                                                  'concatenate_149[0][0]']        \n","                                                                                                  \n"," batch_normalization_260 (Batch  (None, 1, 1, 640)   2560        ['concatenate_150[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_295 (ReLU)               (None, 1, 1, 640)    0           ['batch_normalization_260[0][0]']\n","                                                                                                  \n"," conv2d_324 (Conv2D)            (None, 1, 1, 128)    82048       ['re_lu_295[0][0]']              \n","                                                                                                  \n"," dropout_275 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_324[0][0]']             \n","                                                                                                  \n"," batch_normalization_261 (Batch  (None, 1, 1, 128)   512         ['dropout_275[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_296 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_261[0][0]']\n","                                                                                                  \n"," conv2d_325 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_296[0][0]']              \n","                                                                                                  \n"," dropout_276 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_325[0][0]']             \n","                                                                                                  \n"," concatenate_151 (Concatenate)  (None, 1, 1, 672)    0           ['dropout_276[0][0]',            \n","                                                                  'concatenate_150[0][0]']        \n","                                                                                                  \n"," batch_normalization_262 (Batch  (None, 1, 1, 672)   2688        ['concatenate_151[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_297 (ReLU)               (None, 1, 1, 672)    0           ['batch_normalization_262[0][0]']\n","                                                                                                  \n"," conv2d_326 (Conv2D)            (None, 1, 1, 128)    86144       ['re_lu_297[0][0]']              \n","                                                                                                  \n"," dropout_277 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_326[0][0]']             \n","                                                                                                  \n"," batch_normalization_263 (Batch  (None, 1, 1, 128)   512         ['dropout_277[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_298 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_263[0][0]']\n","                                                                                                  \n"," conv2d_327 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_298[0][0]']              \n","                                                                                                  \n"," dropout_278 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_327[0][0]']             \n","                                                                                                  \n"," concatenate_152 (Concatenate)  (None, 1, 1, 704)    0           ['dropout_278[0][0]',            \n","                                                                  'concatenate_151[0][0]']        \n","                                                                                                  \n"," batch_normalization_264 (Batch  (None, 1, 1, 704)   2816        ['concatenate_152[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_299 (ReLU)               (None, 1, 1, 704)    0           ['batch_normalization_264[0][0]']\n","                                                                                                  \n"," conv2d_328 (Conv2D)            (None, 1, 1, 128)    90240       ['re_lu_299[0][0]']              \n","                                                                                                  \n"," dropout_279 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_328[0][0]']             \n","                                                                                                  \n"," batch_normalization_265 (Batch  (None, 1, 1, 128)   512         ['dropout_279[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_300 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_265[0][0]']\n","                                                                                                  \n"," conv2d_329 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_300[0][0]']              \n","                                                                                                  \n"," dropout_280 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_329[0][0]']             \n","                                                                                                  \n"," concatenate_153 (Concatenate)  (None, 1, 1, 736)    0           ['dropout_280[0][0]',            \n","                                                                  'concatenate_152[0][0]']        \n","                                                                                                  \n"," batch_normalization_266 (Batch  (None, 1, 1, 736)   2944        ['concatenate_153[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_301 (ReLU)               (None, 1, 1, 736)    0           ['batch_normalization_266[0][0]']\n","                                                                                                  \n"," conv2d_330 (Conv2D)            (None, 1, 1, 128)    94336       ['re_lu_301[0][0]']              \n","                                                                                                  \n"," dropout_281 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_330[0][0]']             \n","                                                                                                  \n"," batch_normalization_267 (Batch  (None, 1, 1, 128)   512         ['dropout_281[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_302 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_267[0][0]']\n","                                                                                                  \n"," conv2d_331 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_302[0][0]']              \n","                                                                                                  \n"," dropout_282 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_331[0][0]']             \n","                                                                                                  \n"," concatenate_154 (Concatenate)  (None, 1, 1, 768)    0           ['dropout_282[0][0]',            \n","                                                                  'concatenate_153[0][0]']        \n","                                                                                                  \n"," batch_normalization_268 (Batch  (None, 1, 1, 768)   3072        ['concatenate_154[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_303 (ReLU)               (None, 1, 1, 768)    0           ['batch_normalization_268[0][0]']\n","                                                                                                  \n"," conv2d_332 (Conv2D)            (None, 1, 1, 128)    98432       ['re_lu_303[0][0]']              \n","                                                                                                  \n"," dropout_283 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_332[0][0]']             \n","                                                                                                  \n"," batch_normalization_269 (Batch  (None, 1, 1, 128)   512         ['dropout_283[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_304 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_269[0][0]']\n","                                                                                                  \n"," conv2d_333 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_304[0][0]']              \n","                                                                                                  \n"," dropout_284 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_333[0][0]']             \n","                                                                                                  \n"," concatenate_155 (Concatenate)  (None, 1, 1, 800)    0           ['dropout_284[0][0]',            \n","                                                                  'concatenate_154[0][0]']        \n","                                                                                                  \n"," batch_normalization_270 (Batch  (None, 1, 1, 800)   3200        ['concatenate_155[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_305 (ReLU)               (None, 1, 1, 800)    0           ['batch_normalization_270[0][0]']\n","                                                                                                  \n"," conv2d_334 (Conv2D)            (None, 1, 1, 128)    102528      ['re_lu_305[0][0]']              \n","                                                                                                  \n"," dropout_285 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_334[0][0]']             \n","                                                                                                  \n"," batch_normalization_271 (Batch  (None, 1, 1, 128)   512         ['dropout_285[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_306 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_271[0][0]']\n","                                                                                                  \n"," conv2d_335 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_306[0][0]']              \n","                                                                                                  \n"," dropout_286 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_335[0][0]']             \n","                                                                                                  \n"," concatenate_156 (Concatenate)  (None, 1, 1, 832)    0           ['dropout_286[0][0]',            \n","                                                                  'concatenate_155[0][0]']        \n","                                                                                                  \n"," batch_normalization_272 (Batch  (None, 1, 1, 832)   3328        ['concatenate_156[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_307 (ReLU)               (None, 1, 1, 832)    0           ['batch_normalization_272[0][0]']\n","                                                                                                  \n"," conv2d_336 (Conv2D)            (None, 1, 1, 128)    106624      ['re_lu_307[0][0]']              \n","                                                                                                  \n"," dropout_287 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_336[0][0]']             \n","                                                                                                  \n"," batch_normalization_273 (Batch  (None, 1, 1, 128)   512         ['dropout_287[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_308 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_273[0][0]']\n","                                                                                                  \n"," conv2d_337 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_308[0][0]']              \n","                                                                                                  \n"," dropout_288 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_337[0][0]']             \n","                                                                                                  \n"," concatenate_157 (Concatenate)  (None, 1, 1, 864)    0           ['dropout_288[0][0]',            \n","                                                                  'concatenate_156[0][0]']        \n","                                                                                                  \n"," batch_normalization_274 (Batch  (None, 1, 1, 864)   3456        ['concatenate_157[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_309 (ReLU)               (None, 1, 1, 864)    0           ['batch_normalization_274[0][0]']\n","                                                                                                  \n"," conv2d_338 (Conv2D)            (None, 1, 1, 128)    110720      ['re_lu_309[0][0]']              \n","                                                                                                  \n"," dropout_289 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_338[0][0]']             \n","                                                                                                  \n"," batch_normalization_275 (Batch  (None, 1, 1, 128)   512         ['dropout_289[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_310 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_275[0][0]']\n","                                                                                                  \n"," conv2d_339 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_310[0][0]']              \n","                                                                                                  \n"," dropout_290 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_339[0][0]']             \n","                                                                                                  \n"," concatenate_158 (Concatenate)  (None, 1, 1, 896)    0           ['dropout_290[0][0]',            \n","                                                                  'concatenate_157[0][0]']        \n","                                                                                                  \n"," batch_normalization_276 (Batch  (None, 1, 1, 896)   3584        ['concatenate_158[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_311 (ReLU)               (None, 1, 1, 896)    0           ['batch_normalization_276[0][0]']\n","                                                                                                  \n"," conv2d_340 (Conv2D)            (None, 1, 1, 128)    114816      ['re_lu_311[0][0]']              \n","                                                                                                  \n"," dropout_291 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_340[0][0]']             \n","                                                                                                  \n"," batch_normalization_277 (Batch  (None, 1, 1, 128)   512         ['dropout_291[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_312 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_277[0][0]']\n","                                                                                                  \n"," conv2d_341 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_312[0][0]']              \n","                                                                                                  \n"," dropout_292 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_341[0][0]']             \n","                                                                                                  \n"," concatenate_159 (Concatenate)  (None, 1, 1, 928)    0           ['dropout_292[0][0]',            \n","                                                                  'concatenate_158[0][0]']        \n","                                                                                                  \n"," batch_normalization_278 (Batch  (None, 1, 1, 928)   3712        ['concatenate_159[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_313 (ReLU)               (None, 1, 1, 928)    0           ['batch_normalization_278[0][0]']\n","                                                                                                  \n"," conv2d_342 (Conv2D)            (None, 1, 1, 128)    118912      ['re_lu_313[0][0]']              \n","                                                                                                  \n"," dropout_293 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_342[0][0]']             \n","                                                                                                  \n"," batch_normalization_279 (Batch  (None, 1, 1, 128)   512         ['dropout_293[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_314 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_279[0][0]']\n","                                                                                                  \n"," conv2d_343 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_314[0][0]']              \n","                                                                                                  \n"," dropout_294 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_343[0][0]']             \n","                                                                                                  \n"," concatenate_160 (Concatenate)  (None, 1, 1, 960)    0           ['dropout_294[0][0]',            \n","                                                                  'concatenate_159[0][0]']        \n","                                                                                                  \n"," batch_normalization_280 (Batch  (None, 1, 1, 960)   3840        ['concatenate_160[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_315 (ReLU)               (None, 1, 1, 960)    0           ['batch_normalization_280[0][0]']\n","                                                                                                  \n"," conv2d_344 (Conv2D)            (None, 1, 1, 128)    123008      ['re_lu_315[0][0]']              \n","                                                                                                  \n"," dropout_295 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_344[0][0]']             \n","                                                                                                  \n"," batch_normalization_281 (Batch  (None, 1, 1, 128)   512         ['dropout_295[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_316 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_281[0][0]']\n","                                                                                                  \n"," conv2d_345 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_316[0][0]']              \n","                                                                                                  \n"," dropout_296 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_345[0][0]']             \n","                                                                                                  \n"," concatenate_161 (Concatenate)  (None, 1, 1, 992)    0           ['dropout_296[0][0]',            \n","                                                                  'concatenate_160[0][0]']        \n","                                                                                                  \n"," batch_normalization_282 (Batch  (None, 1, 1, 992)   3968        ['concatenate_161[0][0]']        \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_317 (ReLU)               (None, 1, 1, 992)    0           ['batch_normalization_282[0][0]']\n","                                                                                                  \n"," conv2d_346 (Conv2D)            (None, 1, 1, 128)    127104      ['re_lu_317[0][0]']              \n","                                                                                                  \n"," dropout_297 (Dropout)          (None, 1, 1, 128)    0           ['conv2d_346[0][0]']             \n","                                                                                                  \n"," batch_normalization_283 (Batch  (None, 1, 1, 128)   512         ['dropout_297[0][0]']            \n"," Normalization)                                                                                   \n","                                                                                                  \n"," re_lu_318 (ReLU)               (None, 1, 1, 128)    0           ['batch_normalization_283[0][0]']\n","                                                                                                  \n"," conv2d_347 (Conv2D)            (None, 1, 1, 32)     36896       ['re_lu_318[0][0]']              \n","                                                                                                  \n"," dropout_298 (Dropout)          (None, 1, 1, 32)     0           ['conv2d_347[0][0]']             \n","                                                                                                  \n"," concatenate_162 (Concatenate)  (None, 1, 1, 1024)   0           ['dropout_298[0][0]',            \n","                                                                  'concatenate_161[0][0]']        \n","                                                                                                  \n"," global_average_pooling2d_8 (Gl  (None, 1024)        0           ['concatenate_162[0][0]']        \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," flatten_12 (Flatten)           (None, 1024)         0           ['global_average_pooling2d_8[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dense_20 (Dense)               (None, 10)           10250       ['flatten_12[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,053,642\n","Trainable params: 6,972,170\n","Non-trainable params: 81,472\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"7F3HZ0nWShJX"},"source":["from tensorflow.python.keras.utils.vis_utils import model_to_dot\n","from IPython.display import SVG\n","import pydot\n","import graphviz\n","\n","SVG(model_to_dot(\n","    model, show_shapes=True, show_layer_names=True, rankdir='TB',\n","    expand_nested=False, dpi=60, subgraph=False\n",").create(prog='dot',format='svg'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfTWXmHCtxuM"},"source":["# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","test_acc_metric = keras.metrics.SparseCategoricalAccuracy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8s9yZo3Nupf"},"source":["## **growth rate-24 without dropout and data augmentation--- Training acc: 0.9783 Test acc: 0.7023**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfuFXXdkt7x3","outputId":"35e59cb2-17b3-4e5d-9070-9e8a6165383c"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Validation acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 2.4178\n","Training loss (for one batch) at step 200: 1.2649\n","Training acc over epoch: 0.5004\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 1.0503\n","Training loss (for one batch) at step 200: 1.2342\n","Training acc over epoch: 0.6260\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 1.0458\n","Training loss (for one batch) at step 200: 1.0184\n","Training acc over epoch: 0.6885\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 0.8029\n","Training loss (for one batch) at step 200: 0.8084\n","Training acc over epoch: 0.7274\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 0.6412\n","Training loss (for one batch) at step 200: 0.6222\n","Training acc over epoch: 0.7567\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 0.5394\n","Training loss (for one batch) at step 200: 0.5788\n","Training acc over epoch: 0.7813\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 0.3362\n","Training loss (for one batch) at step 200: 0.4546\n","Training acc over epoch: 0.8045\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 0.5063\n","Training loss (for one batch) at step 200: 0.6278\n","Training acc over epoch: 0.8251\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 0.4920\n","Training loss (for one batch) at step 200: 0.6388\n","Training acc over epoch: 0.8391\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 0.2836\n","Training loss (for one batch) at step 200: 0.3932\n","Training acc over epoch: 0.8557\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 0.3207\n","Training loss (for one batch) at step 200: 0.3172\n","Training acc over epoch: 0.8701\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 0.3550\n","Training loss (for one batch) at step 200: 0.2783\n","Training acc over epoch: 0.8852\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 0.1785\n","Training loss (for one batch) at step 200: 0.2314\n","Training acc over epoch: 0.8978\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 0.2440\n","Training loss (for one batch) at step 200: 0.2242\n","Training acc over epoch: 0.9056\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 0.1597\n","Training loss (for one batch) at step 200: 0.2054\n","Training acc over epoch: 0.9187\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 0.1402\n","Training loss (for one batch) at step 200: 0.1739\n","Training acc over epoch: 0.9219\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 0.0979\n","Training loss (for one batch) at step 200: 0.2148\n","Training acc over epoch: 0.9327\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 0.1418\n","Training loss (for one batch) at step 200: 0.2128\n","Training acc over epoch: 0.9354\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 0.2397\n","Training loss (for one batch) at step 200: 0.1917\n","Training acc over epoch: 0.9420\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.1142\n","Training loss (for one batch) at step 200: 0.1266\n","Training acc over epoch: 0.9457\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.1334\n","Training loss (for one batch) at step 200: 0.0874\n","Training acc over epoch: 0.9512\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 0.1423\n","Training loss (for one batch) at step 200: 0.1912\n","Training acc over epoch: 0.9528\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.0875\n","Training loss (for one batch) at step 200: 0.1423\n","Training acc over epoch: 0.9587\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.1277\n","Training loss (for one batch) at step 200: 0.1203\n","Training acc over epoch: 0.9558\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.1015\n","Training loss (for one batch) at step 200: 0.0781\n","Training acc over epoch: 0.9603\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.0801\n","Training loss (for one batch) at step 200: 0.0553\n","Training acc over epoch: 0.9641\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.1564\n","Training loss (for one batch) at step 200: 0.1168\n","Training acc over epoch: 0.9667\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 0.0964\n","Training loss (for one batch) at step 200: 0.1178\n","Training acc over epoch: 0.9649\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.0655\n","Training loss (for one batch) at step 200: 0.1795\n","Training acc over epoch: 0.9669\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.0681\n","Training loss (for one batch) at step 200: 0.0387\n","Training acc over epoch: 0.9707\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.0559\n","Training loss (for one batch) at step 200: 0.0849\n","Training acc over epoch: 0.9683\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.0480\n","Training loss (for one batch) at step 200: 0.0840\n","Training acc over epoch: 0.9693\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.0398\n","Training loss (for one batch) at step 200: 0.0442\n","Training acc over epoch: 0.9732\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.0627\n","Training loss (for one batch) at step 200: 0.1267\n","Training acc over epoch: 0.9690\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.0674\n","Training loss (for one batch) at step 200: 0.0423\n","Training acc over epoch: 0.9751\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.0568\n","Training loss (for one batch) at step 200: 0.0495\n","Training acc over epoch: 0.9765\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.0213\n","Training loss (for one batch) at step 200: 0.1154\n","Training acc over epoch: 0.9713\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.0692\n","Training loss (for one batch) at step 200: 0.0431\n","Training acc over epoch: 0.9776\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.0336\n","Training loss (for one batch) at step 200: 0.0208\n","Training acc over epoch: 0.9768\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.0174\n","Training loss (for one batch) at step 200: 0.0399\n","Training acc over epoch: 0.9751\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.0415\n","Training loss (for one batch) at step 200: 0.0308\n","Training acc over epoch: 0.9769\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.0610\n","Training loss (for one batch) at step 200: 0.0191\n","Training acc over epoch: 0.9793\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.0624\n","Training loss (for one batch) at step 200: 0.1432\n","Training acc over epoch: 0.9766\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.0293\n","Training loss (for one batch) at step 200: 0.0945\n","Training acc over epoch: 0.9785\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.0489\n","Training loss (for one batch) at step 200: 0.0245\n","Training acc over epoch: 0.9803\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.0175\n","Training loss (for one batch) at step 200: 0.0313\n","Training acc over epoch: 0.9808\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.0551\n","Training loss (for one batch) at step 200: 0.0229\n","Training acc over epoch: 0.9805\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.0491\n","Training loss (for one batch) at step 200: 0.0672\n","Training acc over epoch: 0.9789\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.0512\n","Training loss (for one batch) at step 200: 0.0512\n","Training acc over epoch: 0.9808\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.0750\n","Training loss (for one batch) at step 200: 0.0581\n","Training acc over epoch: 0.9783\n","Validation acc: 0.7023\n","Time taken: 12.24s\n"]}]},{"cell_type":"code","metadata":{"id":"81iiDneOxG_3"},"source":["%load_ext tensorboard\n","%tensorboard --logdir logs/func"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lDRE8t3-vaGi"},"source":["## **growth rate 32 without dropout and data augmentation --Training acc: 0.9498 Test acc: 0.7779**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJ75jLRBu-2N","outputId":"a9412027-3055-453d-db84-3bffd020d02c"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Validation acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 0.2480\n","Training loss (for one batch) at step 200: 0.2737\n","Training acc over epoch: 0.9145\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 0.1943\n","Training loss (for one batch) at step 200: 0.2631\n","Training acc over epoch: 0.9176\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 0.1921\n","Training loss (for one batch) at step 200: 0.2268\n","Training acc over epoch: 0.9194\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 0.1605\n","Training loss (for one batch) at step 200: 0.1699\n","Training acc over epoch: 0.9193\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 0.3000\n","Training loss (for one batch) at step 200: 0.1382\n","Training acc over epoch: 0.9204\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 0.1875\n","Training loss (for one batch) at step 200: 0.2878\n","Training acc over epoch: 0.9227\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 0.1889\n","Training loss (for one batch) at step 200: 0.2564\n","Training acc over epoch: 0.9232\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 0.2391\n","Training loss (for one batch) at step 200: 0.2389\n","Training acc over epoch: 0.9226\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 0.1681\n","Training loss (for one batch) at step 200: 0.1577\n","Training acc over epoch: 0.9240\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 0.1667\n","Training loss (for one batch) at step 200: 0.1956\n","Training acc over epoch: 0.9252\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 0.1997\n","Training loss (for one batch) at step 200: 0.2298\n","Training acc over epoch: 0.9271\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 0.2670\n","Training loss (for one batch) at step 200: 0.1132\n","Training acc over epoch: 0.9285\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 0.2429\n","Training loss (for one batch) at step 200: 0.1264\n","Training acc over epoch: 0.9301\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 0.1975\n","Training loss (for one batch) at step 200: 0.2049\n","Training acc over epoch: 0.9328\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 0.1498\n","Training loss (for one batch) at step 200: 0.2328\n","Training acc over epoch: 0.9278\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 0.3015\n","Training loss (for one batch) at step 200: 0.0670\n","Training acc over epoch: 0.9342\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 0.0990\n","Training loss (for one batch) at step 200: 0.1805\n","Training acc over epoch: 0.9329\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 0.2372\n","Training loss (for one batch) at step 200: 0.1976\n","Training acc over epoch: 0.9327\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 0.1491\n","Training loss (for one batch) at step 200: 0.2337\n","Training acc over epoch: 0.9323\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.1609\n","Training loss (for one batch) at step 200: 0.1969\n","Training acc over epoch: 0.9345\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.1875\n","Training loss (for one batch) at step 200: 0.1565\n","Training acc over epoch: 0.9340\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 0.1549\n","Training loss (for one batch) at step 200: 0.2250\n","Training acc over epoch: 0.9347\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.1032\n","Training loss (for one batch) at step 200: 0.1615\n","Training acc over epoch: 0.9365\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.1093\n","Training loss (for one batch) at step 200: 0.1159\n","Training acc over epoch: 0.9376\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.1076\n","Training loss (for one batch) at step 200: 0.2300\n","Training acc over epoch: 0.9386\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.1584\n","Training loss (for one batch) at step 200: 0.2940\n","Training acc over epoch: 0.9387\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.1529\n","Training loss (for one batch) at step 200: 0.1514\n","Training acc over epoch: 0.9380\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 0.1334\n","Training loss (for one batch) at step 200: 0.1696\n","Training acc over epoch: 0.9383\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.1153\n","Training loss (for one batch) at step 200: 0.1965\n","Training acc over epoch: 0.9407\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.2295\n","Training loss (for one batch) at step 200: 0.1962\n","Training acc over epoch: 0.9400\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.1298\n","Training loss (for one batch) at step 200: 0.1655\n","Training acc over epoch: 0.9400\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.1116\n","Training loss (for one batch) at step 200: 0.1625\n","Training acc over epoch: 0.9423\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.1772\n","Training loss (for one batch) at step 200: 0.0522\n","Training acc over epoch: 0.9432\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.1441\n","Training loss (for one batch) at step 200: 0.1330\n","Training acc over epoch: 0.9433\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.1738\n","Training loss (for one batch) at step 200: 0.2316\n","Training acc over epoch: 0.9435\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.1949\n","Training loss (for one batch) at step 200: 0.1506\n","Training acc over epoch: 0.9455\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.2109\n","Training loss (for one batch) at step 200: 0.2023\n","Training acc over epoch: 0.9453\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.0938\n","Training loss (for one batch) at step 200: 0.1856\n","Training acc over epoch: 0.9458\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.1306\n","Training loss (for one batch) at step 200: 0.1375\n","Training acc over epoch: 0.9470\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.1707\n","Training loss (for one batch) at step 200: 0.1141\n","Training acc over epoch: 0.9457\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.2013\n","Training loss (for one batch) at step 200: 0.2034\n","Training acc over epoch: 0.9482\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.0861\n","Training loss (for one batch) at step 200: 0.0445\n","Training acc over epoch: 0.9461\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.0883\n","Training loss (for one batch) at step 200: 0.0799\n","Training acc over epoch: 0.9489\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.1049\n","Training loss (for one batch) at step 200: 0.2104\n","Training acc over epoch: 0.9474\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.1720\n","Training loss (for one batch) at step 200: 0.1995\n","Training acc over epoch: 0.9497\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.1116\n","Training loss (for one batch) at step 200: 0.1141\n","Training acc over epoch: 0.9499\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.1430\n","Training loss (for one batch) at step 200: 0.1091\n","Training acc over epoch: 0.9490\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.1099\n","Training loss (for one batch) at step 200: 0.0842\n","Training acc over epoch: 0.9495\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.1511\n","Training loss (for one batch) at step 200: 0.1426\n","Training acc over epoch: 0.9532\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.2427\n","Training loss (for one batch) at step 200: 0.1507\n","Training acc over epoch: 0.9498\n","Validation acc: 0.7779\n","Time taken: 19.56s\n"]}]},{"cell_type":"markdown","metadata":{"id":"ktDKVurVNNcr"},"source":["## **growth rate-32, dropout-0.2 and with data augmentation--Training acc: 0.915 Test acc: 0.8022**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArzLuR_31l2c","outputId":"be369afc-03c0-4333-f879-1886d562d443"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Validation acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 2.4580\n","Training loss (for one batch) at step 200: 1.3215\n","Training acc over epoch: 0.4541\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 1.2222\n","Training loss (for one batch) at step 200: 1.1570\n","Training acc over epoch: 0.5846\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 0.9636\n","Training loss (for one batch) at step 200: 1.0707\n","Training acc over epoch: 0.6476\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 0.9656\n","Training loss (for one batch) at step 200: 0.8065\n","Training acc over epoch: 0.6809\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 1.0205\n","Training loss (for one batch) at step 200: 0.8854\n","Training acc over epoch: 0.7071\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 0.7880\n","Training loss (for one batch) at step 200: 0.7674\n","Training acc over epoch: 0.7269\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 0.7082\n","Training loss (for one batch) at step 200: 0.5656\n","Training acc over epoch: 0.7418\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 0.6327\n","Training loss (for one batch) at step 200: 0.7945\n","Training acc over epoch: 0.7528\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 0.6340\n","Training loss (for one batch) at step 200: 0.7466\n","Training acc over epoch: 0.7664\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 0.6220\n","Training loss (for one batch) at step 200: 0.6277\n","Training acc over epoch: 0.7781\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 0.7038\n","Training loss (for one batch) at step 200: 0.5968\n","Training acc over epoch: 0.7845\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 0.5165\n","Training loss (for one batch) at step 200: 0.6074\n","Training acc over epoch: 0.7925\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 0.4956\n","Training loss (for one batch) at step 200: 0.5049\n","Training acc over epoch: 0.7991\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 0.5015\n","Training loss (for one batch) at step 200: 0.4394\n","Training acc over epoch: 0.8084\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 0.6289\n","Training loss (for one batch) at step 200: 0.4920\n","Training acc over epoch: 0.8135\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 0.5083\n","Training loss (for one batch) at step 200: 0.5591\n","Training acc over epoch: 0.8196\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 0.5400\n","Training loss (for one batch) at step 200: 0.5204\n","Training acc over epoch: 0.8262\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 0.5257\n","Training loss (for one batch) at step 200: 0.4030\n","Training acc over epoch: 0.8296\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 0.4485\n","Training loss (for one batch) at step 200: 0.5531\n","Training acc over epoch: 0.8347\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.3972\n","Training loss (for one batch) at step 200: 0.5060\n","Training acc over epoch: 0.8405\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.3822\n","Training loss (for one batch) at step 200: 0.3474\n","Training acc over epoch: 0.8423\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 0.4081\n","Training loss (for one batch) at step 200: 0.3782\n","Training acc over epoch: 0.8486\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.4480\n","Training loss (for one batch) at step 200: 0.2595\n","Training acc over epoch: 0.8531\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.4528\n","Training loss (for one batch) at step 200: 0.4725\n","Training acc over epoch: 0.8561\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.3623\n","Training loss (for one batch) at step 200: 0.3000\n","Training acc over epoch: 0.8588\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.4044\n","Training loss (for one batch) at step 200: 0.4282\n","Training acc over epoch: 0.8629\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.2532\n","Training loss (for one batch) at step 200: 0.4295\n","Training acc over epoch: 0.8677\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 0.3616\n","Training loss (for one batch) at step 200: 0.5544\n","Training acc over epoch: 0.8697\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.2296\n","Training loss (for one batch) at step 200: 0.3236\n","Training acc over epoch: 0.8744\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.4511\n","Training loss (for one batch) at step 200: 0.4315\n","Training acc over epoch: 0.8763\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.1931\n","Training loss (for one batch) at step 200: 0.3093\n","Training acc over epoch: 0.8791\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.4351\n","Training loss (for one batch) at step 200: 0.2895\n","Training acc over epoch: 0.8817\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.2400\n","Training loss (for one batch) at step 200: 0.3192\n","Training acc over epoch: 0.8822\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.3241\n","Training loss (for one batch) at step 200: 0.4450\n","Training acc over epoch: 0.8870\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.2767\n","Training loss (for one batch) at step 200: 0.2940\n","Training acc over epoch: 0.8868\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.1669\n","Training loss (for one batch) at step 200: 0.3324\n","Training acc over epoch: 0.8909\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.2738\n","Training loss (for one batch) at step 200: 0.2890\n","Training acc over epoch: 0.8943\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.3014\n","Training loss (for one batch) at step 200: 0.2994\n","Training acc over epoch: 0.8940\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.2909\n","Training loss (for one batch) at step 200: 0.1498\n","Training acc over epoch: 0.8953\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.2888\n","Training loss (for one batch) at step 200: 0.2173\n","Training acc over epoch: 0.8996\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.2184\n","Training loss (for one batch) at step 200: 0.3615\n","Training acc over epoch: 0.9003\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.1922\n","Training loss (for one batch) at step 200: 0.4221\n","Training acc over epoch: 0.9013\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.2955\n","Training loss (for one batch) at step 200: 0.2648\n","Training acc over epoch: 0.9035\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.2065\n","Training loss (for one batch) at step 200: 0.4158\n","Training acc over epoch: 0.9070\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.2934\n","Training loss (for one batch) at step 200: 0.3219\n","Training acc over epoch: 0.9044\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.1476\n","Training loss (for one batch) at step 200: 0.1882\n","Training acc over epoch: 0.9107\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.2069\n","Training loss (for one batch) at step 200: 0.2494\n","Training acc over epoch: 0.9115\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.2644\n","Training loss (for one batch) at step 200: 0.2245\n","Training acc over epoch: 0.9128\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.2419\n","Training loss (for one batch) at step 200: 0.1343\n","Training acc over epoch: 0.9132\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.2008\n","Training loss (for one batch) at step 200: 0.1662\n","Training acc over epoch: 0.9151\n","Validation acc: 0.8022\n","Time taken: 19.44s\n"]}]},{"cell_type":"markdown","metadata":{"id":"gVVhn9ZGRHzt"},"source":["## **growth rate-32 without batch and bottleneck layer with drop out and data augmentation--Training acc: 0.7846 Test acc: 0.7060**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJgLuzYEX9VI","outputId":"60c2090a-c423-47e1-dd91-6fac0d99b75b"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Test acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 115.0205\n","Training loss (for one batch) at step 200: 1.9857\n","Training acc over epoch: 0.2551\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 1.9081\n","Training loss (for one batch) at step 200: 1.5382\n","Training acc over epoch: 0.3710\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 1.7053\n","Training loss (for one batch) at step 200: 1.6782\n","Training acc over epoch: 0.4184\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 1.5528\n","Training loss (for one batch) at step 200: 1.5269\n","Training acc over epoch: 0.4466\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 1.3650\n","Training loss (for one batch) at step 200: 1.5948\n","Training acc over epoch: 0.4711\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 1.2683\n","Training loss (for one batch) at step 200: 1.3915\n","Training acc over epoch: 0.4913\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 1.1629\n","Training loss (for one batch) at step 200: 1.2803\n","Training acc over epoch: 0.5095\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 1.4561\n","Training loss (for one batch) at step 200: 1.4889\n","Training acc over epoch: 0.5226\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 1.4233\n","Training loss (for one batch) at step 200: 1.1729\n","Training acc over epoch: 0.5381\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 1.1951\n","Training loss (for one batch) at step 200: 1.1202\n","Training acc over epoch: 0.5584\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 1.2605\n","Training loss (for one batch) at step 200: 1.1062\n","Training acc over epoch: 0.5665\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 1.0288\n","Training loss (for one batch) at step 200: 1.0363\n","Training acc over epoch: 0.5821\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 0.9836\n","Training loss (for one batch) at step 200: 0.9786\n","Training acc over epoch: 0.5970\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 1.1343\n","Training loss (for one batch) at step 200: 0.9954\n","Training acc over epoch: 0.6008\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 1.0382\n","Training loss (for one batch) at step 200: 0.9731\n","Training acc over epoch: 0.6119\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 1.1599\n","Training loss (for one batch) at step 200: 1.0892\n","Training acc over epoch: 0.6211\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 1.1255\n","Training loss (for one batch) at step 200: 1.0603\n","Training acc over epoch: 0.6342\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 1.0216\n","Training loss (for one batch) at step 200: 1.0121\n","Training acc over epoch: 0.6390\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 1.1828\n","Training loss (for one batch) at step 200: 1.1210\n","Training acc over epoch: 0.6498\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.9354\n","Training loss (for one batch) at step 200: 0.9273\n","Training acc over epoch: 0.6639\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.7742\n","Training loss (for one batch) at step 200: 0.8650\n","Training acc over epoch: 0.6678\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 1.1197\n","Training loss (for one batch) at step 200: 0.7726\n","Training acc over epoch: 0.6797\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.9611\n","Training loss (for one batch) at step 200: 0.8846\n","Training acc over epoch: 0.6891\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.7728\n","Training loss (for one batch) at step 200: 0.9024\n","Training acc over epoch: 0.6966\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.7065\n","Training loss (for one batch) at step 200: 0.7309\n","Training acc over epoch: 0.7070\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.6682\n","Training loss (for one batch) at step 200: 0.7940\n","Training acc over epoch: 0.7069\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.8305\n","Training loss (for one batch) at step 200: 0.7020\n","Training acc over epoch: 0.7124\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 1.0691\n","Training loss (for one batch) at step 200: 0.8970\n","Training acc over epoch: 0.7196\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.8692\n","Training loss (for one batch) at step 200: 0.7991\n","Training acc over epoch: 0.7182\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.7198\n","Training loss (for one batch) at step 200: 0.7700\n","Training acc over epoch: 0.7320\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.7593\n","Training loss (for one batch) at step 200: 0.9089\n","Training acc over epoch: 0.7334\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.7730\n","Training loss (for one batch) at step 200: 0.9091\n","Training acc over epoch: 0.7304\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.8183\n","Training loss (for one batch) at step 200: 0.6722\n","Training acc over epoch: 0.7407\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.7234\n","Training loss (for one batch) at step 200: 0.7450\n","Training acc over epoch: 0.7464\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.5920\n","Training loss (for one batch) at step 200: 0.6222\n","Training acc over epoch: 0.7437\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.7191\n","Training loss (for one batch) at step 200: 0.6963\n","Training acc over epoch: 0.7495\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.7624\n","Training loss (for one batch) at step 200: 0.7808\n","Training acc over epoch: 0.7525\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.5803\n","Training loss (for one batch) at step 200: 0.7169\n","Training acc over epoch: 0.7597\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.7205\n","Training loss (for one batch) at step 200: 0.6978\n","Training acc over epoch: 0.7586\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.6642\n","Training loss (for one batch) at step 200: 0.6415\n","Training acc over epoch: 0.7623\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.7106\n","Training loss (for one batch) at step 200: 0.7876\n","Training acc over epoch: 0.7572\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.5578\n","Training loss (for one batch) at step 200: 0.6078\n","Training acc over epoch: 0.7672\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.5044\n","Training loss (for one batch) at step 200: 0.5705\n","Training acc over epoch: 0.7746\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.7299\n","Training loss (for one batch) at step 200: 0.6977\n","Training acc over epoch: 0.7693\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.4460\n","Training loss (for one batch) at step 200: 0.6238\n","Training acc over epoch: 0.7671\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.5561\n","Training loss (for one batch) at step 200: 0.6274\n","Training acc over epoch: 0.7758\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.4430\n","Training loss (for one batch) at step 200: 0.7251\n","Training acc over epoch: 0.7807\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.4169\n","Training loss (for one batch) at step 200: 0.7800\n","Training acc over epoch: 0.7807\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.6739\n","Training loss (for one batch) at step 200: 0.5499\n","Training acc over epoch: 0.7797\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.5372\n","Training loss (for one batch) at step 200: 0.5373\n","Training acc over epoch: 0.7846\n","Test acc: 0.7060\n","Time taken: 10.07s\n"]}]},{"cell_type":"code","metadata":{"id":"opbd9d0cYlkA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqAeIxPoRPBU"},"source":["## **growth rate-32 without batch and bottleneck layer with dropout-0.2 and data augmentation for dense block [3,6,12]--Training acc: 0.8001 Test acc: 0.7005**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gJpsb7yZadQ","outputId":"c262fbd3-14cd-4890-8bd4-d8d3b500d545"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Test acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 19.2920\n","Training loss (for one batch) at step 200: 1.7106\n","Training acc over epoch: 0.3333\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 1.5611\n","Training loss (for one batch) at step 200: 1.4488\n","Training acc over epoch: 0.4618\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 1.3985\n","Training loss (for one batch) at step 200: 1.4555\n","Training acc over epoch: 0.5106\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 1.3388\n","Training loss (for one batch) at step 200: 1.1910\n","Training acc over epoch: 0.5459\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 1.0767\n","Training loss (for one batch) at step 200: 1.1924\n","Training acc over epoch: 0.5674\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 1.1860\n","Training loss (for one batch) at step 200: 1.0173\n","Training acc over epoch: 0.5873\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 1.0267\n","Training loss (for one batch) at step 200: 1.0878\n","Training acc over epoch: 0.6086\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 1.0069\n","Training loss (for one batch) at step 200: 0.8785\n","Training acc over epoch: 0.6301\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 1.0772\n","Training loss (for one batch) at step 200: 1.0383\n","Training acc over epoch: 0.6409\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 1.0734\n","Training loss (for one batch) at step 200: 0.8634\n","Training acc over epoch: 0.6506\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 0.9821\n","Training loss (for one batch) at step 200: 0.9425\n","Training acc over epoch: 0.6622\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 0.9536\n","Training loss (for one batch) at step 200: 0.8745\n","Training acc over epoch: 0.6745\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 1.0225\n","Training loss (for one batch) at step 200: 0.8244\n","Training acc over epoch: 0.6791\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 0.9387\n","Training loss (for one batch) at step 200: 1.0673\n","Training acc over epoch: 0.6878\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 0.8265\n","Training loss (for one batch) at step 200: 0.7857\n","Training acc over epoch: 0.6953\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 0.7627\n","Training loss (for one batch) at step 200: 0.7427\n","Training acc over epoch: 0.7060\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 0.7983\n","Training loss (for one batch) at step 200: 0.8382\n","Training acc over epoch: 0.7069\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 0.8163\n","Training loss (for one batch) at step 200: 0.9317\n","Training acc over epoch: 0.7169\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 0.7900\n","Training loss (for one batch) at step 200: 0.6658\n","Training acc over epoch: 0.7241\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.7912\n","Training loss (for one batch) at step 200: 0.7150\n","Training acc over epoch: 0.7269\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.7477\n","Training loss (for one batch) at step 200: 0.6460\n","Training acc over epoch: 0.7372\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 0.7559\n","Training loss (for one batch) at step 200: 0.9529\n","Training acc over epoch: 0.7395\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.6643\n","Training loss (for one batch) at step 200: 0.6755\n","Training acc over epoch: 0.7433\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.6771\n","Training loss (for one batch) at step 200: 0.7405\n","Training acc over epoch: 0.7439\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.8252\n","Training loss (for one batch) at step 200: 0.7809\n","Training acc over epoch: 0.7424\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.5659\n","Training loss (for one batch) at step 200: 0.7550\n","Training acc over epoch: 0.7579\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.6734\n","Training loss (for one batch) at step 200: 0.7774\n","Training acc over epoch: 0.7569\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 0.6065\n","Training loss (for one batch) at step 200: 0.7034\n","Training acc over epoch: 0.7601\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.7980\n","Training loss (for one batch) at step 200: 0.6749\n","Training acc over epoch: 0.7648\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.7420\n","Training loss (for one batch) at step 200: 0.5395\n","Training acc over epoch: 0.7646\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.6656\n","Training loss (for one batch) at step 200: 0.6754\n","Training acc over epoch: 0.7703\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.5747\n","Training loss (for one batch) at step 200: 0.6066\n","Training acc over epoch: 0.7722\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.6435\n","Training loss (for one batch) at step 200: 0.6760\n","Training acc over epoch: 0.7727\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.7676\n","Training loss (for one batch) at step 200: 0.6426\n","Training acc over epoch: 0.7767\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.5456\n","Training loss (for one batch) at step 200: 0.5316\n","Training acc over epoch: 0.7789\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.7238\n","Training loss (for one batch) at step 200: 0.6183\n","Training acc over epoch: 0.7792\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.6568\n","Training loss (for one batch) at step 200: 0.5739\n","Training acc over epoch: 0.7829\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.4961\n","Training loss (for one batch) at step 200: 0.4186\n","Training acc over epoch: 0.7853\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.6412\n","Training loss (for one batch) at step 200: 0.6279\n","Training acc over epoch: 0.7900\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.7181\n","Training loss (for one batch) at step 200: 0.6791\n","Training acc over epoch: 0.7896\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.6089\n","Training loss (for one batch) at step 200: 0.6750\n","Training acc over epoch: 0.7895\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.4292\n","Training loss (for one batch) at step 200: 0.5825\n","Training acc over epoch: 0.7863\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.5606\n","Training loss (for one batch) at step 200: 0.5639\n","Training acc over epoch: 0.7932\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.4024\n","Training loss (for one batch) at step 200: 0.6380\n","Training acc over epoch: 0.7972\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.5440\n","Training loss (for one batch) at step 200: 0.6075\n","Training acc over epoch: 0.7946\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.5121\n","Training loss (for one batch) at step 200: 0.6300\n","Training acc over epoch: 0.7956\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.4438\n","Training loss (for one batch) at step 200: 0.6065\n","Training acc over epoch: 0.7941\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.4185\n","Training loss (for one batch) at step 200: 0.5155\n","Training acc over epoch: 0.8009\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.5264\n","Training loss (for one batch) at step 200: 0.6152\n","Training acc over epoch: 0.7990\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.5779\n","Training loss (for one batch) at step 200: 0.5027\n","Training acc over epoch: 0.8001\n","Test acc: 0.7005\n","Time taken: 19.25s\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZriWHW4VZZ-w"},"source":["## **growth rate-32 with batch and bottleneck layer with drop out and data augmention dense layer [3,6,12]**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFcqBEHYZeTO","outputId":"64dc8606-a22e-4c83-a891-2495531146c7"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Test acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 2.4178\n","Training loss (for one batch) at step 200: 1.5706\n","Training acc over epoch: 0.4368\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 1.1944\n","Training loss (for one batch) at step 200: 1.2739\n","Training acc over epoch: 0.5871\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 0.8971\n","Training loss (for one batch) at step 200: 1.1137\n","Training acc over epoch: 0.6448\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 0.8804\n","Training loss (for one batch) at step 200: 0.9684\n","Training acc over epoch: 0.6861\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 0.8766\n","Training loss (for one batch) at step 200: 0.7041\n","Training acc over epoch: 0.7088\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 0.6389\n","Training loss (for one batch) at step 200: 0.7270\n","Training acc over epoch: 0.7278\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 0.6069\n","Training loss (for one batch) at step 200: 0.9064\n","Training acc over epoch: 0.7433\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 0.6691\n","Training loss (for one batch) at step 200: 0.8371\n","Training acc over epoch: 0.7575\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 0.6538\n","Training loss (for one batch) at step 200: 0.7249\n","Training acc over epoch: 0.7685\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 0.5364\n","Training loss (for one batch) at step 200: 0.4937\n","Training acc over epoch: 0.7831\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 0.5774\n","Training loss (for one batch) at step 200: 0.5609\n","Training acc over epoch: 0.7914\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 0.5021\n","Training loss (for one batch) at step 200: 0.5874\n","Training acc over epoch: 0.7992\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 0.5203\n","Training loss (for one batch) at step 200: 0.4383\n","Training acc over epoch: 0.8092\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 0.5250\n","Training loss (for one batch) at step 200: 0.4904\n","Training acc over epoch: 0.8138\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 0.5181\n","Training loss (for one batch) at step 200: 0.4910\n","Training acc over epoch: 0.8217\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 0.5217\n","Training loss (for one batch) at step 200: 0.3685\n","Training acc over epoch: 0.8295\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 0.5188\n","Training loss (for one batch) at step 200: 0.5647\n","Training acc over epoch: 0.8355\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 0.3770\n","Training loss (for one batch) at step 200: 0.3578\n","Training acc over epoch: 0.8414\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 0.4867\n","Training loss (for one batch) at step 200: 0.4490\n","Training acc over epoch: 0.8484\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.3587\n","Training loss (for one batch) at step 200: 0.5223\n","Training acc over epoch: 0.8528\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.4230\n","Training loss (for one batch) at step 200: 0.3781\n","Training acc over epoch: 0.8592\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 0.3675\n","Training loss (for one batch) at step 200: 0.5152\n","Training acc over epoch: 0.8604\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.3958\n","Training loss (for one batch) at step 200: 0.3877\n","Training acc over epoch: 0.8657\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.2884\n","Training loss (for one batch) at step 200: 0.3643\n","Training acc over epoch: 0.8693\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.3417\n","Training loss (for one batch) at step 200: 0.2156\n","Training acc over epoch: 0.8752\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.2604\n","Training loss (for one batch) at step 200: 0.2769\n","Training acc over epoch: 0.8796\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.2329\n","Training loss (for one batch) at step 200: 0.3588\n","Training acc over epoch: 0.8835\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 0.3849\n","Training loss (for one batch) at step 200: 0.2370\n","Training acc over epoch: 0.8849\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.3106\n","Training loss (for one batch) at step 200: 0.2154\n","Training acc over epoch: 0.8891\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.1863\n","Training loss (for one batch) at step 200: 0.3504\n","Training acc over epoch: 0.8943\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.3812\n","Training loss (for one batch) at step 200: 0.2092\n","Training acc over epoch: 0.8933\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.2839\n","Training loss (for one batch) at step 200: 0.2701\n","Training acc over epoch: 0.9001\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.2129\n","Training loss (for one batch) at step 200: 0.1763\n","Training acc over epoch: 0.9038\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.2236\n","Training loss (for one batch) at step 200: 0.2675\n","Training acc over epoch: 0.9025\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.2217\n","Training loss (for one batch) at step 200: 0.2626\n","Training acc over epoch: 0.9059\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.2222\n","Training loss (for one batch) at step 200: 0.3976\n","Training acc over epoch: 0.9109\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.2455\n","Training loss (for one batch) at step 200: 0.2658\n","Training acc over epoch: 0.9135\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.2271\n","Training loss (for one batch) at step 200: 0.3425\n","Training acc over epoch: 0.9144\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.3357\n","Training loss (for one batch) at step 200: 0.3062\n","Training acc over epoch: 0.9152\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.1644\n","Training loss (for one batch) at step 200: 0.1734\n","Training acc over epoch: 0.9168\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.2330\n","Training loss (for one batch) at step 200: 0.1859\n","Training acc over epoch: 0.9216\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.2185\n","Training loss (for one batch) at step 200: 0.1895\n","Training acc over epoch: 0.9234\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.1134\n","Training loss (for one batch) at step 200: 0.2025\n","Training acc over epoch: 0.9227\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.1441\n","Training loss (for one batch) at step 200: 0.1973\n","Training acc over epoch: 0.9263\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.1854\n","Training loss (for one batch) at step 200: 0.1679\n","Training acc over epoch: 0.9272\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.1776\n","Training loss (for one batch) at step 200: 0.2407\n","Training acc over epoch: 0.9279\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.1758\n","Training loss (for one batch) at step 200: 0.1555\n","Training acc over epoch: 0.9295\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.0806\n","Training loss (for one batch) at step 200: 0.1889\n","Training acc over epoch: 0.9332\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.0986\n","Training loss (for one batch) at step 200: 0.2189\n","Training acc over epoch: 0.9322\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.1853\n","Training loss (for one batch) at step 200: 0.2642\n","Training acc over epoch: 0.9326\n","Test acc: 0.7583\n","Time taken: 32.21s\n"]}]},{"cell_type":"markdown","metadata":{"id":"gpb6wRf3pUkp"},"source":["## **growth rate-32 with batch and bottleneck layer with drop out and data augmention dense layer DenseNet-121 [6,12,24,16]**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CR8JizE4pje0","outputId":"a74b9a0d-987c-4602-e43d-d6ac5c6e5662"},"source":["import time\n","\n","\n","epochs = 50\n","for epoch in range(epochs):\n","    print(\"\\nStart of epoch %d\" % (epoch,))\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        \n","        loss_value = train_step(x_batch_train, y_batch_train)\n","         # Log every 200 batches.\n","        if step % 200 == 0:\n","            print(\n","                \"Training loss (for one batch) at step %d: %.4f\"\n","                % (step, float(loss_value))\n","            )\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in test_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","\n","    test_acc = test_acc_metric.result()\n","    test_acc_metric.reset_states()\n","print(\"Test acc: %.4f\" % (float(test_acc),))\n","print(\"Time taken: %.2fs\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","Training loss (for one batch) at step 0: 2.4802\n","Training loss (for one batch) at step 200: 1.6307\n","Training acc over epoch: 0.4030\n","\n","Start of epoch 1\n","Training loss (for one batch) at step 0: 1.2116\n","Training loss (for one batch) at step 200: 1.4177\n","Training acc over epoch: 0.5611\n","\n","Start of epoch 2\n","Training loss (for one batch) at step 0: 1.2640\n","Training loss (for one batch) at step 200: 0.9875\n","Training acc over epoch: 0.6333\n","\n","Start of epoch 3\n","Training loss (for one batch) at step 0: 0.9368\n","Training loss (for one batch) at step 200: 0.9282\n","Training acc over epoch: 0.6798\n","\n","Start of epoch 4\n","Training loss (for one batch) at step 0: 0.9436\n","Training loss (for one batch) at step 200: 0.7253\n","Training acc over epoch: 0.7141\n","\n","Start of epoch 5\n","Training loss (for one batch) at step 0: 0.7796\n","Training loss (for one batch) at step 200: 0.8034\n","Training acc over epoch: 0.7385\n","\n","Start of epoch 6\n","Training loss (for one batch) at step 0: 0.6545\n","Training loss (for one batch) at step 200: 0.5794\n","Training acc over epoch: 0.7601\n","\n","Start of epoch 7\n","Training loss (for one batch) at step 0: 0.7173\n","Training loss (for one batch) at step 200: 0.8952\n","Training acc over epoch: 0.7642\n","\n","Start of epoch 8\n","Training loss (for one batch) at step 0: 0.7040\n","Training loss (for one batch) at step 200: 0.4872\n","Training acc over epoch: 0.7872\n","\n","Start of epoch 9\n","Training loss (for one batch) at step 0: 0.5844\n","Training loss (for one batch) at step 200: 0.6124\n","Training acc over epoch: 0.7955\n","\n","Start of epoch 10\n","Training loss (for one batch) at step 0: 0.5488\n","Training loss (for one batch) at step 200: 0.6144\n","Training acc over epoch: 0.8113\n","\n","Start of epoch 11\n","Training loss (for one batch) at step 0: 0.5439\n","Training loss (for one batch) at step 200: 0.3411\n","Training acc over epoch: 0.8220\n","\n","Start of epoch 12\n","Training loss (for one batch) at step 0: 0.4304\n","Training loss (for one batch) at step 200: 0.5245\n","Training acc over epoch: 0.8265\n","\n","Start of epoch 13\n","Training loss (for one batch) at step 0: 0.4672\n","Training loss (for one batch) at step 200: 0.4841\n","Training acc over epoch: 0.8371\n","\n","Start of epoch 14\n","Training loss (for one batch) at step 0: 0.5389\n","Training loss (for one batch) at step 200: 0.5695\n","Training acc over epoch: 0.8283\n","\n","Start of epoch 15\n","Training loss (for one batch) at step 0: 0.3760\n","Training loss (for one batch) at step 200: 1.1640\n","Training acc over epoch: 0.8223\n","\n","Start of epoch 16\n","Training loss (for one batch) at step 0: 0.3840\n","Training loss (for one batch) at step 200: 0.5828\n","Training acc over epoch: 0.8436\n","\n","Start of epoch 17\n","Training loss (for one batch) at step 0: 0.4157\n","Training loss (for one batch) at step 200: 0.3631\n","Training acc over epoch: 0.8673\n","\n","Start of epoch 18\n","Training loss (for one batch) at step 0: 0.3641\n","Training loss (for one batch) at step 200: 0.2927\n","Training acc over epoch: 0.8723\n","\n","Start of epoch 19\n","Training loss (for one batch) at step 0: 0.2036\n","Training loss (for one batch) at step 200: 0.3303\n","Training acc over epoch: 0.8814\n","\n","Start of epoch 20\n","Training loss (for one batch) at step 0: 0.2273\n","Training loss (for one batch) at step 200: 0.3358\n","Training acc over epoch: 0.8852\n","\n","Start of epoch 21\n","Training loss (for one batch) at step 0: 0.3044\n","Training loss (for one batch) at step 200: 0.2455\n","Training acc over epoch: 0.8894\n","\n","Start of epoch 22\n","Training loss (for one batch) at step 0: 0.3610\n","Training loss (for one batch) at step 200: 0.4132\n","Training acc over epoch: 0.8933\n","\n","Start of epoch 23\n","Training loss (for one batch) at step 0: 0.2215\n","Training loss (for one batch) at step 200: 0.2246\n","Training acc over epoch: 0.9010\n","\n","Start of epoch 24\n","Training loss (for one batch) at step 0: 0.3359\n","Training loss (for one batch) at step 200: 0.3680\n","Training acc over epoch: 0.9033\n","\n","Start of epoch 25\n","Training loss (for one batch) at step 0: 0.1936\n","Training loss (for one batch) at step 200: 0.2949\n","Training acc over epoch: 0.9080\n","\n","Start of epoch 26\n","Training loss (for one batch) at step 0: 0.2722\n","Training loss (for one batch) at step 200: 0.1769\n","Training acc over epoch: 0.9107\n","\n","Start of epoch 27\n","Training loss (for one batch) at step 0: 0.1717\n","Training loss (for one batch) at step 200: 0.3370\n","Training acc over epoch: 0.9107\n","\n","Start of epoch 28\n","Training loss (for one batch) at step 0: 0.3330\n","Training loss (for one batch) at step 200: 0.2012\n","Training acc over epoch: 0.9170\n","\n","Start of epoch 29\n","Training loss (for one batch) at step 0: 0.2992\n","Training loss (for one batch) at step 200: 0.7317\n","Training acc over epoch: 0.7874\n","\n","Start of epoch 30\n","Training loss (for one batch) at step 0: 0.2949\n","Training loss (for one batch) at step 200: 0.3097\n","Training acc over epoch: 0.8891\n","\n","Start of epoch 31\n","Training loss (for one batch) at step 0: 0.2197\n","Training loss (for one batch) at step 200: 0.2451\n","Training acc over epoch: 0.9170\n","\n","Start of epoch 32\n","Training loss (for one batch) at step 0: 0.1950\n","Training loss (for one batch) at step 200: 0.2340\n","Training acc over epoch: 0.9266\n","\n","Start of epoch 33\n","Training loss (for one batch) at step 0: 0.1152\n","Training loss (for one batch) at step 200: 0.3228\n","Training acc over epoch: 0.9338\n","\n","Start of epoch 34\n","Training loss (for one batch) at step 0: 0.1242\n","Training loss (for one batch) at step 200: 0.2774\n","Training acc over epoch: 0.9116\n","\n","Start of epoch 35\n","Training loss (for one batch) at step 0: 0.1622\n","Training loss (for one batch) at step 200: 0.1792\n","Training acc over epoch: 0.9314\n","\n","Start of epoch 36\n","Training loss (for one batch) at step 0: 0.1156\n","Training loss (for one batch) at step 200: 0.1570\n","Training acc over epoch: 0.9379\n","\n","Start of epoch 37\n","Training loss (for one batch) at step 0: 0.2156\n","Training loss (for one batch) at step 200: 0.2224\n","Training acc over epoch: 0.9391\n","\n","Start of epoch 38\n","Training loss (for one batch) at step 0: 0.2251\n","Training loss (for one batch) at step 200: 0.2304\n","Training acc over epoch: 0.9378\n","\n","Start of epoch 39\n","Training loss (for one batch) at step 0: 0.1381\n","Training loss (for one batch) at step 200: 0.1095\n","Training acc over epoch: 0.9437\n","\n","Start of epoch 40\n","Training loss (for one batch) at step 0: 0.0947\n","Training loss (for one batch) at step 200: 0.1161\n","Training acc over epoch: 0.9435\n","\n","Start of epoch 41\n","Training loss (for one batch) at step 0: 0.1246\n","Training loss (for one batch) at step 200: 0.1303\n","Training acc over epoch: 0.9471\n","\n","Start of epoch 42\n","Training loss (for one batch) at step 0: 0.1165\n","Training loss (for one batch) at step 200: 0.2180\n","Training acc over epoch: 0.9491\n","\n","Start of epoch 43\n","Training loss (for one batch) at step 0: 0.1422\n","Training loss (for one batch) at step 200: 0.2127\n","Training acc over epoch: 0.9475\n","\n","Start of epoch 44\n","Training loss (for one batch) at step 0: 0.2050\n","Training loss (for one batch) at step 200: 0.1444\n","Training acc over epoch: 0.9461\n","\n","Start of epoch 45\n","Training loss (for one batch) at step 0: 0.1404\n","Training loss (for one batch) at step 200: 0.1864\n","Training acc over epoch: 0.9281\n","\n","Start of epoch 46\n","Training loss (for one batch) at step 0: 0.1188\n","Training loss (for one batch) at step 200: 0.0982\n","Training acc over epoch: 0.9494\n","\n","Start of epoch 47\n","Training loss (for one batch) at step 0: 0.1049\n","Training loss (for one batch) at step 200: 0.1365\n","Training acc over epoch: 0.9550\n","\n","Start of epoch 48\n","Training loss (for one batch) at step 0: 0.0862\n","Training loss (for one batch) at step 200: 0.1370\n","Training acc over epoch: 0.9558\n","\n","Start of epoch 49\n","Training loss (for one batch) at step 0: 0.0809\n","Training loss (for one batch) at step 200: 0.1800\n","Training acc over epoch: 0.9498\n","Test acc: 0.7665\n","Time taken: 74.33s\n"]}]}]}