{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5399,"status":"ok","timestamp":1699402694699,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"0CyQfcQ_EZWP","outputId":"c9bbf634-2a2e-4b50-d740-154fa3c87b95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.15,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2023.7.22)\n"]}],"source":["!pip install transformers #installing transformers from hugging face"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7925,"status":"ok","timestamp":1699402724770,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"2BbsZ4AwSfX6","outputId":"49f20716-bc23-4df9-a970-b9a46b4f1462"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.15,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,\u003e=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n","Requirement already satisfied: accelerate\u003e=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate\u003e=0.20.3-\u003etransformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.10-\u003etransformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.10-\u003etransformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.10-\u003etransformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,\u003e=1.10-\u003etransformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[torch]) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[torch]) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch!=1.12.0,\u003e=1.10-\u003etransformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch!=1.12.0,\u003e=1.10-\u003etransformers[torch]) (1.3.0)\n"]}],"source":["!pip install accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6152,"status":"ok","timestamp":1699402700846,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"rkbHMjSREoaj","outputId":"64eb716c-f297-4918-f4a4-3c568594a705"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill\u003c0.3.8,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]\u003c=2023.10.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Requirement already satisfied: huggingface-hub\u003c1.0.0,\u003e=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer\u003c4.0,\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (3.3.2)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2023.7.22)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch) (2.1.3)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2023.3.post1)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch) (1.3.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas-\u003edatasets) (1.16.0)\n"]}],"source":["!pip install datasets torch #Installing datasets from hugging face and torch lib as well"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3255,"status":"ok","timestamp":1699403482046,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"jAirJGbUEzYZ","outputId":"4d4161c8-43af-471f-8dd5-d008ee9a2d77"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:2097: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n","You can remove this warning by passing 'verification_mode=all_checks' instead.\n","  warnings.warn(\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['img', 'label'],\n","    num_rows: 50000\n","})"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset\n","\n","#load the cifar-10 training dataset\n","dataset_train = load_dataset(\"cifar10\",\n","                             split=\"train\",\n","                             ignore_verifications=False)\n","dataset_train"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2393,"status":"ok","timestamp":1699403484434,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"p_NuX_W8Fg0I","outputId":"d13fb60c-9e20-4470-82bd-45692e898313"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:2097: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n","You can remove this warning by passing 'verification_mode=no_checks' instead.\n","  warnings.warn(\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['img', 'label'],\n","    num_rows: 10000\n","})"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["#Load the cifar-10 test dataset\n","dataset_test = load_dataset(\"cifar10\", split=\"test\", ignore_verifications=True)\n","dataset_test"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1699402707436,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"F4rQUyyeGNIL","outputId":"d4cda7aa-238b-4580-9df8-3e45f1be1087"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'datasets.arrow_dataset.Dataset'\u003e\n"]}],"source":["print(type(dataset_test))"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699403484434,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"HaAayjxDGgrU","outputId":"4d0adf28-685e-49b1-8545-cd3eb82872c8"},"outputs":[{"data":{"text/plain":["(10,\n"," ClassLabel(names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], id=None))"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["#Get the number of classes\n","num_classes = len(set(dataset_train[\"label\"]))\n","labels = dataset_train.features[\"label\"]\n","num_classes, labels"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1699403486684,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"RfC9dWpUGooA","outputId":"5bb9ebcb-23d6-46e4-b9be-659b85a7bdd2"},"outputs":[{"data":{"text/plain":["{'img': \u003cPIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32\u003e,\n"," 'label': 0}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["#display the first row in the data. It contains PIL image and label as dict\n","dataset_train[0]"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699403488308,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"ffWLmEcvHaQ2","outputId":"b6d46e9c-a3bb-4898-842f-61f635ba6163"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 32)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH8klEQVR4nHVWS68dRxGuqn7MnDkz53UfwdzEQgSEEsdCihSJLRKIn8KGHX8MwYIVGwRS2CQECSlRYsy149j3Xp/HnDNnpqe7q4rFwcaJRKvVqq6u/r6vululxt//7k/wqiEigAIoIsL/b6r6pvFqqqpw6iIiwiLMzJaIVF8hIiIogL4J9x2y18H/2/UGkyqoIiIi6mnRMvO3UfRNQEQUEURQhdMIAIggJ0u/m8fJLaIiIiKqSq/jAABRTzpO0CmlrutOK6/okEWGIfR9fzz2J1nfEvffE1YiOvntKdMxhO1uwyqXF5feOVXNnF/c3kwn1XQ6PVGKyEnp3fpldzwu54tpVTHzawIBUOHNZt227Wp5Nq1rALAIGFP86vGjJ8+eKMBPHzy8uvd9MrTbt4+vr3/8w3dPClSViG5f3qWURCWEYX7/fozx5ubGWnt5cWG9e3l3e3397+1m3ff9Yr56+MHDqqrss2+ePXn29G5zF9MIgI8ePzoej9O62m7XLze3rDzGIAqL+Xw5n68367v1unT22Pfdfj+m+OLutq4bAQlxfPny7vrJ9RizAEyqJKoIiL/+zW9DGIwhBCAkYS58ASCJx8RSWF8V1aEfp5NyNqu37f4YRkIForPlqu9aREC0232bU64mhUEKfRTRh+89WJyvYorWoS4vz/f7w6HrSu+dIeaUUET1rK6naMcshTUied/tvXf3Lt8qCndo2/bQjmFoCgekVenZGlZpJsVbswYFQYbHT764ubuznty0nPSHHoEuzlZ1WW13u8PYHzkNx76oKlHxjqp66r1HkTT2OeiExTuno2HRUUZQEElZ+NALAiDQYRO33X4YBouZU9dbxKauJmVpLBmLZ8V0lotDe2QW620a03DsIBVGdDf0ibn07rKq31mdDSkdlLPw0/bGGgPKN7t2GOOibqbFxBtrl7OaCSbolmXFKQxJQxxZdV6WYkzLXIlNLKEP63RABTfxdVWy5IOIMzQIl0XZxyAMGYA5xZwzS4rReduNo51eXmx3e0WDzk9KNco5hpggsk6c89aiqvXGkt9qQLJNM00xiUIGUZVuHIuiWDT1vXuXSaTdbEi5tCQ577qui9EaY2LOOStLsiSQQ8o8qcpuyDnngjCmXE/L89XCHw5A5nJ19vxuPYY4KSfOmv44kDVIVLnST4rxeDx2R+9NyGlIkJnttmuFREkF9DAMm/WdClRVrIpi1jQiHFPeh3TMrXG2tHa72XLOInI4dMYSEj57/mI2nzEz9zmEITMXgCpCCARgl1VtWLPJRVl4v1yv1zEmhNEZo4UW5SRkHmMOQ7g4XyHQs5vn/RhndV14e2yPfRj6IYjwbFYfDp0hOlvMC+cRAQhE1BpnACFlNlmaabGom+BDymmIQVl8EVXUO9dMJ6W1YewvLs/b/SGEYQhgyNRVUU8nhMQpzZv5crEahmNOUQFzZs7Jqoh3zhAVRQHAhlg4obJB5wtrDQiCSs4x70MvqsZQ6cx2108KX1YVC6eUAYCZc46SYBxH4QxIqmiMtaoQhhhjGsc0nzUqyHlUFbQ29IO8quWqAISoqqDCGQSHkBIfVDTnbIz1zvX9LrMoKPOpPgpntjlxHHMfRj7I7c1huwlZRzTEmoA5s6ScrbOgYJHcGMFiKux0MgVDIYyl9yIqkp2xgFAUJmURlbqqrDEibFVVQdbr7aNHT1WtpXo2nyyWxMIpR0O2JJwVE6eqqnUEX03h6gKNsc6klKqy6IdRBLyzaMBbG8YYwricz+p6IiLWWHP51vl0Wt3erNfb4/lZUcc8bmFx1VTTlSGSIUuI2veJcMCMFs8Wc1Xw3lRlgYgiqgAGEQgRUVQ5Ze+stZaFrYgwc92UH3308JNPPgcXcRh3Ldl68fDBT5ar2X7b/uOzTwOBEIIntrBgRkVni8nEqwIiiQqRQ0RFAQF1zCoCqog25xxjOgaeNtXVvfNP/v6VFW9NefN19/GfH//8lx++98GDt++/k7MoIGv2zs2bGSBaa5ylnKUfxrqaxLE3gFhWzDnHFMZhv9/t91vbdV3f94eud95Yn5u6GHpzdtFcXV3ePh/++Ie/3X93+Ytf/ezsrAYwqgKoCJiFVSAxHA7Dx3/9bHm+yk+ufzRzzQfvm/NzY33tCrLFGNnu2w0irRZNCOH5dlcvidx40/7r6/UX/ZHHMX/6uT6/u/7ww/dnzXTWzJz1dHqCrIf+sNt3L7cvHl8/cuMYbCjbjf/BfWOMsS6zGGOsMdYYMs6eNZdFUTlvRXiz3m7b9ng8Hocxx/zN86f7v2zPV8vFYsGi3jkEUBVCFGGgCGYYS/hnVr/dVqFXAmadNzNrjFUwMcvtNy8AoPKOiJpqagnfefteXTfdoYt53Ky3Ctq1uy+/fLTZ7VarZemcMfTO1dVsVjOPbbsh8kRgEdViVlnv2nldA4Jtuzal1IeBVClZJZI0JNCwH7rjXjgjQDVx1lrvyFpaLabL+dx7r6DWqGgmgu9dniERCDhUIEKlWVO17ZoQbe0Ii/KsqQjAEACSijIqqKoIWUuAqiCqflLOJwXiOQICABIioKg4QPBeVdAaRAhx5BS9AUkRkSykqIgAyKCKqK+/kCcYUAZFBAKE0+8URQFVFE9RqioMCKJCaBANCZOoApAKiNghDsxiyGaNpKAIgOjIEKpotmhz5owyxOTJO2MVGBRUQFAJIQsjIYugmtPNK0hmQQEkEOH/AIgrr0LkBku7AAAAAElFTkSuQmCC\n","text/plain":["\u003cPIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32\u003e"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["#Display the first image\n","print(dataset_train[0][\"img\"].size)\n","dataset_train[0][\"img\"]"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699403490063,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"fOhcTGjiHzQc","outputId":"3bddf8b4-e7b3-486e-afa6-a775582c012a"},"outputs":[{"data":{"text/plain":["(0, 'airplane')"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["#display the label(which is int) and the class name (in str) for first img\n","dataset_train[0][\"label\"], labels.names[dataset_train[0][\"label\"]]"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1699403492300,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"XBdnHo31IaLc","outputId":"0361d329-3d58-4e57-fe8c-05ae5dc7d3bc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n"]}],"source":["#Loading/Downloading Vision Transformer Pretrained Net that is trained on ImageNet 21K Dataset\n","#This uses 16x16 patches of 224x224 image\n","#This model is from huggingface library\n","#We use this pretrained model to extract features for our image dataset\n","\n","from transformers import ViTFeatureExtractor\n","\n","model_name_or_path = \"google/vit-base-patch16-224-in21k\"\n","feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699403492849,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"juPO-ojuJ9hK","outputId":"300bad50-f8ac-4a32-96e7-1bc914cbe692"},"outputs":[{"data":{"text/plain":["ViTFeatureExtractor {\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.5,\n","    0.5,\n","    0.5\n","  ],\n","  \"image_processor_type\": \"ViTFeatureExtractor\",\n","  \"image_std\": [\n","    0.5,\n","    0.5,\n","    0.5\n","  ],\n","  \"resample\": 2,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"height\": 224,\n","    \"width\": 224\n","  }\n","}"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["#display the config of Feature extractor\n","#FE kind of preprocess our input images to network requirements and also sepcifies the processor type\n","feature_extractor"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1699403496974,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"_d2zxc5PKrUY","outputId":"af8157ba-8f6c-4331-b41b-cdda6c62d919"},"outputs":[{"data":{"text/plain":["{'pixel_values': tensor([[[[ 0.3961,  0.3961,  0.3961,  ...,  0.2941,  0.2941,  0.2941],\n","          [ 0.3961,  0.3961,  0.3961,  ...,  0.2941,  0.2941,  0.2941],\n","          [ 0.3961,  0.3961,  0.3961,  ...,  0.2941,  0.2941,  0.2941],\n","          ...,\n","          [-0.1922, -0.1922, -0.1922,  ..., -0.2863, -0.2863, -0.2863],\n","          [-0.1922, -0.1922, -0.1922,  ..., -0.2863, -0.2863, -0.2863],\n","          [-0.1922, -0.1922, -0.1922,  ..., -0.2863, -0.2863, -0.2863]],\n","\n","         [[ 0.3804,  0.3804,  0.3804,  ...,  0.2784,  0.2784,  0.2784],\n","          [ 0.3804,  0.3804,  0.3804,  ...,  0.2784,  0.2784,  0.2784],\n","          [ 0.3804,  0.3804,  0.3804,  ...,  0.2784,  0.2784,  0.2784],\n","          ...,\n","          [-0.2471, -0.2471, -0.2471,  ..., -0.3412, -0.3412, -0.3412],\n","          [-0.2471, -0.2471, -0.2471,  ..., -0.3412, -0.3412, -0.3412],\n","          [-0.2471, -0.2471, -0.2471,  ..., -0.3412, -0.3412, -0.3412]],\n","\n","         [[ 0.4824,  0.4824,  0.4824,  ...,  0.3647,  0.3647,  0.3647],\n","          [ 0.4824,  0.4824,  0.4824,  ...,  0.3647,  0.3647,  0.3647],\n","          [ 0.4824,  0.4824,  0.4824,  ...,  0.3647,  0.3647,  0.3647],\n","          ...,\n","          [-0.2784, -0.2784, -0.2784,  ..., -0.3961, -0.3961, -0.3961],\n","          [-0.2784, -0.2784, -0.2784,  ..., -0.3961, -0.3961, -0.3961],\n","          [-0.2784, -0.2784, -0.2784,  ..., -0.3961, -0.3961, -0.3961]]]])}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["#Lets see the feature representation for our first image using the VIT feature extractor\n","example = feature_extractor(dataset_train[0][\"img\"],\n","                            return_tensors=\"pt\")\n","example"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1699403505404,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"S1MH5eE6L4vf","outputId":"f59dc176-c81b-4e67-c69e-9992764c5263"},"outputs":[{"data":{"text/plain":["torch.Size([1, 3, 224, 224])"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["example[\"pixel_values\"].shape #same size as resize input image (3, 224, 224) channel first, along with batch dimension"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699403507009,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"6sDc8KnsMC9H","outputId":"c535a5bc-b5e7-4512-d02b-722c2925d00c"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["#Lets fine the ViT transformer model with our data using the feature representations of our images using Vit\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699403611907,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"-t3CNU_qNEUl"},"outputs":[],"source":["#Now set up the same preprocess part and feature extraction as we did above for demo using single image to actually do for reall for batch of images\n","\n","def preprocess(batch):\n","    #take batch of PIL Images and preprocess them and extract features\n","    inputs = feature_extractor(batch[\"img\"], return_tensors=\"pt\")\n","    #include the labels\n","    inputs[\"label\"] = batch[\"label\"]\n","    return inputs\n"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699403614742,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"f2ZXW1HvOeLN"},"outputs":[],"source":["#apply the preprocessing transformations the training dataset\n","prepared_train = dataset_train.with_transform(preprocess)\n","\n","#transform the testing dataset\n","prepared_test = dataset_test.with_transform(preprocess)"]},{"cell_type":"markdown","metadata":{"id":"9qs11G55QcSr"},"source":["## **Model Finetuning**\n","\n","    We need to define args to the model like train, test datasets, feature extractor, model, collate function, eval metric, other training args"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699403617714,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"ySmmi2OvO7OI"},"outputs":[],"source":["#Collate function is useful when  dealing with lots of data.\n","#Batches are lists of dictionaries, so collate will help us create batch tensors\n","#It return batch data in dictionary format\n","def collate_fn(batch):\n","    return{\n","        \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n","        \"labels\": torch.tensor([x[\"label\"] for x in batch])\n","    }"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":1356,"status":"ok","timestamp":1699403622074,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"tbH6w4uNQvr2"},"outputs":[],"source":["#Eval function\n","import numpy as np\n","from datasets import load_metric\n","\n","#accuracy metric\n","metric = load_metric(\"accuracy\")\n","\n","def compute_metric(p):\n","    return metric.compute(\n","        predictions=np.argmax(p.predictions, axis=1),\n","        references=p.label_ids\n","    )"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1699403623137,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"GK6vYGiqRTe-"},"outputs":[],"source":["#Training via Finetuning\n","from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./cifar\",\n","    per_device_train_batch_size=16,\n","    evaluation_strategy=\"steps\",\n","    num_train_epochs=4,\n","    save_steps=100,\n","    eval_steps=100,\n","    logging_steps=10,\n","    learning_rate=2e-4,\n","    save_total_limit=2,\n","    remove_unused_columns=False,\n","    push_to_hub=False,\n","    load_best_model_at_end=True\n",")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1676,"status":"ok","timestamp":1699403627678,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"jlwkYNR0SUCj","outputId":"6fff62e1-5ad3-4321-8321-776f871cb9e1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#Initialize the pretrained model with our classification head of num_classes we have i.e 10\n","#we ll also have id2label and label2id mappings to have human readable labels in the Hub widget\n","\n","from transformers import ViTForImageClassification\n","\n","labels = dataset_train.features[\"label\"].names\n","\n","model = ViTForImageClassification.from_pretrained(\n","    model_name_or_path,\n","    num_labels=len(labels)\n",")"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699403630144,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"FoXQqNzyTuci","outputId":"85660cea-c3b6-485b-bed5-94c5cfec1074"},"outputs":[{"data":{"text/plain":["ViTForImageClassification(\n","  (vit): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","      )\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["#moving the model to GPU\n","model.to(device)"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699403633574,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"},"user_tz":-60},"id":"X8PJg9UvUE58"},"outputs":[],"source":["#Now, all instances can be passed to Trainer\n","\n","from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=collate_fn,\n","    compute_metrics=compute_metric,\n","    train_dataset=prepared_train,\n","    eval_dataset=prepared_test,\n","    tokenizer=feature_extractor,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":583},"id":"XWX4FXgbUo4x"},"outputs":[{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='2101' max='12500' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [ 2101/12500 1:27:53 \u003c 7:15:27, 0.40 it/s, Epoch 0.67/4]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","      \u003cth\u003eAccuracy\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e100\u003c/td\u003e\n","      \u003ctd\u003e0.323600\u003c/td\u003e\n","      \u003ctd\u003e0.469281\u003c/td\u003e\n","      \u003ctd\u003e0.883900\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e200\u003c/td\u003e\n","      \u003ctd\u003e0.349100\u003c/td\u003e\n","      \u003ctd\u003e0.317912\u003c/td\u003e\n","      \u003ctd\u003e0.918600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e300\u003c/td\u003e\n","      \u003ctd\u003e0.319400\u003c/td\u003e\n","      \u003ctd\u003e0.290000\u003c/td\u003e\n","      \u003ctd\u003e0.919600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e400\u003c/td\u003e\n","      \u003ctd\u003e0.429700\u003c/td\u003e\n","      \u003ctd\u003e0.417170\u003c/td\u003e\n","      \u003ctd\u003e0.885300\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e500\u003c/td\u003e\n","      \u003ctd\u003e0.453300\u003c/td\u003e\n","      \u003ctd\u003e0.330900\u003c/td\u003e\n","      \u003ctd\u003e0.903100\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e600\u003c/td\u003e\n","      \u003ctd\u003e0.217300\u003c/td\u003e\n","      \u003ctd\u003e0.270006\u003c/td\u003e\n","      \u003ctd\u003e0.919500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e700\u003c/td\u003e\n","      \u003ctd\u003e0.285900\u003c/td\u003e\n","      \u003ctd\u003e0.231009\u003c/td\u003e\n","      \u003ctd\u003e0.932200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e800\u003c/td\u003e\n","      \u003ctd\u003e0.382800\u003c/td\u003e\n","      \u003ctd\u003e0.328023\u003c/td\u003e\n","      \u003ctd\u003e0.904200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e900\u003c/td\u003e\n","      \u003ctd\u003e0.279100\u003c/td\u003e\n","      \u003ctd\u003e0.252272\u003c/td\u003e\n","      \u003ctd\u003e0.928200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1000\u003c/td\u003e\n","      \u003ctd\u003e0.345100\u003c/td\u003e\n","      \u003ctd\u003e0.330839\u003c/td\u003e\n","      \u003ctd\u003e0.901400\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1100\u003c/td\u003e\n","      \u003ctd\u003e0.270900\u003c/td\u003e\n","      \u003ctd\u003e0.264216\u003c/td\u003e\n","      \u003ctd\u003e0.919200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1200\u003c/td\u003e\n","      \u003ctd\u003e0.222000\u003c/td\u003e\n","      \u003ctd\u003e0.271286\u003c/td\u003e\n","      \u003ctd\u003e0.918600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1300\u003c/td\u003e\n","      \u003ctd\u003e0.419300\u003c/td\u003e\n","      \u003ctd\u003e0.293046\u003c/td\u003e\n","      \u003ctd\u003e0.911600\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1400\u003c/td\u003e\n","      \u003ctd\u003e0.348700\u003c/td\u003e\n","      \u003ctd\u003e0.249183\u003c/td\u003e\n","      \u003ctd\u003e0.923700\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1500\u003c/td\u003e\n","      \u003ctd\u003e0.246300\u003c/td\u003e\n","      \u003ctd\u003e0.226261\u003c/td\u003e\n","      \u003ctd\u003e0.934700\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1600\u003c/td\u003e\n","      \u003ctd\u003e0.218000\u003c/td\u003e\n","      \u003ctd\u003e0.213635\u003c/td\u003e\n","      \u003ctd\u003e0.937200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1700\u003c/td\u003e\n","      \u003ctd\u003e0.248800\u003c/td\u003e\n","      \u003ctd\u003e0.200575\u003c/td\u003e\n","      \u003ctd\u003e0.936500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1800\u003c/td\u003e\n","      \u003ctd\u003e0.221500\u003c/td\u003e\n","      \u003ctd\u003e0.257436\u003c/td\u003e\n","      \u003ctd\u003e0.926800\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1900\u003c/td\u003e\n","      \u003ctd\u003e0.192300\u003c/td\u003e\n","      \u003ctd\u003e0.280447\u003c/td\u003e\n","      \u003ctd\u003e0.918200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2000\u003c/td\u003e\n","      \u003ctd\u003e0.343400\u003c/td\u003e\n","      \u003ctd\u003e0.253203\u003c/td\u003e\n","      \u003ctd\u003e0.923000\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='852' max='1250' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [ 852/1250 01:57 \u003c 00:54, 7.26 it/s]\n","    \u003c/div\u003e\n","    "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["#Train the model\n","train_results = trainer.train()\n","\n","#save tokenizer with the model\n","trainer.save_model()\n","\n","#log and also save the training accuracy metric\n","trainer.log_metrics(\"train\", train_results.metrics)\n","trainer.save_metrics(\"train\", train_results.metrics)\n","\n","#save the trainer state\n","trainer.save_state()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhKK49lOVaHe"},"outputs":[],"source":["#Model Evaluation\n","metrics = trainer.evaluate(prepared_test)\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOkMiuoqOPw3BVu8k8S943q","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}