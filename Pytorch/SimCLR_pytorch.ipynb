{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNM+30UMlEkzQSiw6GgiAgH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"2Plv8Xw189B5","executionInfo":{"status":"ok","timestamp":1701300061443,"user_tz":-60,"elapsed":559,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","from torchvision import transforms, datasets\n","from torch.optim import SGD\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["class GaussianBlur:\n","    def __init__(self):\n","        pass\n","\n","class DataAugmentTransform:\n","    \"\"\"\n","    Perform Data Augmentations to create positive and negative pairs\n","    \"\"\"\n","    def __init__(self,\n","                 input_height: int = 224,\n","                 guassian_blur: bool = False,\n","                 jitter_strength: float = 1.) -> None:\n","        self.input_height = input_height\n","        self.guassian_blur = guassian_blur\n","        self.jitter_strength = jitter_strength\n","\n","    def simclr_transform_pipeline(self):\n","        color_jitter = transforms.ColorJitter(\n","            brightness=0.8 * self.jitter_strength,\n","            contrast=0.8 * self.jitter_strength,\n","            hue=0.8 * self.jitter_strength,\n","            saturation=0.2 * self.jitter_strength)\n","\n","        transforms_list = [transforms.RandomResizedCrop(size=self.input_height),\n","                           transforms.RandomHorizontalFlip(p=0.5),\n","                           transforms.RandomApply([color_jitter], p=0.8),\n","                           transforms.RandomGrayscale(p=0.2),\n","                           ]\n","        if self.guassian_blur:\n","            transforms_list.append(GaussianBlur(kernel_size=int(0.1 * self.input_height, p=0.5)))\n","        #until this point, all transforms are applied on PIL images, so here we will convert the transformed PIL images to Tensors\n","        transforms_list.append(transforms.ToTensor())\n","        self.train_transform = transforms.Compose(transforms_list) #final training transform list\n","\n","    def __call__(self, name, n_views):\n","        #we perfprm transforms on data here\n","        pass\n","\n","\n",""],"metadata":{"id":"IVOJbXmx9xVr","executionInfo":{"status":"ok","timestamp":1701211323275,"user_tz":-60,"elapsed":333,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Contrastive Loss NT-Xent without vectorization\n","class ContrastiveLossv1(nn.Module):\n","    def __init__(self, batch_size, temperature=0.5, verbose=False):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.temperature = temperature\n","        self.verbose = verbose\n","\n","    def forward(self, emb_i, emb_j):\n","        if self.verbose:\n","            print(f\"Embeddings shape emb_i: {emb_i.shape}, emb_j: {emb_j.shape}\")\n","        #Normalize the embeddings\n","        z_i = F.normalize(emb_i, dim=1)\n","        z_j = F.normalize(emb_j, dim=1)\n","\n","        #Concatenate the representations of both the views batches\n","        projection_representations = torch.cat([z_i, z_j], dim=0)\n","        if self.verbose:\n","            print(f\"Concatenated projection representations z shape:\\\n","             {projection_representations.shape}\")\n","            print(f\"Projection representations unsqueeze with dim=1 shape:\\\n","             {projection_representations.unsqueeze(dim=1).shape}\")\n","            print(f\"Projection representations unsqueeze with dim=0 shape:\\\n","             {projection_representations.unsqueeze(dim=0).shape}\")\n","\n","        #Construct the similarity matrix\n","        sim_matrix = F.cosine_similarity(\n","            x1=projection_representations.unsqueeze(dim=1),\n","            x2=projection_representations.unsqueeze(dim=0),\n","            dim=2\n","        )\n","        if self.verbose:\n","            print(f\"Similarity matrix shape:{sim_matrix.shape}\")\n","            print(f\"Similarity matrix :{sim_matrix}\")\n","\n","        #Calculating the loss function l(i, j)\n","        #(in one view persepctive l(i, j))\n","        def l_ij(i, j):\n","            if self.verbose:\n","                print(f\"l_ij batch sample indexes {i}, {j}\")\n","            #get the representations using the indexez i, j\n","            z_i_, z_j_ = projection_representations[i], projection_representations[j]\n","\n","            #Get the similarity value of these 2 representation we already calculated\n","            sim_i_j = sim_matrix[i, j]\n","            if self.verbose:\n","                print(f\"sim({i}, {j})={sim_i_j}\")\n","            #l_ij loss for each sample\n","            #Calculate the numerator of l_ij loss\n","            numerator = torch.exp(sim_i_j / self.temperature)\n","            if self.verbose: print(\"Numerator\", numerator)\n","            #Calculate the mask for denomiator to implement the indicator function to exclude same samples from sim matrix\n","            one_k_not_i = torch.ones((2 * self.batch_size)).scatter(0, torch.tensor([i]), 0.0)\n","            if self.verbose:\n","                print(f\"1{{k!={i}}} shape\", one_k_not_i.shape)\n","                print(f\"1{{k!={i}}}\", one_k_not_i)\n","\n","            #Calculate the denominator\n","            denominator = torch.sum(one_k_not_i * torch.exp(sim_matrix[i, :] / self.temperature))\n","            if self.verbose: print(\"Denominator\", denominator)\n","\n","            #loss l_i_j\n","            loss_ij = - torch.log(numerator / denominator)\n","            if self.verbose:\n","                print(f\"loss({i},{j})={loss_ij}\\n\")\n","            return loss_ij.squeeze()\n","\n","        N = self.batch_size\n","        loss = 0.0 # we accumulate loss for all the samples in the batch\n","        for k in range(0, N):\n","            print(k+N)\n","            print(k)\n","            loss += l_ij(k, k + N) + l_ij(k + N, k)\n","            # l_ij = l_ij(k, k+N)\n","            # l_ji = l_ij(k+N, k)\n","            # l_i = l_ij + l_ji\n","            # loss += l_i\n","        final_loss = (1.0 / 2*N) * loss\n","        return final_loss\n","\n"],"metadata":{"id":"AQ892kodQ1Qk","executionInfo":{"status":"ok","timestamp":1701301139785,"user_tz":-60,"elapsed":339,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#Test the function\n","\n","#Take 3 images in a batch wirth representation size of 2 for each image\n","U = torch.tensor([\n","    [1.0, 2.0],\n","    [3.0, -2.0],\n","    [1.0, 5.0]\n","]) #first augmentation batch\n","V = torch.tensor([\n","    [1.0, 0.75],\n","    [2.8, -1.75],\n","     [1.0, 4.7]\n","]) #second augmentation\n","lossobj = ContrastiveLossv1(batch_size=3, temperature=1.0, verbose=True)\n","lossobj(U, V)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWYIxisYaKZP","executionInfo":{"status":"ok","timestamp":1701301142254,"user_tz":-60,"elapsed":468,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"36d046d0-2423-4577-aa9b-8d67846a90c6"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Embeddings shape emb_i: torch.Size([3, 2]), emb_j: torch.Size([3, 2])\n","Concatenated projection representations z shape:             torch.Size([6, 2])\n","Projection representations unsqueeze with dim=1 shape:             torch.Size([6, 1, 2])\n","Projection representations unsqueeze with dim=0 shape:             torch.Size([1, 6, 2])\n","Similarity matrix shape:torch.Size([6, 6])\n","Similarity matrix :tensor([[ 1.0000, -0.1240,  0.9648,  0.8944, -0.0948,  0.9679],\n","        [-0.1240,  1.0000, -0.3807,  0.3328,  0.9996, -0.3694],\n","        [ 0.9648, -0.3807,  1.0000,  0.7452, -0.3534,  0.9999],\n","        [ 0.8944,  0.3328,  0.7452,  1.0000,  0.3604,  0.7533],\n","        [-0.0948,  0.9996, -0.3534,  0.3604,  1.0000, -0.3419],\n","        [ 0.9679, -0.3694,  0.9999,  0.7533, -0.3419,  1.0000]])\n","3\n","0\n","l_ij batch sample indexes 0, 3\n","sim(0, 3)=0.8944272994995117\n","Numerator tensor(2.4459)\n","1{k!=0} shape torch.Size([6])\n","1{k!=0} tensor([0., 1., 1., 1., 1., 1.])\n","Denominator tensor(9.4954)\n","loss(0,3)=1.3563847541809082\n","\n","l_ij batch sample indexes 3, 0\n","sim(3, 0)=0.8944272994995117\n","Numerator tensor(2.4459)\n","1{k!=3} shape torch.Size([6])\n","1{k!=3} tensor([1., 1., 1., 0., 1., 1.])\n","Denominator tensor(9.5058)\n","loss(3,0)=1.357473373413086\n","\n","4\n","1\n","l_ij batch sample indexes 1, 4\n","sim(1, 4)=0.9995677471160889\n","Numerator tensor(2.7171)\n","1{k!=1} shape torch.Size([6])\n","1{k!=1} tensor([1., 0., 1., 1., 1., 1.])\n","Denominator tensor(6.3699)\n","loss(1,4)=0.8520082831382751\n","\n","l_ij batch sample indexes 4, 1\n","sim(4, 1)=0.9995677471160889\n","Numerator tensor(2.7171)\n","1{k!=4} shape torch.Size([6])\n","1{k!=4} tensor([1., 1., 1., 1., 0., 1.])\n","Denominator tensor(6.4733)\n","loss(4,1)=0.8681114912033081\n","\n","5\n","2\n","l_ij batch sample indexes 2, 5\n","sim(2, 5)=0.9999250769615173\n","Numerator tensor(2.7181)\n","1{k!=2} shape torch.Size([6])\n","1{k!=2} tensor([1., 1., 0., 1., 1., 1.])\n","Denominator tensor(8.8348)\n","loss(2,5)=1.1787779331207275\n","\n","l_ij batch sample indexes 5, 2\n","sim(5, 2)=0.9999250769615173\n","Numerator tensor(2.7181)\n","1{k!=5} shape torch.Size([6])\n","1{k!=5} tensor([1., 1., 1., 1., 1., 0.])\n","Denominator tensor(8.8762)\n","loss(5,2)=1.1834462881088257\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(10.1943)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["class ContrastiveLossNTXent(nn.Module):\n","    def __init__(self, batch_size, temperature=0.5, verbose=False):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.temperature = temperature\n","        self.verbose = verbose\n","\n","    def forward(self, emb_z_i, emb_z_j):\n","        \"\"\"\n","        Calculate NT_Xent Loss\n","\n","        emb_z_i : (b, 128) Projecttion head embeddings of one flow of augmentations z_i of a batch\n","        emb_z_j : (b, 128) Projecttion head embeddings of second flow of augmentations z_j of a batch\n","        \"\"\"\n","        ## Normalize the embeddings first\n","        z_i = F.normalize(emb_z_i, 1)\n","        z_j = F.normalize(emb_z_j, 1)\n","\n","        #Contentanate both of them to further use it to construct similarity matrix\n","        representations = torch.cat([z_i, z_j], dim=0)\n","\n","        #Similarity Matrix using cosine similarity manual\n","        sim_matrix = torch.matmul(representations, representations.T)\n","\n","        if self.verbose:\n","            print(f\"Similarity Matrix: \\n {sim_matrix}\")\n","\n","        #Denominator similarity\n","        #creating mask\n","        num_samples = len(representations)\n","        mask = ~torch.eye(num_samples).bool()\n","        sim_matrix_neg = torch.exp(sim_matrix / self.temperature)\n","        loss_denominator_neg = sim_matrix_neg.masked_select(mask).view(num_samples, -1).sum(dim=-1)\n","        print(\"Mask\"+str(mask))\n","        print(\"loss denominator\"+str(loss_denominator_neg))\n","\n","        #Positive examples Numerator similarity\n","        loss_numerator_pos = torch.exp(torch.sum(z_i * z_j, dim=-1) / self.temperature)\n","        print(\"loss loss_numerator_pos\"+str(loss_numerator_pos))\n","        loss_numerator_pos = torch.cat([loss_numerator_pos, loss_numerator_pos], dim=0)\n","        print(\"Concat loss_numerator_pos\"+str(loss_numerator_pos))\n","\n","        final_loss = - torch.log( loss_numerator_pos / loss_denominator_neg ).mean()\n","        print(torch.log( loss_numerator_pos / loss_denominator_neg ))\n","        print(final_loss)\n","        return final_loss.squeeze()\n"],"metadata":{"id":"nJsD_feQ_6Ze","executionInfo":{"status":"ok","timestamp":1701214655204,"user_tz":-60,"elapsed":229,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","emb_i = torch.randn(3, 1)\n","print(emb_i)\n","torch.manual_seed(0)\n","emb_j = torch.randn(3, 1)\n","print(emb_j)\n","\n","contloss = ContrastiveLossNTXent(batch_size=2, verbose=True)\n","contloss(emb_i, emb_j)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XXPx1RPHGNBz","executionInfo":{"status":"ok","timestamp":1701214645849,"user_tz":-60,"elapsed":236,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"08091b76-0a1a-4718-91f4-cda3e6f1fd48"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.3367],\n","        [0.1288],\n","        [0.2345]])\n","tensor([[ 1.5410],\n","        [-0.2934],\n","        [-2.1788]])\n","Similarity Matrix: \n"," tensor([[ 1.,  1.,  1.,  1., -1., -1.],\n","        [ 1.,  1.,  1.,  1., -1., -1.],\n","        [ 1.,  1.,  1.,  1., -1., -1.],\n","        [ 1.,  1.,  1.,  1., -1., -1.],\n","        [-1., -1., -1., -1.,  1.,  1.],\n","        [-1., -1., -1., -1.,  1.,  1.]])\n","Masktensor([[False,  True,  True,  True,  True,  True],\n","        [ True, False,  True,  True,  True,  True],\n","        [ True,  True, False,  True,  True,  True],\n","        [ True,  True,  True, False,  True,  True],\n","        [ True,  True,  True,  True, False,  True],\n","        [ True,  True,  True,  True,  True, False]])\n","loss denominatortensor([22.4378, 22.4378, 22.4378, 22.4378,  7.9304,  7.9304])\n","loss loss_numerator_postensor([7.3891, 0.1353, 0.1353])\n","Concat loss_numerator_postensor([7.3891, 0.1353, 0.1353, 7.3891, 0.1353, 0.1353])\n","tensor([-1.1107, -5.1107, -5.1107, -1.1107, -4.0707, -4.0707])\n","tensor(3.4307)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(3.4307)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","sim_matrix = torch.randn(6, 6)\n","mask = ~torch.eye(6).bool()\n","my_mat = sim_matrix.masked_select(mask)\n","transformed_mat = my_mat.view(len(sim_matrix), -1)\n","sum_mat = transformed_mat.sum(dim=-1) #axis=1\n","sim_matrix, mask, my_mat, transformed_mat, sum_mat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-Zn1y2cGuOt","executionInfo":{"status":"ok","timestamp":1701212400258,"user_tz":-60,"elapsed":234,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4acdf92d-b423-43ab-b60b-0bc499b5b83b"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345],\n","         [-0.0431, -1.6047, -0.7521,  1.6487, -0.3925, -1.4036],\n","         [-0.7279, -0.5594, -0.7688,  0.7624,  1.6423, -0.1596],\n","         [-0.4974,  0.4396,  0.3189, -0.4245,  0.3057, -0.7746],\n","         [ 0.0349,  0.3211,  1.5736, -0.8455, -1.2742,  2.1228],\n","         [-1.2347, -0.4879, -1.4181,  0.8963,  0.0499,  2.2667]]),\n"," tensor([[False,  True,  True,  True,  True,  True],\n","         [ True, False,  True,  True,  True,  True],\n","         [ True,  True, False,  True,  True,  True],\n","         [ True,  True,  True, False,  True,  True],\n","         [ True,  True,  True,  True, False,  True],\n","         [ True,  True,  True,  True,  True, False]]),\n"," tensor([ 1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -0.7521,  1.6487,\n","         -0.3925, -1.4036, -0.7279, -0.5594,  0.7624,  1.6423, -0.1596, -0.4974,\n","          0.4396,  0.3189,  0.3057, -0.7746,  0.0349,  0.3211,  1.5736, -0.8455,\n","          2.1228, -1.2347, -0.4879, -1.4181,  0.8963,  0.0499]),\n"," tensor([[ 1.4873,  0.9007, -2.1055,  0.6784, -1.2345],\n","         [-0.0431, -0.7521,  1.6487, -0.3925, -1.4036],\n","         [-0.7279, -0.5594,  0.7624,  1.6423, -0.1596],\n","         [-0.4974,  0.4396,  0.3189,  0.3057, -0.7746],\n","         [ 0.0349,  0.3211,  1.5736, -0.8455,  2.1228],\n","         [-1.2347, -0.4879, -1.4181,  0.8963,  0.0499]]),\n"," tensor([-0.2736, -0.9426,  0.9579, -0.2078,  3.2069, -2.1945]))"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"AzgbOYzuInKV"},"execution_count":null,"outputs":[]}]}