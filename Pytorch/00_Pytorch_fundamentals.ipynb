{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO9F1cN6ePcwSVqz53fZLoB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["keyboard shortcuts\n","- for docstring https://stackoverflow.com/questions/49042988/quick-docstrings-in-colaboratory"],"metadata":{"id":"tTxAdNUXyqQ0"}},{"cell_type":"markdown","source":["## **Pytorch Fundamentals**"],"metadata":{"id":"Ls_QN4s8Ft39"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vA8oC7bthx5"},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tEml2CrotpJL","executionInfo":{"status":"ok","timestamp":1700422541281,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"07825dc6-12ad-4b7e-a454-6a40cbcc6b75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.1.0+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["!nvidia-smi #nvidia-smi command, which is used to check the GPU usage and performance\n","#when we get command not found when we run this, it means we r not running on GPU runtime. Change it to GPU from CPU to execute this command"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CyEiLfTtsmj","executionInfo":{"status":"ok","timestamp":1700431617327,"user_tz":-60,"elapsed":234,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3d225810-6faf-4781-eff5-6a5b875dec28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 19 22:06:57 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   60C    P0    27W /  70W |    635MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["### **1.Introduction to Tensors**"],"metadata":{"id":"RcshUdtPFLw3"}},{"cell_type":"markdown","source":["#### Creating Tensors\n","- https://pytorch.org/docs/stable/tensors.html"],"metadata":{"id":"McylAztEITlP"}},{"cell_type":"code","source":["#scalar tensor - 0D tensor\n","scalar = torch.tensor(7)\n","scalar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hzKD33PIBfA","executionInfo":{"status":"ok","timestamp":1700422541812,"user_tz":-60,"elapsed":27,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"bd40581c-66fe-43cf-fa87-2c4df21a9228"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["scalar.ndim #rank of the tensor - how many dimensions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tt6nrKlIdM7","executionInfo":{"status":"ok","timestamp":1700422541813,"user_tz":-60,"elapsed":26,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"fbafb623-34f8-41eb-b4e9-afba132755e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["scalar.item() #gives the value inside the tensor if it is scalar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLJO9rEmJTkF","executionInfo":{"status":"ok","timestamp":1700422541813,"user_tz":-60,"elapsed":24,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"df0fcf36-acec-447c-83e1-60697c8b7f21"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["scalar.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2Rtug6BJ7T_","executionInfo":{"status":"ok","timestamp":1700422541813,"user_tz":-60,"elapsed":23,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"38884f8b-0958-4af4-aaf5-9529293a0066"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Vector tensor - 1D tensor\n","vector = torch.tensor([1, 2, 3])\n","vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y89sNG2AJdlE","executionInfo":{"status":"ok","timestamp":1700422541813,"user_tz":-60,"elapsed":22,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"68bad4a3-fd21-41e0-f7f2-c691a3dfa0c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["vector.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fF9XtFSwJw_n","executionInfo":{"status":"ok","timestamp":1700422541813,"user_tz":-60,"elapsed":21,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"5d851ea8-4503-4c4b-fd17-e2cb0f56903b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["vector.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3pLhc9YJy2H","executionInfo":{"status":"ok","timestamp":1700422541813,"user_tz":-60,"elapsed":20,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"09c04550-8634-4364-fe14-1f77e75691e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["vector.item() #throws error as it only works for scalar, not for vector tensor\n","#Use torch.Tensor.item() to get a Python number from a tensor containing a single value:"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"qiQ5L7pLMyEb","executionInfo":{"status":"error","timestamp":1700422552458,"user_tz":-60,"elapsed":272,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"51c995cc-9d1f-494b-9f34-44c800c9f320"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-3eaaaa7a3a29>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#throws error as it only works for scalar, not for vector tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 3 elements cannot be converted to Scalar"]}]},{"cell_type":"code","source":["import torch\n","matrix = torch.tensor([[1]]) #shape (1, 1)\n","matrix.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QU9o4du45vTf","executionInfo":{"status":"ok","timestamp":1700939682599,"user_tz":-60,"elapsed":407,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"0bc66828-a3bc-4797-cec3-78133c702b40"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["#Matrix = 2D - combination of several 1D vectors\n","MATRIX = torch.tensor([[1, 2],\n","                       [3, 4]])\n","MATRIX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEYAs6OqJ0j6","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":416,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b7d445e1-4b47-4361-fbd6-24dd00a003a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["MATRIX.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1fGcAViKT43","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":39,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"22a2dba1-a559-48d8-80c8-68c61a150b38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["MATRIX.shape #2 rows 2 cols"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXb7VfgtKO6l","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":38,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"2f5c4cf3-d49c-4b54-abd1-f478acd13edb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["MATRIX[1] #second row"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEMdj8A3KQQ5","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":37,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"15da805d-ad1e-41af-b821-e6e9533a1037"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 4])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["MATRIX[:, 0] #0th column, all rows"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omnwmqPCKa9G","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":36,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"f94321d5-bd53-46af-b27c-ebf326e34266"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 3])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["#Tensor - 3D, 4D....\n","TENSOR = torch.tensor([[[1, 2, 3],\n","                        [4, 5, 6],\n","                        [7, 8, 9]]])\n","TENSOR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VH-8gnsOKhp8","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":35,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"55fd6a4d-e0b9-40b8-fcbf-77df4b9c2d8b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[1, 2, 3],\n","         [4, 5, 6],\n","         [7, 8, 9]]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["TENSOR.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15EtAh45K8zO","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":34,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e72ff54b-6f31-4893-89d0-e9a11b86784a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["TENSOR.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7mXaAG0LFiB","executionInfo":{"status":"ok","timestamp":1700422553309,"user_tz":-60,"elapsed":33,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a1588bc4-b87c-4f81-9f06-923d243636b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 3])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["TENSOR[0] #getting the first dimension, we get 2D matrix (3, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oelaf_BXLIOP","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":33,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"07bbca13-e3f9-48a9-c695-29b8e752aed9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["TENSOR[0, 1] #first dimension 0th index, second dimension second index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WgnUq2sLOXY","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":32,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"c4215cc6-0ab3-4078-d0db-1dc2a164a12a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([4, 5, 6])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Note: Scalars and vector varaible in lowercase and , matrix and tensor variables in uppercase is the nomenclature"],"metadata":{"id":"e2YsluQ9MCFX"}},{"cell_type":"markdown","source":["#### **Random Tensors**\n","\n","`Create random tensors of required distributions like uniform, normal..`"],"metadata":{"id":"qZYMRniXLcRs"}},{"cell_type":"code","source":["#creates a random 2d tensor from uniform distribution with 3 rows 4 cols\n","RANDTENSOR = torch.rand(size=(3, 4))\n","RANDTENSOR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sj_97BG0MUpC","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":31,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"19e864ec-07c5-4de8-947a-caf055e5053f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8330, 0.4173, 0.7556, 0.7996],\n","        [0.1591, 0.8125, 0.6666, 0.3599],\n","        [0.1775, 0.6334, 0.8769, 0.5936]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["RANDTENSOR.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Da14GXcZNNGq","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":30,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"0ee229dd-dad4-4308-ff5d-f36771f31d20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["RANDTENSOR.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opl1F_sgNidK","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":29,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"0ceda2be-b54b-4da9-b76f-b1ce5565785e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 4])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["RANDTENSOR.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DP33UXehNkvr","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":28,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"48d360ae-4052-4479-cc83-3376d6f460e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 4])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["RANDTENSOR = torch.rand(1, 10, 10) #3d tensor\n","RANDTENSOR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjI2sPwsNm8g","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":27,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"860ce46d-7a59-4b09-c2eb-86c55429c9fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0.5748, 0.6483, 0.1993, 0.7878, 0.3013, 0.0202, 0.2468, 0.6627,\n","          0.1677, 0.6982],\n","         [0.8170, 0.6167, 0.5005, 0.5654, 0.7155, 0.6746, 0.9074, 0.7459,\n","          0.0563, 0.4101],\n","         [0.7636, 0.1107, 0.9364, 0.4106, 0.9274, 0.8021, 0.2235, 0.4407,\n","          0.4660, 0.5173],\n","         [0.1491, 0.8308, 0.8413, 0.2356, 0.6054, 0.3793, 0.2585, 0.9534,\n","          0.6792, 0.1943],\n","         [0.2378, 0.6371, 0.7900, 0.0358, 0.6088, 0.5830, 0.2062, 0.3491,\n","          0.2786, 0.8206],\n","         [0.0166, 0.9266, 0.1059, 0.9857, 0.7767, 0.8337, 0.7377, 0.4126,\n","          0.5359, 0.1571],\n","         [0.7990, 0.5983, 0.0245, 0.9392, 0.6150, 0.9827, 0.7325, 0.6946,\n","          0.8612, 0.7283],\n","         [0.3293, 0.2255, 0.2191, 0.2707, 0.0208, 0.5311, 0.9228, 0.6551,\n","          0.4036, 0.9717],\n","         [0.0896, 0.7481, 0.2962, 0.9401, 0.5256, 0.7213, 0.9592, 0.7619,\n","          0.8354, 0.8446],\n","         [0.0541, 0.0799, 0.9494, 0.6350, 0.1464, 0.4629, 0.2562, 0.4376,\n","          0.6500, 0.2689]]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["RANDTENSOR.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZAjgc3CNw_O","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":26,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6475087a-0a0a-4d0b-b2bf-6e2ce5c65607"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["RANDTENSOR = torch.rand(3, 10, 10) #3d tensor\n","RANDTENSOR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdBT3GNlN2Y-","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":24,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"2b6845bf-1bac-43cc-e1bc-a24d5e8fd554"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0.0498, 0.7095, 0.8348, 0.1548, 0.4922, 0.5233, 0.8510, 0.3104,\n","          0.6748, 0.4136],\n","         [0.5245, 0.8593, 0.8096, 0.7116, 0.2164, 0.8160, 0.9984, 0.4183,\n","          0.8078, 0.2023],\n","         [0.4846, 0.2036, 0.2496, 0.9416, 0.5172, 0.3335, 0.3536, 0.2083,\n","          0.9910, 0.2904],\n","         [0.1989, 0.1794, 0.6432, 0.8179, 0.4666, 0.1354, 0.5311, 0.7577,\n","          0.9279, 0.3376],\n","         [0.7211, 0.1985, 0.0702, 0.0649, 0.3213, 0.8071, 0.2385, 0.0672,\n","          0.7656, 0.2807],\n","         [0.8741, 0.9918, 0.7156, 0.9953, 0.9849, 0.4948, 0.2704, 0.1663,\n","          0.2009, 0.0777],\n","         [0.3156, 0.1253, 0.4491, 0.0867, 0.1504, 0.2244, 0.3485, 0.8558,\n","          0.9733, 0.7432],\n","         [0.7925, 0.5197, 0.4216, 0.8918, 0.9719, 0.3011, 0.1010, 0.9630,\n","          0.0708, 0.2334],\n","         [0.5692, 0.5992, 0.1073, 0.1650, 0.0055, 0.5956, 0.6178, 0.7532,\n","          0.7121, 0.0623],\n","         [0.7599, 0.8568, 0.2687, 0.9927, 0.3927, 0.4230, 0.4625, 0.9940,\n","          0.8772, 0.0012]],\n","\n","        [[0.8586, 0.7780, 0.6775, 0.0603, 0.2558, 0.7847, 0.2429, 0.2621,\n","          0.1326, 0.7190],\n","         [0.9907, 0.4723, 0.9775, 0.1621, 0.9919, 0.0695, 0.5029, 0.7450,\n","          0.9170, 0.4753],\n","         [0.0060, 0.6311, 0.9780, 0.1352, 0.1216, 0.3886, 0.8305, 0.5878,\n","          0.0500, 0.8297],\n","         [0.5127, 0.8262, 0.2795, 0.6066, 0.0336, 0.9651, 0.7945, 0.3192,\n","          0.6345, 0.8612],\n","         [0.1551, 0.8899, 0.9800, 0.8409, 0.9876, 0.0599, 0.5968, 0.7115,\n","          0.8381, 0.1132],\n","         [0.5281, 0.4481, 0.6206, 0.2232, 0.2739, 0.4667, 0.1074, 0.1740,\n","          0.9686, 0.9387],\n","         [0.6468, 0.0798, 0.9624, 0.5433, 0.7120, 0.2496, 0.5409, 0.2300,\n","          0.6263, 0.2858],\n","         [0.1494, 0.4385, 0.1705, 0.3522, 0.3454, 0.3161, 0.8762, 0.4706,\n","          0.2141, 0.8841],\n","         [0.7439, 0.7377, 0.5434, 0.8536, 0.8843, 0.0834, 0.9886, 0.0250,\n","          0.1178, 0.0622],\n","         [0.8010, 0.3081, 0.9131, 0.6471, 0.9571, 0.6856, 0.5250, 0.9304,\n","          0.8766, 0.8022]],\n","\n","        [[0.9579, 0.0572, 0.6804, 0.8981, 0.0112, 0.1177, 0.4434, 0.7122,\n","          0.8745, 0.6549],\n","         [0.3481, 0.7808, 0.1000, 0.9208, 0.6108, 0.1119, 0.3482, 0.8375,\n","          0.0441, 0.6262],\n","         [0.0597, 0.2416, 0.1624, 0.6957, 0.4860, 0.7181, 0.4870, 0.0535,\n","          0.3389, 0.2401],\n","         [0.1031, 0.8826, 0.9802, 0.8324, 0.5130, 0.8852, 0.5393, 0.6695,\n","          0.8821, 0.4041],\n","         [0.6866, 0.6135, 0.6311, 0.8813, 0.8564, 0.4443, 0.1422, 0.5043,\n","          0.0976, 0.5578],\n","         [0.4813, 0.8007, 0.5059, 0.4458, 0.2683, 0.6288, 0.6325, 0.0061,\n","          0.7039, 0.4804],\n","         [0.1187, 0.8961, 0.3105, 0.4468, 0.2012, 0.5755, 0.9463, 0.5054,\n","          0.4736, 0.8928],\n","         [0.6862, 0.0791, 0.5545, 0.9004, 0.2002, 0.7793, 0.1248, 0.4667,\n","          0.1134, 0.9555],\n","         [0.2827, 0.2965, 0.9872, 0.6342, 0.8110, 0.6284, 0.7586, 0.7936,\n","          0.9237, 0.0548],\n","         [0.4376, 0.0300, 0.4052, 0.8228, 0.7221, 0.5848, 0.3936, 0.1441,\n","          0.0668, 0.0608]]])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["RANDTENSOR.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVYibI1uN65-","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":23,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"142197de-396e-4c16-f933-4078a1adc066"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["#Create a random tensor with similar shape to an image tensor\n","random_image_tensor = torch.rand(224, 224, 3) #height, width, channel\n","random_image_tensor.shape, random_image_tensor.ndim #observe, we can print all in one line"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MZcEZouN9yy","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":21,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ca6dc562-fd5b-4636-fc2c-e0f2c1fa7979"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([224, 224, 3]), 3)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["import torch\n","random_tensor = torch.randint(0, 10, size=(4,))\n","random_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gpmcfRg5aD2m","executionInfo":{"status":"ok","timestamp":1703196345822,"user_tz":-60,"elapsed":4482,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"304545a3-5b4e-4265-8bf2-40a963919563"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([8, 3, 6, 1])"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import torch\n","random_img_tensor = torch.randint(0, 255, size=(1, 32, 32))\n","random_img_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y4u-k4IaaJy","executionInfo":{"status":"ok","timestamp":1703196382205,"user_tz":-60,"elapsed":325,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"c51112c4-b75a-46a1-ddda-287dbc3b198e"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[192,  51, 100,  ..., 225,  73, 236],\n","         [159, 128, 170,  ..., 234,  72, 172],\n","         [ 61, 205, 247,  ..., 116, 199,  35],\n","         ...,\n","         [213,  12, 220,  ..., 109,  95, 198],\n","         [ 21,  15, 121,  ...,  45,  21, 133],\n","         [143,  19, 233,  ...,  17, 121, 107]]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["#### **Zeros and ones**"],"metadata":{"id":"wT75cnFROhjp"}},{"cell_type":"code","source":["zeros = torch.zeros(3, 4)\n","zeros, zeros.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfE5OOSgPpae","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":20,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"9978ed68-4d69-4ef2-d7ae-9f91ea2d03b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]),\n"," torch.float32)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["ones = torch.ones(size=(3, 4))\n","ones"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drxJOKQtPuJy","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":19,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"17eb8109-dbb2-4a41-9e44-48132184dbe9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["ones.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1md2h4MGPxvI","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":18,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"09583a81-679d-4943-8905-866f59941b58"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["#### **Creating a range of tensors and zeros-like, ones_like**"],"metadata":{"id":"ZUNyTj-eP3fT"}},{"cell_type":"code","source":["#torch.arange()\n","torch.arange(0, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFz4a-VGQMdq","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":17,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"75516f08-1824-4bef-86b9-75f2a0c46a6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["torch.arange(1, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dOVzrjSuQRoe","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e1255ad9-6128-45de-ce5d-0dd8830eaac6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["torch.arange(start=1, end=10, step=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibjRmvUYQY-V","executionInfo":{"status":"ok","timestamp":1700422553310,"user_tz":-60,"elapsed":15,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"f08c6b94-2ac2-42a9-c9f8-c2bc227be286"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 3, 5, 7, 9])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["torch.arange(start=10, end=1, step=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUUNAOdLQizU","executionInfo":{"status":"ok","timestamp":1700422553698,"user_tz":-60,"elapsed":402,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6636e56e-ca4a-487c-a625-f69540777540"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10,  9,  8,  7,  6,  5,  4,  3,  2])"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["#torch.zeros_like, ones_like\n","original = torch.arange(1, 11)\n","liketensor = torch.zeros_like(original)\n","original, original.shape, liketensor, liketensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnDmA0ljQlbW","executionInfo":{"status":"ok","timestamp":1700422553698,"user_tz":-60,"elapsed":41,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"80b0885f-e0a3-4505-97d7-922fd61a62a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n"," torch.Size([10]),\n"," tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," torch.Size([10]))"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["#### **Tensor datatype, device, requires_grad params**"],"metadata":{"id":"n-8StEsPRRBP"}},{"cell_type":"code","source":["#even we specify none as dtype, still the dtype is gonna return as float32\n","#based on input data it has\n","float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n","float_32_tensor.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rs62h8s-RmrP","executionInfo":{"status":"ok","timestamp":1700422553698,"user_tz":-60,"elapsed":40,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d694bc85-302d-44b7-8386-f467efdfbea2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["#it will return int eventhough we have given dtype=None, based on i/p data\n","int_32_tensor = torch.tensor([3, 6, 9], dtype=None)\n","int_32_tensor.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tHgyg96R8YE","executionInfo":{"status":"ok","timestamp":1700422553698,"user_tz":-60,"elapsed":39,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d618ac91-b8fd-4a5a-b71a-c1dee8d0d7af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.int64"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["#device param, requires_grad params of a tensor\n","float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=None,\n","                               device=None, #None, \"cpu\", \"cuda\" for gpu, tells what device is your tensor on\n","                               requires_grad=False)#construct tensor with no autograd history, called leaf tensor, no tracking of tensor\n","float_32_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0dGZx8omR_oy","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":39,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4490a83f-e9ab-4b1d-ef2a-9efd3428769b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3., 6., 9.])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["#dtype param of a tensor\n","float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=torch.float16)\n","float_16_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiJjxgcYUBpv","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":38,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"387e7901-21e6-4f68-9b13-431484ba9089"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3., 6., 9.], dtype=torch.float16)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["#convert dtype of a tensor from float32 tensor to float 16\n","float_16_tensor = float_32_tensor.type(torch.float16)\n","float_16_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUYnHwp1Ur0r","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":37,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d4a61c65-e6fe-488e-dff1-d26074cf75f6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3., 6., 9.], dtype=torch.float16)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["#convert float32 tensor to float 16 using type_as\n","float_16_tensor_1 = float_32_tensor.type_as(float_16_tensor)\n","float_16_tensor_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hljgpfaUU9zh","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":36,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"94c22bab-993a-49d6-e120-46a771299069"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3., 6., 9.], dtype=torch.float16)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["#can we multiply float_16 tensor with float_32 tensor?\n","multipl_16_32 = float_16_tensor_1 * float_32_tensor #yes we could and we get float32\n","multipl_16_32, multipl_16_32.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67qAOheUVYuI","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":34,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"cae28d2d-3fa0-4c99-cb74-4f55f521c7b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 9., 36., 81.]), torch.float32)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["```but sometimes tensors of differet datatypes may end up with errors when performing other operations. It is advisable to avoid different datatypes operations```"],"metadata":{"id":"_QrLFb__afjE"}},{"cell_type":"code","source":["#lets try multiply a int tensor and float tensor to see what happens\n","int_tensor_32 = torch.tensor([1, 2, 3], dtype=torch.int32)\n","float_tensor_32 = torch.tensor([1.2, 2., 3.], dtype=torch.float32)\n","res = int_tensor_32 * float_tensor_32\n","res, res.dtype #we get float32 as result and multiplication is success"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"we5SaV0UZu1J","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":33,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ff81980d-657d-4447-ed41-bd98b9ecb31d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1.2000, 4.0000, 9.0000]), torch.float32)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["#lets try division a int tensor and float tensor to see what happens\n","int_tensor_32 = torch.tensor([1, 2, 3], dtype=torch.int32)\n","float_tensor_32 = torch.tensor([1.2, 2., 3.], dtype=torch.float32)\n","res = int_tensor_32 / float_tensor_32\n","res, res.dtype #we get float32 as result and division is success"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUn-nTYHZ8wV","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":32,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"bf53d5a1-0182-4245-cd4c-c84a6f5fe965"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.8333, 1.0000, 1.0000]), torch.float32)"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["#lets try division a int32 tensor and float16 tensor to see what happens\n","int_tensor_32 = torch.tensor([1, 2, 3], dtype=torch.int32)\n","float_tensor_16 = torch.tensor([1.2, 2., 3.], dtype=torch.float16)\n","res = int_tensor_32 / float_tensor_16\n","res, res.dtype #we get float16 as result and division is success"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WU_FAgZxbxUO","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":31,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ba0c7a28-48e8-4884-8c9f-22354e24edf9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.8330, 1.0000, 1.0000], dtype=torch.float16), torch.float16)"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["#Getting info from tensors - shape, size(), dtype, device\n","mytensor = torch.rand(3, 4)\n","mytensor, mytensor.dtype, mytensor.shape, mytensor.size(), mytensor.device\n","#default dtype is float32, device is cpu if not specified"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BXPLBAqb3nS","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":30,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"0106a81b-de6f-4bdb-db89-5331745ec4b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.4100, 0.3716, 0.8757, 0.5050],\n","         [0.1170, 0.0782, 0.4253, 0.7218],\n","         [0.4660, 0.6588, 0.3866, 0.2083]]),\n"," torch.float32,\n"," torch.Size([3, 4]),\n"," torch.Size([3, 4]),\n"," device(type='cpu'))"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["### **Manipulating Tensors(tensor operations)**\n","- Addition\n","- Subtraction\n","- Multiplication(element-wise)\n","- Division\n","- Matrix multiplication"],"metadata":{"id":"cLVGZbQfozaZ"}},{"cell_type":"code","source":["## Addition - adding 10 to a tensor - broadcasting\n","mytensor = torch.tensor([1, 2, 3])\n","mytensor + 10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAcm7L-weYDF","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":28,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ce0dc870-a579-4452-b4b5-8f128435d6bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([11, 12, 13])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["## Multiplication - multipying with 10 to a tensor - broadcasting\n","mytensor = torch.tensor([1, 2, 3])\n","mytensor = mytensor * 10 #inplace - modifying the tensor\n","mytensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5V3KZnxpbqU","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":27,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"17d7ef79-467b-421b-80eb-7b82cf860daf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10, 20, 30])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["## Division\n","mytensor = torch.tensor([1, 2, 3])\n","mytensor / 10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2HTIoguptjK","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":26,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3317c40d-37b3-45ff-8977-195df3f99e9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1000, 0.2000, 0.3000])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["## Subtraction\n","mytensor = torch.tensor([1, 2, 3])\n","mytensor - 10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spItlMQ5p-Fe","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":25,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"5d3ade00-369a-4ca1-afe7-5434bbbb7224"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-9, -8, -7])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["#sum for 2D or more dimensional tensors\n","mytensor = torch.tensor([[1, 2, 3]])\n","torch.sum(mytensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OasWQCFttPZW","executionInfo":{"status":"ok","timestamp":1700422553699,"user_tz":-60,"elapsed":24,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"0d8f7bc7-2260-4f9f-e717-f19394faad0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6)"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["#sum for 2D or more dimensional tensors\n","mytensor = torch.tensor([[1, 2, 3]])\n","torch.sum(mytensor, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":24,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"f7e9c791-6f77-461a-846a-2673d29dc1a5","id":"jtVhanrctvU4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3])"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["#sum for 2D or more dimensional tensors\n","mytensor = torch.tensor([[1, 2, 3]])\n","torch.sum(mytensor, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XIrPhjptSBm","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":23,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"7f09f9a8-66c0-462b-9095-ada40d07f005"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6])"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["``Pytorch inbuilt functions for elementwise operations``\n","\n","But its better to use elementwise operations like add, subtract, multiplication with python opertaors instead of torch built-in functions for better readability"],"metadata":{"id":"WmWQn65Ps5eO"}},{"cell_type":"code","source":["#multiplication\n","mytensor = torch.tensor([1, 2, 3])\n","torch.mul(mytensor, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oMBdoHyqCqt","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":22,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d4e6a7bf-5388-4631-ff50-e5df8ef26135"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10, 20, 30])"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["#addition\n","mytensor = torch.tensor([1, 2, 3])\n","torch.add(mytensor, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JoderFTrtEY8","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":21,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"655e1fad-e850-4d02-b153-267e03682f7b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([11, 12, 13])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["#subtract\n","mytensor = torch.tensor([1, 2, 3])\n","torch.subtract(mytensor, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2vYURCltInN","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":20,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4b9d0d72-28cc-41ec-b9c3-81c8e0688b27"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-9, -8, -7])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["#Matrix-multiplication with matmul rules of shapes\n","#matmul is similar to dot product but we use dot product when we have 1D tensors or when we use loop and it is bit slow compared to matmul\n","#matmul for 1D, 2D,... vectorized matmul operation without loop\n","# @ or torch.matmul or torch.mm - matmul, . or torch.dot - dot product\n","\n","mytensor = torch.tensor([1, 2, 3]) #shape (3,) - single dimension\n","print(mytensor.shape)\n","print(\"Element wise multiplication\"+ str(mytensor * mytensor))\n","print(\"Matrix multiplication\"+ str(torch.matmul(mytensor, mytensor)))\n","print(\"Matrix multiplication\"+ str(torch.matmul(mytensor, mytensor).shape))\n","print(\"Dot product\"+ str(torch.dot(mytensor, mytensor)))\n","print(\"Dot product\"+ str(torch.dot(mytensor, mytensor).shape))\n","#observe how the one dimension variable gives a scalar value without the dimension."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5hz_KDst5ZJ","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":19,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"5417c73d-3902-443a-d627-a7949c435d36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3])\n","Element wise multiplicationtensor([1, 4, 9])\n","Matrix multiplicationtensor(14)\n","Matrix multiplicationtorch.Size([])\n","Dot producttensor(14)\n","Dot producttorch.Size([])\n"]}]},{"cell_type":"code","source":["#But if the matrices are 2D, like (1, 3) shape, then it would give resultant matrix with shape (1, 1)\n","\n","mytensor = torch.tensor([[1, 2, 3]]) #shape (1, 3) - 2 dimensions\n","print(\"Element wise multiplication\"+ str(mytensor * mytensor))\n","print(\"Matrix multiplication\"+ str(torch.matmul(mytensor, mytensor.T))) #matmul 1st cols = 2nd rows, hence transpose\n","print(\"Matrix multiplication shape\"+ str(torch.matmul(mytensor, mytensor.T).shape))\n","# print(\"Dot product\"+ str(torch.dot(mytensor, mytensor))) #throws error - 1D tensors expected, but got 2D and 2D tensors\n","\n","#always perform matmul after reshaping the matrix to atleast 2D"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOK4V2tD04P5","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":18,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"85859933-dae2-4362-c68a-93fa8e45439a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Element wise multiplicationtensor([[1, 4, 9]])\n","Matrix multiplicationtensor([[14]])\n","Matrix multiplication shapetorch.Size([1, 1])\n"]}]},{"cell_type":"code","source":["#matrix multiplication of 1D matrix by hand using for loop, also lets time it\n","%%time\n","mytensor = torch.tensor([1, 2, 3])\n","print(len(mytensor)) #3\n","print(mytensor.shape) #[3,]\n","value = 0\n","for i in range(len(mytensor)):\n","    value += mytensor[i] * mytensor[i]\n","value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFZ_IoQM1abl","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":17,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"42627fd2-a567-4972-d938-b273216e5c86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","torch.Size([3])\n","CPU times: user 1.85 ms, sys: 0 ns, total: 1.85 ms\n","Wall time: 2.14 ms\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(14)"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["#dot product using for loop of 2D tensor =~ matmul\n","%%time\n","mytensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(len(mytensor)) #2\n","print(mytensor.shape) #[2, 3]\n","value = torch.zeros(2, 2)\n","for i in range(len(mytensor)):\n","    for j in range(len(mytensor)):\n","        # print(mytensor[i])\n","        # print(mytensor[j])\n","        value[i][j] = torch.dot(mytensor[i], mytensor[j])\n","value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ddqclh-v4nXg","executionInfo":{"status":"ok","timestamp":1700422553700,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a3cdc5a1-13df-4896-85ef-1b42ee913737"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","torch.Size([2, 3])\n","CPU times: user 1.77 ms, sys: 0 ns, total: 1.77 ms\n","Wall time: 1.81 ms\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[14., 32.],\n","        [32., 77.]])"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["#matmul\n","%%time\n","mytensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(len(mytensor)) #2\n","print(mytensor.shape) #[2, 3]\n","\n","#matmul\n","print(torch.matmul(mytensor, mytensor.T))\n","print(mytensor @ mytensor.T)\n","print(torch.mm(mytensor, mytensor.T))\n","\n","#see the time difference btwn for loop and matmul"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b2-InkuV6Nkx","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":46,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3eeb837c-3d68-40e2-c330-224d4f236368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","torch.Size([2, 3])\n","tensor([[14, 32],\n","        [32, 77]])\n","tensor([[14, 32],\n","        [32, 77]])\n","tensor([[14, 32],\n","        [32, 77]])\n","CPU times: user 4.3 ms, sys: 0 ns, total: 4.3 ms\n","Wall time: 6.58 ms\n"]}]},{"cell_type":"markdown","source":["### **Tensor Aggregation**\n","- Sum\n","- Max\n","- Min\n","- Mean (i.e average)\n","- Median\n","- argmax\n","- argmin"],"metadata":{"id":"QbW9jk2lJGCg"}},{"cell_type":"code","source":["#max , default axis is max among the whole matrix, gives scalar with collapsed dimension\n","mytensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(torch.max(mytensor))\n","print(mytensor.max())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t43vgYtM7mYG","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":45,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"33844690-dbb3-40c0-ce9d-ffeb0391b3ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6)\n","tensor(6)\n"]}]},{"cell_type":"code","source":["#max , default axis is max among the whole matrix - 1D\n","mytensor = torch.tensor([1, 2, 3, 4, 5, 6])\n","print(torch.max(mytensor))\n","print(mytensor.max())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPhB3hsnajLz","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":43,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"59847786-6b0c-4d81-ce84-787ce3aaf9c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6)\n","tensor(6)\n"]}]},{"cell_type":"code","source":["#max , axis=0\n","mytensor = torch.tensor([[1, 8, 3], [4, 5, 6]])\n","print(torch.max(mytensor, axis=0))\n","print(mytensor.max(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pzEsHCEMG00","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":41,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a662995a-b90e-4da3-a34f-d9133e814ff2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.return_types.max(\n","values=tensor([4, 8, 6]),\n","indices=tensor([1, 0, 1]))\n","torch.return_types.max(\n","values=tensor([4, 8, 6]),\n","indices=tensor([1, 0, 1]))\n"]}]},{"cell_type":"code","source":["#max , axis=1\n","mytensor = torch.tensor([[3, 2, 3], [4, 5, 6]])\n","torch.max(mytensor, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYQjVxNgNHc0","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":39,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"84b1a09d-eafd-47b1-9a1d-1d38165bfa0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.return_types.max(\n","values=tensor([3, 6]),\n","indices=tensor([0, 2]))"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["#min, whole matrix\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","torch.min(mytensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZYsLnj_Maud","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":37,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"41a199c1-808f-4122-da4b-e2b472078362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(1)"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["#min, axis=0\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","torch.min(mytensor, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iu0Sv8qvM3IZ","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":35,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"dce190d3-5cfa-4351-d648-ef0924995fef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.return_types.min(\n","values=tensor([ 1, 11, 21, 31, 41]),\n","indices=tensor([0, 0, 0, 0, 0]))"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["#min, axis=1\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.min(mytensor, axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-GMuFNGOLos","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":33,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b27da996-6768-4623-9907-d8edf670268f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","torch.return_types.min(\n","values=tensor([ 1, 51]),\n","indices=tensor([0, 0]))\n"]}]},{"cell_type":"code","source":["#min, axis=0, values\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.min(mytensor, axis=0).values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvvrlvMWNz-C","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":34,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"099aa8ca-e292-45e5-a13b-0c6e6170712a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor([ 1, 11, 21, 31, 41])\n"]}]},{"cell_type":"code","source":["#min, axis=1, indices\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.min(mytensor, axis=1).indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIRVVHCsOSnw","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":32,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e0b73cd2-6a6f-478c-a83d-65d7487d5b71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor([0, 0])\n"]}]},{"cell_type":"code","source":["#mean, whole matrix, mean only accepts float or complex dtype, not long i.e int64\n","mytensor = torch.arange(1, 100, 10, dtype=torch.float32) '\n","#we can also use torch.mean(mytensor.type(torch.float32)) or mytensor.type(torch.float32).mean()\n","print(mytensor)\n","print(torch.mean(mytensor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZXfzqPmOcsC","executionInfo":{"status":"ok","timestamp":1700422554126,"user_tz":-60,"elapsed":31,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"21c43fdd-9460-4518-d7d4-494cb4533c6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.])\n","tensor(46.)\n"]}]},{"cell_type":"code","source":["#mean, axis=0, 1d tensor\n","mytensor = torch.arange(1, 100, 10, dtype=torch.float32)\n","print(mytensor)\n","print(torch.mean(mytensor, axis=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fo4mhd0uOohk","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":30,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4e17b869-4078-4dcb-f706-d0a8dd55026e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.])\n","tensor(46.)\n"]}]},{"cell_type":"code","source":["#mean, axis=0, 2d tensor\n","mytensor = torch.arange(1, 100, 10, dtype=torch.float32).reshape(2, 5)\n","print(mytensor)\n","print(torch.mean(mytensor, axis=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JWP5RDAO8bU","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":29,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"1d67554f-aa7f-4592-a51c-2bbc4a73a4b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1., 11., 21., 31., 41.],\n","        [51., 61., 71., 81., 91.]])\n","tensor([26., 36., 46., 56., 66.])\n"]}]},{"cell_type":"code","source":["#mean, axis=1, 2d tensor\n","mytensor = torch.arange(1, 100, 10, dtype=torch.float32).reshape(2, 5)\n","print(mytensor)\n","print(torch.mean(mytensor, axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xy19ZPddPJWY","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":28,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"cd0e1aea-ced9-4ed8-d41d-9ed4a3356aaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1., 11., 21., 31., 41.],\n","        [51., 61., 71., 81., 91.]])\n","tensor([21., 71.])\n"]}]},{"cell_type":"code","source":["#sum\n","mytensor = torch.arange(1, 100, 10)\n","print(mytensor)\n","print(torch.sum(mytensor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3-YOuaQPbUX","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":27,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b82ca490-7e3e-4c87-8b2a-43b893de0e7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n","tensor(460)\n"]}]},{"cell_type":"code","source":["#sum, axis=0\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.sum(mytensor, axis=0))\n","#observe how the dimension is collapsed to one dimension"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZ-R2S5bPoN1","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":26,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a826f2fd-7460-4587-bffe-a5ffec322b7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor([ 52,  72,  92, 112, 132])\n"]}]},{"cell_type":"code","source":["#sum, axis=1\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.sum(mytensor, axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cArUc54QIIj","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":24,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a7494828-85b4-46cd-dcd0-07c061952eb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor([105, 355])\n"]}]},{"cell_type":"code","source":["#argmin, argmax, whole matrix\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.argmin(mytensor))\n","print(torch.argmax(mytensor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qIrM1ynOQ3PM","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":22,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4346c25d-7903-46b1-c577-ff4612b3cc2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor(0)\n","tensor(9)\n"]}]},{"cell_type":"code","source":["#argmin, argmax, axis=0\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.argmin(mytensor, axis=0))\n","print(torch.argmax(mytensor, axis=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"burnUcSYQS8-","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":20,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6163231b-5a50-4eb8-ee97-d61937476d44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor([0, 0, 0, 0, 0])\n","tensor([1, 1, 1, 1, 1])\n"]}]},{"cell_type":"code","source":["#argmin, argmax, axis=1\n","mytensor = torch.arange(1, 100, 10).reshape(2, 5)\n","print(mytensor)\n","print(torch.argmin(mytensor, axis=1))\n","print(torch.argmax(mytensor, axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AxpovAUQdrh","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":19,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"abc6ec69-f406-4758-fdc4-4d14e36c486f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1, 11, 21, 31, 41],\n","        [51, 61, 71, 81, 91]])\n","tensor([0, 0])\n","tensor([4, 4])\n"]}]},{"cell_type":"markdown","source":["### **Tensor Reshaping, Viewing, stacking, squeezing, unsqueezing, Permuting**\n","\n","In simple terms, all the below are used to manipulate the input tensors shape in required dimension\n","- reshape - reshapes an input tensor to a defined shape\n","- view - return a view of an input tensor of certain shape but keep the memory as the original tensor, share the same memory as original tensor\n","- stack (stack with axis, vstack, hstack) - combine/contanate multiple tensors on top of each other(vstack) or side by side(hstack)\n","- squeeze - removes all `1` dimensions from a tensor\n","- unsqueeze - add a `1` dimension to a target tensor\n","- permute - return a view of the input with dimensions permuted(swapped) in a certain specified way"],"metadata":{"id":"rIex2z1IbSnc"}},{"cell_type":"code","source":["mytensor = torch.arange(1., 10.)\n","mytensor, mytensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBfQAeKzQlGh","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":18,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3ae08789-9487-4e87-a071-cf7fb51112a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["#reshape - adding extra axis along dimension 0\n","#make sure the dimensions of reshaped tensor should match with the original tensor\n","#multiplication(no. of elements) of shape should result in original tensor shape\n","\n","mytensor = torch.arange(1., 10.) #shape (9,)\n","mytensor_reshaped = mytensor.reshape(1, 9)\n","mytensor_reshaped, mytensor_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gg6yOk3JmmpH","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":17,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4f7057e8-fbc0-4945-c124-715965aa1191"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["#reshape - adding new dimension along dimension 1\n","mytensor = torch.arange(1., 10.)\n","mytensor_reshaped = mytensor.reshape(9, 1)\n","mytensor_reshaped, mytensor_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufGW31vQmmXN","executionInfo":{"status":"ok","timestamp":1700422554127,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"cb39670c-8087-4e1f-a05c-073f5f4843b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1.],\n","         [2.],\n","         [3.],\n","         [4.],\n","         [5.],\n","         [6.],\n","         [7.],\n","         [8.],\n","         [9.]]),\n"," torch.Size([9, 1]))"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["#reshape - so that no. of elements of original tensor and reshaped tensor match\n","mytensor = torch.arange(1., 10.) #(9,)\n","mytensor_reshaped = mytensor.reshape(3, 3)\n","mytensor_reshaped, mytensor_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6d9aDm6mmIp","executionInfo":{"status":"ok","timestamp":1700422554529,"user_tz":-60,"elapsed":417,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d9ca32c5-ec56-48b4-e95b-3d51da99cd0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 2., 3.],\n","         [4., 5., 6.],\n","         [7., 8., 9.]]),\n"," torch.Size([3, 3]))"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["#reshape - to 3D\n","mytensor = torch.arange(1., 10.)\n","mytensor_reshaped = mytensor.reshape(3, 3, 1) # creates 3 (3,1) matrices\n","mytensor_reshaped, mytensor_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnP70CzFnmZN","executionInfo":{"status":"ok","timestamp":1700422554530,"user_tz":-60,"elapsed":33,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"993808f6-5343-4818-f468-c58ee73539aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1.],\n","          [2.],\n","          [3.]],\n"," \n","         [[4.],\n","          [5.],\n","          [6.]],\n"," \n","         [[7.],\n","          [8.],\n","          [9.]]]),\n"," torch.Size([3, 3, 1]))"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["#reshape - to 3D\n","mytensor = torch.arange(1., 10.)\n","mytensor_reshaped = mytensor.reshape(9, 1, 1)\n","mytensor_reshaped, mytensor_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hd0C-leHnqYG","executionInfo":{"status":"ok","timestamp":1700422554530,"user_tz":-60,"elapsed":30,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ed724576-a751-4ed8-c3ee-7ce029292672"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1.]],\n"," \n","         [[2.]],\n"," \n","         [[3.]],\n"," \n","         [[4.]],\n"," \n","         [[5.]],\n"," \n","         [[6.]],\n"," \n","         [[7.]],\n"," \n","         [[8.]],\n"," \n","         [[9.]]]),\n"," torch.Size([9, 1, 1]))"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["#reshape - throws error if no. of elements in the reshape shape doesnt match with original tensor elements\n","#here we are trying to put 9 elements in 10 elements tensor - so it throws error\n","mytensor = torch.arange(1., 10.) #9 elements\n","mytensor_reshaped = mytensor.reshape(10, 1)\n","#mytensor_reshaped = mytensor.reshape(7, 1) #also throws error as we are trying to squeeze 9 elements in 7 element tensor\n","mytensor_reshaped, mytensor_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"3CkZlNpcnxiG","executionInfo":{"status":"error","timestamp":1700422564978,"user_tz":-60,"elapsed":15,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"cd320674-1d2b-4073-e9f1-91145d5acf31"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-bd80e79c84ea>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#here we are trying to put 9 elements in 10 elements tensor - so it throws error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmytensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmytensor_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmytensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#mytensor_reshaped = mytensor.reshape(7, 1) #also throws error as we are trying to squeeze 9 elements in 7 element tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmytensor_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmytensor_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[10, 1]' is invalid for input of size 9"]}]},{"cell_type":"code","source":["#view\n","mytensor = torch.arange(1., 10.) #shape (9,)\n","z = mytensor.view(1, 9) #changes the view of mytensor to (1, 9) but doesnt alter the shape of original mytensor here. It shows the view of original tensor in specified shape\n","z, z.shape, mytensor.shape\n","\n","#If you observe, view is similar to reshape, but the only the difference is,\n","#view variable z shares the memory with the original tensor mytensor here\n","#z is just a different view of mytensor, it shares the same memory as mytensor,\n","#it wont create new memory for z unlike reshape that creates new memory instance\n","#if you change something in z or mytensor, the other tensor value also changes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-dnwRYsn44R","executionInfo":{"status":"ok","timestamp":1700422565291,"user_tz":-60,"elapsed":19,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"459cb00f-48aa-4e63-b492-28548a6432e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n"," torch.Size([1, 9]),\n"," torch.Size([9]))"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["#Changing z(i.e view of original tensor) changes also the original tensor\n","#cuz they share the same memory, z is just a view of original tensor\n","\n","#shape (9,)\n","z = mytensor.view(1, 9) #changes the view of mytensor to (1, 9)\n","\n","#lets change z(may be the modify one element in z) and observe it changes mytensor too\n","z[:, 0] = 11\n","z, z.shape, mytensor, mytensor.shape\n","#modified the element in both, the shape of both doesnt get altered though"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXwfXWC5qRQY","executionInfo":{"status":"ok","timestamp":1700422565291,"user_tz":-60,"elapsed":18,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"552b3902-4559-4858-88cd-dfe2cfb21592"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[11.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]]),\n"," torch.Size([1, 9]),\n"," tensor([11.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]),\n"," torch.Size([9]))"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["#stack or vstack\n","#stack on top of each other like vstack - note shapes of stacking matrices should match\n","#Note: stacking 1D vectors creates 2D matrix - it is creating a new dimension in the specfied axis\n","\n","x = torch.arange(1., 10.) #shape(9,)\n","print(x)\n","y = torch.arange(11., 20.) #shape(9,)\n","print(y)\n","\n","x_stacked = torch.stack([x, y], axis=0) #vstack\n","x_stacked, x_stacked.shape\n","\n","#think of it as it contantenating the dimension on specified axis position"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_iPYR0Or2fP","executionInfo":{"status":"ok","timestamp":1700422565291,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ecba5e21-27c1-46ff-df02-feb62f1f9b90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n","tensor([11., 12., 13., 14., 15., 16., 17., 18., 19.])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n","         [11., 12., 13., 14., 15., 16., 17., 18., 19.]]),\n"," torch.Size([2, 9]))"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["#stack or hstack\n","#stack side by side like hstack - 1D vectors, stacking results in 2D matrix\n","\n","x = torch.arange(1., 10.) #shape(9,)\n","print(x)\n","y = torch.arange(11., 20.) ##shape(9,)\n","print(y)\n","\n","x_stacked = torch.stack([x, y], axis=1) #hstack\n","x_stacked, x_stacked.shape\n","\n","#observe how each 1D vector is changed as column vector\n","#think of it as it contantenating the dimension on specified axis position"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP0gVw9dtCgb","executionInfo":{"status":"ok","timestamp":1700422565292,"user_tz":-60,"elapsed":16,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"8e4ac8d8-7fa1-4dc1-e1b5-1f6124634be8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n","tensor([11., 12., 13., 14., 15., 16., 17., 18., 19.])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 1., 11.],\n","         [ 2., 12.],\n","         [ 3., 13.],\n","         [ 4., 14.],\n","         [ 5., 15.],\n","         [ 6., 16.],\n","         [ 7., 17.],\n","         [ 8., 18.],\n","         [ 9., 19.]]),\n"," torch.Size([9, 2]))"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["#vstack on top of each other like vstack for 2D matrices - results in 3D matrix\n","\n","x = torch.arange(1., 10.). reshape(1, 9)\n","print(x)\n","y = torch.arange(11., 20.).reshape(1, 9)\n","print(y)\n","\n","x_stacked = torch.stack([x, y], dim=0) #vstack\n","x_stacked, x_stacked.shape\n","\n","#observe the shape - it is 2 - (1,9) matrices i.e a 3d Matrix\n","#concatenates along the specified axis, at axis position 0, it concatenates both the matrices (2, 1, 9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jo8zWMX1umJK","executionInfo":{"status":"ok","timestamp":1700422565292,"user_tz":-60,"elapsed":15,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d44c623a-cfbc-4b76-ebc2-0c382e64ef1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n","tensor([[11., 12., 13., 14., 15., 16., 17., 18., 19.]])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]],\n"," \n","         [[11., 12., 13., 14., 15., 16., 17., 18., 19.]]]),\n"," torch.Size([2, 1, 9]))"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["#hstack side by side like hstack for 2D matrices - results in 3D matrix\n","\n","x = torch.arange(1., 10.). reshape(1, 9)\n","print(x)\n","y = torch.arange(11., 20.).reshape(1, 9)\n","print(y)\n","\n","x_stacked = torch.stack([x, y], axis=1) #hstack\n","x_stacked, x_stacked.shape\n","\n","#observe the shape, it is 1 - (2, 9) matrices\n","#concatenates along the specified axis, at axis position 1, it concatenates both the matrices (1, 2, 9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vL12Mzd3tZFr","executionInfo":{"status":"ok","timestamp":1700422565292,"user_tz":-60,"elapsed":13,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b657e7d5-7ef8-4e33-cd2f-88b226ea96d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n","tensor([[11., 12., 13., 14., 15., 16., 17., 18., 19.]])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n","          [11., 12., 13., 14., 15., 16., 17., 18., 19.]]]),\n"," torch.Size([1, 2, 9]))"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["#many stacks of 1D vstack  - contanates on specified axis and create a 2D matrix\n","x = torch.arange(1., 10.) #(9,)\n","x_stacked = torch.stack([x, x, x, x], dim=0) #vstack - results in (4, 9)\n","x_stacked, x_stacked.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHiVXDK0tjxQ","executionInfo":{"status":"ok","timestamp":1700422693824,"user_tz":-60,"elapsed":7,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"66f62e23-aee1-4d2b-d28d-fdfadce379b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n","         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n","         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n","         [1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n"," torch.Size([4, 9]))"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["#many stacks of 1D hstack\n","x = torch.arange(1., 10.) #(9,)\n","x_stacked = torch.stack([x, x, x, x], dim=1) #hstack - results in (9, 4)\n","x_stacked, x_stacked.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nDVU0AKF4Xp","executionInfo":{"status":"ok","timestamp":1700422749951,"user_tz":-60,"elapsed":256,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"647644f4-48e2-40b3-9ab0-c891b681b8e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1., 1.],\n","         [2., 2., 2., 2.],\n","         [3., 3., 3., 3.],\n","         [4., 4., 4., 4.],\n","         [5., 5., 5., 5.],\n","         [6., 6., 6., 6.],\n","         [7., 7., 7., 7.],\n","         [8., 8., 8., 8.],\n","         [9., 9., 9., 9.]]),\n"," torch.Size([9, 4]))"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["#many stacks of 2D - vstack - creates 3D matrix\n","x = torch.arange(1., 10.). reshape(1, 9)\n","x_stacked = torch.stack([x, x, x, x], dim=0) #hstack - results in (4, 1, 9)\n","x_stacked, x_stacked.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xfdyh8jKGDKx","executionInfo":{"status":"ok","timestamp":1700422793776,"user_tz":-60,"elapsed":250,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"04b1394a-461f-46ae-ebaf-dc0c7c0d57cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1., 2., 3., 4., 5., 6., 7., 8., 9.]],\n"," \n","         [[1., 2., 3., 4., 5., 6., 7., 8., 9.]],\n"," \n","         [[1., 2., 3., 4., 5., 6., 7., 8., 9.]],\n"," \n","         [[1., 2., 3., 4., 5., 6., 7., 8., 9.]]]),\n"," torch.Size([4, 1, 9]))"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["#many stacks of 2D - hstack\n","x = torch.arange(1., 10.). reshape(1, 9)\n","x_stacked = torch.stack([x, x, x, x], dim=1) #hstack - results in (1, 4, 9)\n","x_stacked, x_stacked.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOOcDV4LysDm","executionInfo":{"status":"ok","timestamp":1700422816859,"user_tz":-60,"elapsed":263,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d8daeb5f-bc35-497b-b529-5348773f584b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n","          [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n","          [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n","          [1., 2., 3., 4., 5., 6., 7., 8., 9.]]]),\n"," torch.Size([1, 4, 9]))"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["#cat is similar to stack but wont create a new dimension in the specified axis\n","#Concatenates the given sequence of tensors in the given dimension.\n","#All tensors must either have the same shape (except in the concatenating dimension) or be empty.\n","#torch.cat() can be seen as an inverse operation for torch.split() and torch.chunk().\n","#While torch.stack() concatenates the given sequence along a new dimension.\n","import torch\n","x = torch.arange(6).reshape(2, 3)\n","myconcat = torch.cat([x, x]) #default is axis=0, vertical concat\n","x, x.size(), myconcat, myconcat.shape\n","\n","#observe how they are concstenated in the 0th dimension without creating new axis, also 2d concats results in 2d concats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSlSw-zqOnj8","executionInfo":{"status":"ok","timestamp":1701515755544,"user_tz":-60,"elapsed":12,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"77f46708-3f6e-4225-d8a8-a74fdfb0ce00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1, 2],\n","         [3, 4, 5]]),\n"," torch.Size([2, 3]),\n"," tensor([[0, 1, 2],\n","         [3, 4, 5],\n","         [0, 1, 2],\n","         [3, 4, 5]]),\n"," torch.Size([4, 3]))"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["#torch.cat() with axis=1, horizontal concat\n","import torch\n","x = torch.arange(6).reshape(2, 3)\n","myconcat = torch.cat([x, x, x], axis=1) #default is axis=0\n","x, x.size(), myconcat, myconcat.shape #results in (2, 9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izQGfJ5dP3u5","executionInfo":{"status":"ok","timestamp":1701515964486,"user_tz":-60,"elapsed":208,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"1cdafd6e-2ebc-4fc2-c60b-63d47c34cd05"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1, 2],\n","         [3, 4, 5]]),\n"," torch.Size([2, 3]),\n"," tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n","         [3, 4, 5, 3, 4, 5, 3, 4, 5]]),\n"," torch.Size([2, 9]))"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#torch.cat() with axis=1, horizontal concat\n","import torch\n","x = torch.arange(6).reshape(2, 3)\n","myconcat = torch.cat([x, x, x], axis=1) #default is axis=0\n","#les change original tensor and see how it effects the concatenated tensor - it wont affect as they dont share memory\n","x[0, 1] = 9 #wont change the concatenated tensor\n","x, x.size(), myconcat, myconcat.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6xj6rSEQs6F","executionInfo":{"status":"ok","timestamp":1701516143670,"user_tz":-60,"elapsed":206,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"7a4b2fdd-446b-4af8-b3a1-d41f1e6e96c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 9, 2],\n","         [3, 4, 5]]),\n"," torch.Size([2, 3]),\n"," tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n","         [3, 4, 5, 3, 4, 5, 3, 4, 5]]),\n"," torch.Size([2, 9]))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#torch.split(tensor, split_size_or_sections, dim=0) opposite of concatenation\n","#Splits the tensor into chunks. Each chunk is a view of the original tensor.\n","#If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible).\n","#Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.\n","#If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections.\n","#returns tuple of splits\n","a = torch.arange(10).reshape(5, 2)\n","z = torch.split(a, 3, dim=0) #returns splits by using dim=0/split size = 5/3 = 1 (3, 2) and remaining (2, 2)\n","a, a.shape, z, type(z), len(z) #z is view of a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqoZafncQg9I","executionInfo":{"status":"ok","timestamp":1701516411609,"user_tz":-60,"elapsed":8,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d228270b-d142-40c7-8add-d066ad438a09"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]),\n"," torch.Size([5, 2]),\n"," (tensor([[0, 1],\n","          [2, 3],\n","          [4, 5]]),\n","  tensor([[6, 7],\n","          [8, 9]])),\n"," tuple,\n"," 2)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#split with 2 as split size along dim 0\n","a = torch.arange(10).reshape(5, 2)\n","z = torch.split(a, 2, dim=0) #returns splits by using dim=0/split size = 5/2 = 2 (2, 2) and remaining (1, 2)\n","a, a.shape, z, type(z), len(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdsZCHJ_Spi5","executionInfo":{"status":"ok","timestamp":1701516648780,"user_tz":-60,"elapsed":197,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"f7e90aec-bc9a-49a4-cebe-60f9cea0c078"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]),\n"," torch.Size([5, 2]),\n"," (tensor([[0, 1],\n","          [2, 3]]),\n","  tensor([[4, 5],\n","          [6, 7]]),\n","  tensor([[8, 9]])),\n"," tuple,\n"," 3)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#split with 2 as split size along dim 1\n","a = torch.arange(10).reshape(5, 2)\n","z = torch.split(a, 2, dim=1) #returns splits by using dim=1/split size = 2/2 = 1 (5, 2)\n","a, a.shape, z, type(z), len(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JttnGi0pTLT5","executionInfo":{"status":"ok","timestamp":1701516767508,"user_tz":-60,"elapsed":666,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"51bf8c96-1c25-46e2-ac90-5e39e0cb381e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]),\n"," torch.Size([5, 2]),\n"," (tensor([[0, 1],\n","          [2, 3],\n","          [4, 5],\n","          [6, 7],\n","          [8, 9]]),),\n"," tuple,\n"," 1)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#split with list\n","a = torch.arange(10).reshape(5, 2)\n","y = torch.split(a, [4, 1], dim=0) #note t he split size list should sum up to specified dim, otherwise split throws error\n","a, a.shape, y, type(y), len(y) #number of splits = len(splits), each split is of size specifies"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18xHM5KITjFq","executionInfo":{"status":"ok","timestamp":1701517175846,"user_tz":-60,"elapsed":200,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"5b1df2d4-ae28-455b-8e71-c1f87f66e8bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]),\n"," torch.Size([5, 2]),\n"," (tensor([[0, 1],\n","          [2, 3],\n","          [4, 5],\n","          [6, 7]]),\n","  tensor([[8, 9]])),\n"," tuple,\n"," 2)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#split with list\n","a = torch.arange(10).reshape(5, 2)\n","y = torch.split(a, [1, 1, 3], dim=0) #note t he split size list should sum up to specified dim, otherwise split throws error\n","a, a.shape, y, type(y), len(y) #number of splits = len(splits), each split is of size specifies"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XimO_jgcU9lK","executionInfo":{"status":"ok","timestamp":1701517200379,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"1ed47342-af7f-4a94-80db-9f53764943a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0, 1],\n","         [2, 3],\n","         [4, 5],\n","         [6, 7],\n","         [8, 9]]),\n"," torch.Size([5, 2]),\n"," (tensor([[0, 1]]),\n","  tensor([[2, 3]]),\n","  tensor([[4, 5],\n","          [6, 7],\n","          [8, 9]])),\n"," tuple,\n"," 3)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#Squeeze - removes all single dimensions\n","x = torch.rand(1, 9) #2D rand matrix - (1, 9) shape\n","x_squeezed = torch.squeeze(x) #removes all single(i.e 1) dimensions\n","x_squeezed, x_squeezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2YPYbE0Iy6lX","executionInfo":{"status":"ok","timestamp":1700423168998,"user_tz":-60,"elapsed":277,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e4c2d27c-744b-4dca-878e-f24bc75c0096"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.5722, 0.3600, 0.3053, 0.8419, 0.0156, 0.9315, 0.6137, 0.6469, 0.8203]),\n"," torch.Size([9]))"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["#Squeeze\n","x = torch.rand(3, 1, 9)\n","x_squeezed = torch.squeeze(x) #removes all single dimensions\n","x_squeezed, x_squeezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79jJWeZjG80p","executionInfo":{"status":"ok","timestamp":1700423206759,"user_tz":-60,"elapsed":278,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ffa54b8e-6cc6-41e1-c52a-e3567b892c8f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.9409, 0.6097, 0.7303, 0.7773, 0.4734, 0.5287, 0.5762, 0.1418, 0.0549],\n","         [0.3758, 0.8665, 0.5548, 0.3031, 0.1574, 0.1892, 0.7647, 0.3592, 0.3243],\n","         [0.8961, 0.2962, 0.5720, 0.7616, 0.5108, 0.6592, 0.4729, 0.0958, 0.2991]]),\n"," torch.Size([3, 9]))"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["#Squeeze\n","x = torch.rand(1, 1, 9)\n","x_squeezed = torch.squeeze(x) #removes all single dimensions\n","x_squeezed, x_squeezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Is0uZKYHHwO4","executionInfo":{"status":"ok","timestamp":1700423229352,"user_tz":-60,"elapsed":322,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"682df7bb-be4a-4f6b-dd3c-0247a03dc953"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0.0827, 0.4191, 0.7804, 0.9521, 0.0110, 0.4553, 0.7805, 0.7213, 0.2481]),\n"," torch.Size([9]))"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["#squeeze with axis=0\n","x = torch.rand(1, 1, 9)\n","x_squeezed = torch.squeeze(x, axis=0) #removes single dimensions in the specified axis\n","x_squeezed, x_squeezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R69HfSQhH1va","executionInfo":{"status":"ok","timestamp":1700423364312,"user_tz":-60,"elapsed":304,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"132e624a-fe81-4c6d-c9ae-d1e3f0cc4069"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.9369, 0.6349, 0.0922, 0.0212, 0.2508, 0.9257, 0.3828, 0.3973, 0.1609]]),\n"," torch.Size([1, 9]))"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["#squeeze with axis=1\n","x = torch.rand(1, 1, 9)\n","x_squeezed = torch.squeeze(x, axis=1) #removes single dimensions in the specified axis\n","x_squeezed, x_squeezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kb2Q8UqZIWsW","executionInfo":{"status":"ok","timestamp":1700423432628,"user_tz":-60,"elapsed":330,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"1da31e30-fc08-4581-9258-a3141241223d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.9161, 0.1603, 0.4227, 0.1836, 0.5709, 0.7000, 0.7228, 0.2823, 0.4317]]),\n"," torch.Size([1, 9]))"]},"metadata":{},"execution_count":111}]},{"cell_type":"code","source":["#squeeze with axis=2, if there is no single dim in the specified axis, then it doesnt change anything\n","x = torch.rand(1, 1, 9)\n","x_squeezed = torch.squeeze(x, axis=2)\n","x_squeezed, x_squeezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKNfI2zmInWt","executionInfo":{"status":"ok","timestamp":1700423484668,"user_tz":-60,"elapsed":380,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"c17cdafc-9f2c-4844-b874-ca51db36627b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[0.5244, 0.0485, 0.3735, 0.2527, 0.5644, 0.1040, 0.8604, 0.8302,\n","           0.9635]]]),\n"," torch.Size([1, 1, 9]))"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["#unsqueeze() - adds a single dimension to the target tensor at the specific dim\n","x = torch.arange(1., 10.) #(9,)\n","print(x.shape)\n","x_unsqueezed = torch.unsqueeze(x, dim=0)\n","x_unsqueezed, x_unsqueezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Xoo6UqcI0Dk","executionInfo":{"status":"ok","timestamp":1700424022033,"user_tz":-60,"elapsed":318,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"bc2ba186-d41b-4c8d-d620-cb0b3edb5692"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([9])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["#unsqueeze() - adds a single dimension to the target tensor at the specific dim\n","x = torch.arange(1., 10.) #(9,)\n","print(x.shape)\n","x_unsqueezed = torch.unsqueeze(x, dim=1)\n","x_unsqueezed, x_unsqueezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRmsLvMlKyoO","executionInfo":{"status":"ok","timestamp":1700424032277,"user_tz":-60,"elapsed":305,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b104f331-59d8-4006-d4f0-9991bd824339"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([9])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[1.],\n","         [2.],\n","         [3.],\n","         [4.],\n","         [5.],\n","         [6.],\n","         [7.],\n","         [8.],\n","         [9.]]),\n"," torch.Size([9, 1]))"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["#unsqueeze() - adds a single dimension to the target tensor at the specific dim\n","x = torch.rand(2, 3) #2D matrix shape (2, 3)\n","print(x.shape)\n","x_unsqueezed = torch.unsqueeze(x, dim=1) #adds new dim at axis=1 position\n","x_unsqueezed, x_unsqueezed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eisp9EP0K5xg","executionInfo":{"status":"ok","timestamp":1700424095568,"user_tz":-60,"elapsed":318,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a9e6b2e6-848f-47b8-9887-150543d02473"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[0.9187, 0.7700, 0.4104]],\n"," \n","         [[0.6246, 0.7881, 0.8985]]]),\n"," torch.Size([2, 1, 3]))"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["#permute() - rearranges/swaps the dimensions of a target tensor with the specified dimensions\n","#this returns the view of a original input tensor with the specified dimensions - shared memory with original tensor\n","#Note:number of dimensions should match with the original tensor\n","#permute is used specially with images\n","\n","x = torch.rand(2, 3) #2D shape - (2, 3), axis=0 is 2, axis=1 is 3\n","print(x.shape)\n","print(x.ndim)\n","x_permuted = torch.permute(x, (1, 0)) #rearranges axis 0 with axis 1 - resultant shape is (3, 2)\n","x_permuted, x_permuted.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVMFgpVcLJNa","executionInfo":{"status":"ok","timestamp":1700425076856,"user_tz":-60,"elapsed":321,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a82d4fd4-2aa1-4bd3-8888-3ba0bc96ee1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3])\n","2\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.9214, 0.1027],\n","         [0.1448, 0.3962],\n","         [0.1083, 0.5010]]),\n"," torch.Size([3, 2]))"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["x = torch.rand(2, 3, 5) #axis=0 is 2, axis=1 is 3, axis=2 is 5\n","print(x.shape)\n","print(x.ndim)\n","x_permuted = torch.permute(x, (2, 0, 1)) #rearranges and the result will have shape (5, 2, 3)\n","x_permuted, x_permuted.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXmvaAIMN1Yk","executionInfo":{"status":"ok","timestamp":1700425217450,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"d75b3c5c-06f1-454a-cc87-190a25088276"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 5])\n","3\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[0.5971, 0.9160, 0.0104],\n","          [0.4019, 0.6722, 0.9785]],\n"," \n","         [[0.2735, 0.6564, 0.9202],\n","          [0.5873, 0.5792, 0.1812]],\n"," \n","         [[0.9070, 0.4338, 0.5861],\n","          [0.7571, 0.2866, 0.4753]],\n"," \n","         [[0.4250, 0.2546, 0.2385],\n","          [0.1199, 0.7644, 0.7839]],\n"," \n","         [[0.9421, 0.6633, 0.8925],\n","          [0.4988, 0.8506, 0.5455]]]),\n"," torch.Size([5, 2, 3]))"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["#permute the image of (h, w, c) to (c, h, w)\n","img_original = torch.rand(size=(224, 224, 3))\n","img_permuted = img_original.permute(2, 1, 0)\n","img_permuted.size(), img_original.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KTDDFzynPUNE","executionInfo":{"status":"ok","timestamp":1700425774605,"user_tz":-60,"elapsed":17,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"349df308-8876-40ff-9547-d5e31d95e345"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([3, 224, 224]), torch.Size([224, 224, 3]))"]},"metadata":{},"execution_count":125}]},{"cell_type":"markdown","source":["### **Tensor Indexing**\n","    Indexing in pytorch is similary to numpy indexing"],"metadata":{"id":"9LkWMQtRR8Ca"}},{"cell_type":"code","source":["x = torch.arange(1, 10).reshape(1, 3, 3)\n","x, x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSjfdUV7RUax","executionInfo":{"status":"ok","timestamp":1700426015440,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"39c6c5c8-35f6-4c56-f59a-0c03c5df67a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[1, 2, 3],\n","          [4, 5, 6],\n","          [7, 8, 9]]]),\n"," torch.Size([1, 3, 3]))"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["#access the first element in 3dim matrix - returns 2D matrix in first index\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[0], x[0].size() #index on the first dim, dim=0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLUW1xuJSd1Y","executionInfo":{"status":"ok","timestamp":1700426110621,"user_tz":-60,"elapsed":272,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3b9a2a7b-63e1-42d6-c4f7-a5fac0794e69"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1, 2, 3],\n","         [4, 5, 6],\n","         [7, 8, 9]]),\n"," torch.Size([3, 3]))"]},"metadata":{},"execution_count":128}]},{"cell_type":"code","source":["#index on the middle bracket, second dim, dim=1\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[0][0], x[0, 0], x[0][0].size() #returns 0th index 2D matrix's of dim (3, 3), 0th row in (3, 3)\n","#observe we get 1D when we index 2 axis in a 3D matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aPXsK3ZESwg7","executionInfo":{"status":"ok","timestamp":1700426296564,"user_tz":-60,"elapsed":20,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"315c6eea-ad54-452f-daf0-98dadd969c92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([1, 2, 3]), tensor([1, 2, 3]), torch.Size([3]))"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["#index on the inner bracket i.e last dim, dim=2\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[0][0][0], x[0, 0, 0], x[0][0][0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lDWWNbFTZld","executionInfo":{"status":"ok","timestamp":1700426398936,"user_tz":-60,"elapsed":22,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a621c62d-56a8-4acc-cad0-317e85cda038"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(1), tensor(1), torch.Size([]))"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","source":["#index on the inner bracket i.e last dim, dim=2\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[0][0][1], x[0, 0, 1], x[0][0][1].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DTuwFEUT7m6","executionInfo":{"status":"ok","timestamp":1700426487053,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e67eaeac-7e03-47fc-c721-72897d53c3de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(2), tensor(2), torch.Size([]))"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["#index on the inner bracket i.e last dim, dim=2 along with middle bracket dim=1 with index 1\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[0][1][1], x[0, 1, 1], x[0][1][1].size()\n","#observe we got scalar here as we are indexing on all the axis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1yMCm5-URBU","executionInfo":{"status":"ok","timestamp":1700426507294,"user_tz":-60,"elapsed":8,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3004499c-298f-4cd8-c8b2-eeb15c96682e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(5), tensor(5), torch.Size([]))"]},"metadata":{},"execution_count":133}]},{"cell_type":"code","source":["#index with first bracket=1\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[1][1][1], x[1, 1, 1], x[1][1][1].size() #throws error as we have only 1 element in dim 0 - (1, 3, 3) => only 1 (3,3) matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"Y2zXrE4aUWGx","executionInfo":{"status":"error","timestamp":1700426595038,"user_tz":-60,"elapsed":263,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"63136ff0-3c73-43a0-e272-49d50565e187"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-134-0ced06503fa3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#index on the inner bracket i.e last dim, dim=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#throws error as we have only element in dim 0 - (1, 3, 3) => only 1 (3,3) matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"]}]},{"cell_type":"code","source":["#index on the inner bracket i.e last dim, dim=2\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[0][1][1], x[0, 1, 1], x[0][1][1].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bknQLYQUrcb","executionInfo":{"status":"ok","timestamp":1700426647201,"user_tz":-60,"elapsed":269,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"9c296a35-b372-4e29-e8b1-51cb2a8d2c68"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(5), tensor(5), torch.Size([]))"]},"metadata":{},"execution_count":135}]},{"cell_type":"code","source":["#: - get all the elements in 0th and 1st dim but only index 1 of second dim\n","x = torch.arange(1, 10).reshape(1, 3, 3)\n","x[:, :, 1], x[:, :, 1].size() #returns 2D matrix of remaining dimensions shape(where we used :) instead of specified dim\n","# x[:][:][1], x[:][:][1].size() #this wont work, use only the above representation when using :"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzdVmAHLU4M1","executionInfo":{"status":"ok","timestamp":1700426858004,"user_tz":-60,"elapsed":267,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"493af8b3-88e2-4c59-f0d4-9c2a72c2dec7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[2, 5, 8]]), torch.Size([1, 3]))"]},"metadata":{},"execution_count":140}]},{"cell_type":"code","source":["#: - get all the elements in 0th and 2nd dim but only index 1 of first dim\n","x = torch.arange(1, 19).reshape(3, 2, 3)\n","print(x)\n","x[:, 1, :], x[:, 1, :].size() #returns 2D matrix of remaning dimensions shape(where we used :) instead of specified dim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7T7ucuABVNLF","executionInfo":{"status":"ok","timestamp":1700427089907,"user_tz":-60,"elapsed":389,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6a94dcbd-09c2-4690-d2dd-d4618819abbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]],\n","\n","        [[13, 14, 15],\n","         [16, 17, 18]]])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 4,  5,  6],\n","         [10, 11, 12],\n","         [16, 17, 18]]),\n"," torch.Size([3, 3]))"]},"metadata":{},"execution_count":144}]},{"cell_type":"code","source":["#: - get all the elements in 0th but only index 1 of second dim, 1 of third dim\n","x = torch.arange(1, 19).reshape(3, 2, 3)\n","print(x)\n","x[:, 1, 1], x[:, 1, 1].size() #returns 1D matrix of remaining dimensions shape(where we used :) instead of specified dim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRujJ8SZWaKb","executionInfo":{"status":"ok","timestamp":1700427290712,"user_tz":-60,"elapsed":315,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"cb06fb22-5278-46b9-c36e-e9c126ddc7d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]],\n","\n","        [[13, 14, 15],\n","         [16, 17, 18]]])\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([ 5, 11, 17]), torch.Size([3]))"]},"metadata":{},"execution_count":145}]},{"cell_type":"markdown","source":["### **Pytorch tensors and numpy**\n","- torch.from_numpy(ndarray) - Data in numpy array to Pytorch tensor - Changes in the NumPy array reflects in the tensor.\n","- torch.Tensor.numpy() - Pytorch tensor to numpy array - shares memory. A change in the tensor reflects in the NumPy array."],"metadata":{"id":"s0Z25TjOYIkX"}},{"cell_type":"code","source":["#convert numpy array to torch tensor\n","import numpy as np\n","myarray = np.random.rand(2, 3)\n","print(myarray.shape)\n","print(type(myarray))\n","\n","#converting to tensor\n","mytensor = torch.from_numpy(myarray)\n","print(mytensor) #observe the dtype is float64, cux the default dtype for np is float64, hence conversion is also float64\n","print(mytensor.shape)\n","print(type(mytensor))\n","\n","#note but for torch,usually the default dtype is float32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45MYIITxXVQw","executionInfo":{"status":"ok","timestamp":1700428029633,"user_tz":-60,"elapsed":9,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"45b8361f-873f-439f-92e3-01d9b8a5c92f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 3)\n","<class 'numpy.ndarray'>\n","tensor([[0.8800, 0.5006, 0.8982],\n","        [0.5433, 0.8242, 0.1111]], dtype=torch.float64)\n","torch.Size([2, 3])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["#change in numpy array reflect in tensor\n","import numpy as np\n","myarray = np.ones((2, 3))\n","\n","#converting to tensor\n","mytensor = torch.from_numpy(myarray)\n","\n","print(mytensor)\n","print(myarray)\n","\n","#change numpy array\n","myarray[:, 1] = 5\n","print(mytensor)\n","print(myarray)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69snOqi3tbVt","executionInfo":{"status":"ok","timestamp":1703167877967,"user_tz":-60,"elapsed":259,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b2fb5abc-d9c5-4137-cb65-d820c66705c2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n","[[1. 1. 1.]\n"," [1. 1. 1.]]\n","tensor([[1., 5., 1.],\n","        [1., 5., 1.]], dtype=torch.float64)\n","[[1. 5. 1.]\n"," [1. 5. 1.]]\n"]}]},{"cell_type":"code","source":["#convert torch tensor to numpy array\n","mytensor = torch.rand(2, 3)\n","print(type(mytensor))\n","\n","#converting to numpy\n","myarray = torch.Tensor(mytensor).numpy() #myarray = mytensor.numpy() also works\n","print(myarray)\n","print(myarray.dtype) #float32, cuz torch default dtype is float32\n","print(myarray.shape)\n","print(type(myarray))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPbX5-BLZBNr","executionInfo":{"status":"ok","timestamp":1703167569021,"user_tz":-60,"elapsed":346,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"9d38cb8d-2bdf-48aa-8809-1557bb9fd24b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","[[0.19944525 0.53114545 0.21373248]\n"," [0.3263812  0.1673665  0.24456131]]\n","float32\n","(2, 3)\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["#chnage in tensor chnages numpy array as they share memory when using .numpy()\n","mytensor = torch.ones(2, 3)\n","\n","#converting to numpy\n","myarray = mytensor.numpy() #myarray = mytensor.numpy() also works\n","print(mytensor)\n","print(myarray)\n","\n","#modify the tensor\n","mytensor[:, 1] = 3\n","mytensor, myarray"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4O_vBKMmsrXx","executionInfo":{"status":"ok","timestamp":1703167714487,"user_tz":-60,"elapsed":12,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"90c80e21-8142-4ac4-e35e-3013451b66a3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n","[[1. 1. 1.]\n"," [1. 1. 1.]]\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 3., 1.],\n","         [1., 3., 1.]]),\n"," array([[1., 3., 1.],\n","        [1., 3., 1.]], dtype=float32))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["#what will happen, if we change the numpy array, then, what happens to tensor that is constructed from ndarray? - it wont chnage as they dont share memory like view\n","import numpy as np\n","myarray = np.arange(1, 10).reshape(3, 3)\n","print(myarray)\n","\n","#converting to tensor\n","mytensor = torch.from_numpy(myarray).type(torch.float32) #observe we can also change the dtype to float32 where as deafult from np is float64\n","print(mytensor)\n","\n","#lets modify the  myarray and see whther it effects the mytensor\n","myarray = myarray + 10\n","print(\"After\")\n","print(myarray)\n","print(mytensor) #doesnt alter, it holds true for other conversion too, numpy to tensor conversion\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kvoO8v0Zqh1","executionInfo":{"status":"ok","timestamp":1700428563850,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"30946737-87eb-4c66-ca8d-c49505ffdc8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]]\n","tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]])\n","After\n","[[11 12 13]\n"," [14 15 16]\n"," [17 18 19]]\n","tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]])\n"]}]},{"cell_type":"markdown","source":["### **Pytorch Reproducibility**\n","\n","Using seed in random\n","\n","More info: https://pytorch.org/docs/stable/notes/randomness.html"],"metadata":{"id":"TwxBQURpc8ER"}},{"cell_type":"code","source":["#without seed\n","import torch\n","\n","randtensor_1 = torch.rand(3, 4)\n","randtensor_2 = torch.rand(3, 4)\n","randtensor_1, randtensor_2, randtensor_1 == randtensor_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upzd4nb7c_yw","executionInfo":{"status":"ok","timestamp":1700429005116,"user_tz":-60,"elapsed":238,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"f028b51a-cf0c-4b35-f77e-6ebecadb21f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.3253, 0.0812, 0.4807, 0.9843],\n","         [0.0696, 0.6656, 0.9906, 0.1498],\n","         [0.8047, 0.8190, 0.4115, 0.1681]]),\n"," tensor([[0.5678, 0.5044, 0.6207, 0.7248],\n","         [0.9813, 0.7951, 0.2166, 0.7590],\n","         [0.2051, 0.7535, 0.0236, 0.7730]]),\n"," tensor([[False, False, False, False],\n","         [False, False, False, False],\n","         [False, False, False, False]]))"]},"metadata":{},"execution_count":160}]},{"cell_type":"code","source":["#with seed - reproducible tensors i.e it results in same tensor for every execution\n","#make sure to keep the same seed before every random tensor of same shape, other wise u ll get different random tensor of where we didnt add seed\n","import torch\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","randtensor_1 = torch.rand(3, 4)\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","randtensor_2 = torch.rand(3, 4)\n","\n","randtensor_1, randtensor_2, randtensor_1 == randtensor_2\n","\n","#to get same tensor for both variables, we need to use same seed before both tensors\n","#but if you want diffrnt tensor but they should be generated similar for every execution, then oone seed is enough"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xO59rXG5dbFk","executionInfo":{"status":"ok","timestamp":1700429590009,"user_tz":-60,"elapsed":417,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"78b3582f-1285-49f1-840c-fa47a9ec85d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","         [0.3904, 0.6009, 0.2566, 0.7936],\n","         [0.9408, 0.1332, 0.9346, 0.5936]]),\n"," tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","         [0.3904, 0.6009, 0.2566, 0.7936],\n","         [0.9408, 0.1332, 0.9346, 0.5936]]),\n"," tensor([[True, True, True, True],\n","         [True, True, True, True],\n","         [True, True, True, True]]))"]},"metadata":{},"execution_count":166}]},{"cell_type":"code","source":["#with seed - reproduceable tensors i.e it results in same tensor for every execution, but they bpth wont be same like above\n","#this is th example where we get rand tensors as we didnt place seed before the second tensor\n","import torch\n","\n","RANDOM_SEED = 42\n","torch.manual_seed(RANDOM_SEED)\n","randtensor_1 = torch.rand(3, 4)\n","\n","randtensor_2 = torch.rand(3, 4)\n","\n","randtensor_1, randtensor_2, randtensor_1 == randtensor_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYQ-YVi6e8mh","executionInfo":{"status":"ok","timestamp":1700429551164,"user_tz":-60,"elapsed":275,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a0e2d169-8335-431a-ec6b-573ef579000c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","         [0.3904, 0.6009, 0.2566, 0.7936],\n","         [0.9408, 0.1332, 0.9346, 0.5936]]),\n"," tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n","         [0.8854, 0.5739, 0.2666, 0.6274],\n","         [0.2696, 0.4414, 0.2969, 0.8317]]),\n"," tensor([[False, False, False, False],\n","         [False, False, False, False],\n","         [False, False, False, False]]))"]},"metadata":{},"execution_count":165}]},{"cell_type":"markdown","source":["### **Running tensors and pytorch objects on GPUs(for faster computation)**\n","\n","https://pytorch.org/docs/stable/notes/cuda.html\n","\n","GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + Pytorch working behind the scenes for faster computation\n","\n","- Options to use free GPU is via google colab or colab pro or colab pro+\n","- Use your own GPU which takes littlebit of set up and investment of purchasing a GPU\n","- Use Cloud computing - GCP - Google Cloud Platform, Amazon AWS, Microsoft Azure - these services allow you to rent computers on the cloud and access them\n","\n","For 2, 3, refer to pytorch setup documentation"],"metadata":{"id":"VSosju5zgzvS"}},{"cell_type":"code","source":["!nvidia-smi #make sure you change the runtime to GPU in colab for it return the GPU details"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46tsVMPTfrYO","executionInfo":{"status":"ok","timestamp":1700431558180,"user_tz":-60,"elapsed":206,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6adc51de-9471-4cc6-e240-3053b23b7901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 19 22:05:57 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   61C    P0    27W /  70W |    635MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["### check for GPU access with pytorch\n","import torch\n","torch.cuda.is_available()#cuda is nvidia paralled computing interface that allows us to use GPUs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMcJFGVBiwuH","executionInfo":{"status":"ok","timestamp":1700431555832,"user_tz":-60,"elapsed":203,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"48b17204-fa5c-45b9-cf1c-1482d9a11a97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### **Setting up Device Agnostic code**"],"metadata":{"id":"3fsOcxWWFN5g"}},{"cell_type":"code","source":["#Setup device agnostic code by setting the device variable\n","# see best practices section - Device-agnostic code - https://pytorch.org/docs/stable/notes/cuda.html\n","import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device #we can use any variable here. device is used for readability, we use this variable later in the code\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"O1ssO2aVjE6H","executionInfo":{"status":"ok","timestamp":1700431552170,"user_tz":-60,"elapsed":208,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e4406ca9-1c23-4f01-f57b-2dcecbf9933b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#count the number of GPUs\n","import torch\n","torch.cuda.device_count()\n","\n","#https://pytorch.org/docs/stable/notes/cuda.html - to understand on how to run different operations on multiple GPUs, see best practices section - Device-agnostic code"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WLjeuyAj2zh","executionInfo":{"status":"ok","timestamp":1700431548608,"user_tz":-60,"elapsed":7,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"cbe78c19-3c8b-46d1-fbca-1d29c7dc06a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["### **Setting up device agnostic code and putting tensors on and off the GPU**"],"metadata":{"id":"OhoKvVNTlefS"}},{"cell_type":"code","source":["# Putting tensors and models on GPU - cuz we want our tensors/model on GPU bcuz with GPU, we can achieve faster computation\n","\n","#creates tensor variable on CPU device and cpu is the default device\n","mytensor = torch.tensor([1, 2, 3], device=\"cpu\")\n","print(mytensor, mytensor.device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o524-EMOj_iY","executionInfo":{"status":"ok","timestamp":1700431260428,"user_tz":-60,"elapsed":19,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"4d72b907-7ad2-4cc2-f6c4-69c985218c4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) cpu\n"]}]},{"cell_type":"code","source":["#Move tensor variable to GPU if available, else keep it in cpu. For this, we can use our device variable\n","import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","mytensor = torch.tensor([1, 2, 3]) #lets create a tensor that was initially on cpu\n","\n","#move the tensor to gpu or lets just say the target device\n","tensor_on_gpu = mytensor.to(device) #moves to gpu if exists else keep it in cpu\n","\n","print(tensor_on_gpu, tensor_on_gpu.device)\n","\n","#Here cuda:0, 0 represents the index of our GPU. As we have only one GPU, we get one in the 0th index\n","#if we have more GPUs, then it will give the index of the GPU where the tensor is moved"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVXi-zVqmehQ","executionInfo":{"status":"ok","timestamp":1700431601800,"user_tz":-60,"elapsed":200,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"f8e93e79-5317-44b2-acd0-63610821e901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3], device='cuda:0') cuda:0\n"]}]},{"cell_type":"markdown","source":["### **Moving tensors back to CPU**\n","\n","- FOr eg, Numpy arrays only work on CPUs, so we would need to move our tensors back to cpu before changing it to numpy array"],"metadata":{"id":"NpnFpGbhocyn"}},{"cell_type":"code","source":["#convert the gpu tensor to cpu using tensor.cpu() and then use tensor.numpy() for converting to numpy array.\n","#using directly tensor_on_gpu.numpy() throws error\n","\n","import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","mytensor = torch.tensor([1, 2, 3])\n","tensor_on_gpu = mytensor.to(device) #moves to gpu if exists else keep it in cpu\n","\n","#convert back to cpu\n","tensor_on_cpu = tensor_on_gpu.cpu()\n","print(tensor_on_cpu, tensor_on_cpu.device)\n","tensor_to_numpy = tensor_on_cpu.numpy() #before using numpy operations or even matplotlib, you need to convert gpu tensors to cpu first using .cpu()\n","tensor_to_numpy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNPWOEgWm8KB","executionInfo":{"status":"ok","timestamp":1700432278598,"user_tz":-60,"elapsed":198,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"8cbe8f22-1229-44c2-bc76-baa142cbd855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3]) cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Exercises and Extra Cirriculum of Fundamentals from learnpytorch.io\n","\n","https://www.learnpytorch.io/00_pytorch_fundamentals/\n","\n","https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb"],"metadata":{"id":"2FJbPphBtfC9"}},{"cell_type":"markdown","source":["#### Exercise - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb\n"],"metadata":{"id":"XC0UJ5LJGes1"}},{"cell_type":"code","source":["#2. Create a random tensor with shape (7, 7)\n","import torch\n","randtensor = torch.rand(7, 7)\n","randtensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocmGu34KGXLf","executionInfo":{"status":"ok","timestamp":1700926287577,"user_tz":-60,"elapsed":3896,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"8aef368d-ce01-437b-b5cf-9a15be302c4c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8493, 0.3823, 0.4027, 0.9836, 0.1611, 0.3413, 0.2639],\n","        [0.1290, 0.3436, 0.3251, 0.1980, 0.1889, 0.8084, 0.8720],\n","        [0.3975, 0.6625, 0.5379, 0.0508, 0.9605, 0.0503, 0.1468],\n","        [0.3227, 0.2875, 0.9458, 0.8068, 0.1479, 0.0077, 0.4584],\n","        [0.4240, 0.1123, 0.9784, 0.1217, 0.2616, 0.4602, 0.2381],\n","        [0.5125, 0.2519, 0.5665, 0.6018, 0.7618, 0.4739, 0.5245],\n","        [0.0083, 0.7461, 0.2699, 0.3545, 0.3179, 0.9277, 0.5126]])"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["#3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7)\n","#(hint: you may have to transpose the second tensor).\n","randtensor2 = torch.rand(1, 7)\n","mulres = torch.matmul(randtensor, randtensor2.T)\n","mulres"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfXc8xiSG0c_","executionInfo":{"status":"ok","timestamp":1700926352576,"user_tz":-60,"elapsed":4,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"8f67500a-cd33-428f-8d39-be6870919731"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.1492],\n","        [1.2923],\n","        [0.9560],\n","        [1.4096],\n","        [1.1286],\n","        [1.6751],\n","        [1.5290]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["#4. Set the random seed to 0 and do 2 & 3 over again.\n","RANDOM_SEED = 0\n","\n","torch.manual_seed(RANDOM_SEED)\n","randtensor1 = torch.rand(7, 7)\n","randtensor2 = torch.rand(1, 7)\n","\n","matmulres = torch.mm(randtensor1, randtensor2.T)\n","matmulres, matmulres.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfQ88AOzHGlP","executionInfo":{"status":"ok","timestamp":1700940739979,"user_tz":-60,"elapsed":236,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"03a93fea-4ea8-4dee-975a-4cd759120422"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1.8542],\n","         [1.9611],\n","         [2.2884],\n","         [3.0481],\n","         [1.7067],\n","         [2.5290],\n","         [1.7989]]),\n"," torch.Size([7, 1]))"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["#5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent?\n","#(hint: you'll need to look into the documentation for torch.cuda for this one)\n","#If there is, set the GPU random seed to 1234.\n","RANDOM_SEED = 1234\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","randtensor1 = torch.rand(7, 7).cuda()\n","\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","randtensor2 = torch.rand(1, 7).cuda()\n","\n","matmulres = torch.mm(randtensor1, randtensor2.T)\n","randtensor1.device, randtensor2.device, matmulres, matmulres.device, matmulres.size()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Iys01ZfHfqm","executionInfo":{"status":"ok","timestamp":1700939129400,"user_tz":-60,"elapsed":6,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"47ff68ce-82a7-456e-e0e1-76c825d2dcf8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," tensor([[0.8613],\n","         [1.2761],\n","         [1.1540],\n","         [1.0134],\n","         [0.6783],\n","         [1.1122],\n","         [0.7266]], device='cuda:0'),\n"," device(type='cuda', index=0),\n"," torch.Size([7, 1]))"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["#6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this).\n","#Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed).\n","#The output should be something like:\n","# Device: cuda\n","# (tensor([[0.0290, 0.4019, 0.2598],\n","#          [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n","#  tensor([[0.0518, 0.4681, 0.6738],\n","#          [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n","RANDOM_SEED = 1234\n","\n","torch.manual_seed(RANDOM_SEED)\n","randtensor1 = torch.rand(2, 3)\n","randtensor2 = torch.rand(2, 3)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","randtensor1 = randtensor1.to(device) #we need to reassign to reflect the tensor on GPU\n","randtensor2 = randtensor2.to(device)\n","\n","randtensor1, randtensor1.device, randtensor2, randtensor2.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sV1pHddBIEO7","executionInfo":{"status":"ok","timestamp":1700940822253,"user_tz":-60,"elapsed":247,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"7b129eab-811e-4aba-d61f-dbeae80e953b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.0290, 0.4019, 0.2598],\n","         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n"," device(type='cuda', index=0),\n"," tensor([[0.0518, 0.4681, 0.6738],\n","         [0.3315, 0.7837, 0.5631]], device='cuda:0'),\n"," device(type='cuda', index=0))"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["#7. Perform a matrix multiplication on the tensors you created in 6\n","#(again, you may have to adjust the shapes of one of the tensors).\n","# The output should look like:\n","\n","# (tensor([[0.3647, 0.4709],\n","#          [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))\n","\n","RANDOM_SEED = 1234\n","\n","torch.manual_seed(RANDOM_SEED)\n","randtensor1 = torch.rand(2, 3)\n","randtensor2 = torch.rand(2, 3)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","randtensor1 = randtensor1.to(device) #we need to reassign to reflect the tensor on GPU\n","randtensor2 = randtensor2.to(device)\n","matmulres = randtensor1 @ randtensor2.T\n","\n","matmulres, matmulres.device, matmulres.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCZIOpK9I2cb","executionInfo":{"status":"ok","timestamp":1700940870861,"user_tz":-60,"elapsed":7,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"9969c41f-e499-40a0-a78f-6ee10ed7090f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.3647, 0.4709],\n","         [0.5184, 0.5617]], device='cuda:0'),\n"," device(type='cuda', index=0),\n"," torch.Size([2, 2]))"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["#8. Find the maximum and minimum values of the output of 7.\n","import torch\n","RANDOM_SEED = 1234\n","\n","torch.manual_seed(RANDOM_SEED)\n","randtensor1 = torch.rand(2, 3)\n","randtensor2 = torch.rand(2, 3)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","randtensor1 = randtensor1.to(device) #we need to reassign to reflect the tensor on GPU\n","randtensor2 = randtensor2.to(device)\n","matmulres = randtensor1 @ randtensor2.T\n","\n","matmulres.max(), torch.min(matmulres)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1YEufItJ6fq","executionInfo":{"status":"ok","timestamp":1700940894952,"user_tz":-60,"elapsed":249,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"501cb6dc-fbcc-4cba-f336-04fd2f8fe67b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.5617, device='cuda:0'), tensor(0.3647, device='cuda:0'))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["#9. Find the maximum and minimum index values of the output of 7.\n","import torch\n","RANDOM_SEED = 1234\n","\n","torch.manual_seed(RANDOM_SEED)\n","randtensor1 = torch.rand(2, 3)\n","randtensor2 = torch.rand(2, 3)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","randtensor1 = randtensor1.to(device) #we need to reassign to reflect the tensor on GPU\n","randtensor2 = randtensor2.to(device)\n","matmulres = randtensor1 @ randtensor2.T\n","\n","matmulres.argmax(), torch.argmin(matmulres)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBt3ERhNvFpr","executionInfo":{"status":"ok","timestamp":1700940905046,"user_tz":-60,"elapsed":305,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6c0725dd-8beb-4a83-d362-91d221e6c931"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["#10. Make a random tensor with shape (1, 1, 1, 10) and\n","#then create a new tensor with all the 1 dimensions removed to be left\n","#with a tensor of shape (10). Set the seed to 7 when you create it and\n","#print out the first tensor and it's shape as well as the second tensor and it's shape.\n","import torch\n","RANDOM_SEED = 7\n","torch.manual_seed(RANDOM_SEED)\n","mytensor1 = torch.rand(1, 1, 1, 10)\n","mytensor2 = mytensor1.squeeze()\n","\n","mytensor1, mytensor1.shape, mytensor2, mytensor2.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrqtqATivYBC","executionInfo":{"status":"ok","timestamp":1700937159751,"user_tz":-60,"elapsed":5,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"eae2c779-381d-4c47-8f7f-7413a5fce584"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n","            0.3653, 0.8513]]]]),\n"," torch.Size([1, 1, 1, 10]),\n"," tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n","         0.8513]),\n"," torch.Size([10]))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#matmul with out param\n","import torch\n","\n","# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","# ``tensor.T`` returns the transpose of a tensor\n","tensor = torch.ones(4, 4)\n","tensor[:,1] = 0\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(y1)\n","torch.matmul(tensor, tensor.T, out=y3)\n","tensor, y1, y2, y3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Apxl7GToqneo","executionInfo":{"status":"ok","timestamp":1703167346556,"user_tz":-60,"elapsed":250,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"8c76dec8-9523-4745-917c-e96968b1c822"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [1., 0., 1., 1.]]),\n"," tensor([[3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]]),\n"," tensor([[3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]]),\n"," tensor([[3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]]))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#element wise multiplication with out param\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","tensor = torch.ones(4, 4)\n","\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)\n","tensor, z1, z2, z3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0geOpGmOq-Xl","executionInfo":{"status":"ok","timestamp":1703167240745,"user_tz":-60,"elapsed":9,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"b074da26-f916-4dbf-f8b2-67dd2d201058"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]),\n"," tensor([[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]),\n"," tensor([[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]),\n"," tensor([[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]))"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["#### Inplace operations\n","\n","0 Operations that store the result into the operand are called in-place. They are denoted by a _ suffix. For example: x.copy_(y), x.t_(), will change x.\n","\n","Note: In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged.\n"],"metadata":{"id":"kEYaPOTDrhoO"}},{"cell_type":"code","source":["tensor = torch.ones(4, 4)\n","tensor[:, 1] = 0\n","print(f\"{tensor} \\n\")\n","tensor.add_(5)\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJTtLPoMrfdz","executionInfo":{"status":"ok","timestamp":1703167378631,"user_tz":-60,"elapsed":237,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e16e8a41-8b04-4e56-a9a7-4f25ffdd4c0b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}]},{"cell_type":"code","source":["tensor = torch.ones(4, 4)\n","tensor[:, 1] = 0\n","print(f\"{tensor} \\n\")\n","tensor.copy_(5)\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rh0TGIJ5r-uj","executionInfo":{"status":"ok","timestamp":1703167417290,"user_tz":-60,"elapsed":263,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"1e6207c1-86ca-4861-b3ac-b7d7b19bf7fa"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[5., 5., 5., 5.],\n","        [5., 5., 5., 5.],\n","        [5., 5., 5., 5.],\n","        [5., 5., 5., 5.]])\n"]}]},{"cell_type":"code","source":["tensor = torch.ones(4, 4)\n","tensor[:, 1] = 0\n","print(f\"{tensor} \\n\")\n","tensor.t_() #inplace transpose\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MR7cfChSsHsZ","executionInfo":{"status":"ok","timestamp":1703167444334,"user_tz":-60,"elapsed":252,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"10f87c4d-71e0-4453-d9d3-9f06616fbb50"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[1., 1., 1., 1.],\n","        [0., 0., 0., 0.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.]])\n"]}]},{"cell_type":"markdown","source":["### Extra Cirriculum\n","- https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n","- https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html"],"metadata":{"id":"vAVJkaHewVEg"}},{"cell_type":"code","source":[],"metadata":{"id":"P12vuGq_Eaob"},"execution_count":null,"outputs":[]}]}