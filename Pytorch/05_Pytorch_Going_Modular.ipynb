{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO40Q0u1mygXArJU7GFL5ap"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"81bc5b1a1455403da6f9fdf3eb22fe8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd8f8fd26a6c446fa5694eda9f51efde","IPY_MODEL_a4535264a0d740a99966713898a5b67c","IPY_MODEL_f416368fdaed42d4ad1646ab1a8afbe3"],"layout":"IPY_MODEL_70acaf714c20470694e0fd54b9970e95"}},"dd8f8fd26a6c446fa5694eda9f51efde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_895059d594be4d3eb4a7b31f91eec5a3","placeholder":"​","style":"IPY_MODEL_f1a0b79064374169b2ad99296815b23d","value":"100%"}},"a4535264a0d740a99966713898a5b67c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c3bb43ae0364b5bb52de3e895f5bfdd","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9eccda46c4f44c9f996cff824e760f3e","value":5}},"f416368fdaed42d4ad1646ab1a8afbe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d2b37b94d74636b1354a7cda10136b","placeholder":"​","style":"IPY_MODEL_cb02a755123f41fc9db4329d63691a53","value":" 5/5 [00:12&lt;00:00,  2.52s/it]"}},"70acaf714c20470694e0fd54b9970e95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"895059d594be4d3eb4a7b31f91eec5a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a0b79064374169b2ad99296815b23d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c3bb43ae0364b5bb52de3e895f5bfdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eccda46c4f44c9f996cff824e760f3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9d2b37b94d74636b1354a7cda10136b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb02a755123f41fc9db4329d63691a53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["###**05. PyTorch Going Modular**\n","This section answers the question, **\"how do I turn my notebook code into Python scripts?\"**\n","\n","To do so, we're going to turn the most useful code cells in notebook 04. PyTorch Custom Datasets into a series of Python scripts saved to a directory called `going_modular`.\n","\n","####**What is going modular?**\n","Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality.\n","\n","For example, we could turn our notebook code from a series of cells into the following Python files:\n","\n","- `data_setup.py` - a file to prepare and download data if needed.\n","- `engine.py` - a file containing various training functions.\n","- `model_builder.py` or `model.py` - a file to create a PyTorch model.\n","- `train.py` - a file to leverage all other files and train a target PyTorch model.\n","- `utils.py` - a file dedicated to helpful utility functions.\n","\n","**Note**: The naming and layout of the above files will depend on your use case and code requirements. Python scripts are as general as individual notebook cells, meaning, you could create one for almost any kind of functionality.\n","\n","####**Why would you want to go modular?**\n","Notebooks are fantastic for iteratively exploring and running experiments quickly.\n","\n","However, for larger scale projects you may find Python scripts more reproducible and easier to run.\n","\n","Though this is a debated topic, as companies like Netflix have shown how they use notebooks for production code.\n","\n","Production code is code that runs to offer a service to someone or something.\n","\n","For example, if you have an app running online that other people can access and use, the code running that app is considered production code.\n","\n","And libraries like `fast.ai's` `nb-dev` (short for notebook development) enable you to write whole Python libraries (including documentation) with Jupyter Notebooks.\n","\n","####**Pros and cons of notebooks vs Python scripts**\n","There's arguments for both sides.\n","\n","But this list sums up a few of the main topics.\n","\n","**Notebooks**\n","- Pros\n","\t- Easy to experiment/get started\n","    - Easy to share (e.g. a link to a Google Colab notebook)\n","    - Very visual\n","- Cons\n","    - Versioning can be hard\n","\t- Hard to use only specific parts\n","\t- Text and graphics can get in the way of code\n","    \n","**Python scripts**\n","- Pros\n","\t- Can package code together (saves rewriting similar code across different notebooks)\n","    - Can use git for versioning\n","    - Many open source projects use scripts\n","    - Larger projects can be run on cloud vendors (not as much support for notebooks)\n","- Cons\n","    - Experimenting isn't as visual (usually have to run the whole script rather than one cell)\n"],"metadata":{"id":"bQ-O5w9q4In3"}},{"cell_type":"markdown","source":["**My workflow**\n","\n","I usually start machine learning projects in Jupyter/Google Colab notebooks for quick experimentation and visualization.\n","\n","Then when I've got something working, I move the most useful pieces of code to Python scripts.\n","\n","There are many possible workflows for writing machine learning code. Some prefer to start with scripts, others (like me) prefer to start with notebooks and go to scripts later on.\n","\n","**PyTorch in the wild**\n","In your travels, you'll see many code repositories for PyTorch-based ML projects have instructions on how to run the PyTorch code in the form of Python scripts.\n","\n","For example, you might be instructed to run code like the following in a terminal/command line to train a model:\n","\n","```\n","python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS\n","```\n","\n","ABive is the example of running a `PyTorch train.py script` on the command line with various hyperparameter settings.\n","\n","In this case, `train.py` is the target Python script, it'll likely contain functions to train a PyTorch model.\n","\n","And `--model, --batch_size, --lr and --num_epochs` are known as argument flags.\n","\n","You can set these to whatever values you like and if they're compatible with train.py, they'll work, if not, they'll error.\n","\n","For example, let's say we wanted to train our TinyVGG model from notebook 04 for 10 epochs with a batch size of 32 and a learning rate of 0.001:\n","\n","```\n","python train.py --model tinyvgg --batch_size 32 --lr 0.001 --num_epochs 10\n","```\n","\n","You could setup any number of these argument flags in your ```train.py``` script to suit your needs.\n","\n","The PyTorch blog post for training state-of-the-art computer vision models uses this style.\n","\n","https://github.com/pytorch/vision/tree/v0.10.0/references/classification\n","\n","```\n","python -m torch.distributed.launch --nproc_per_node=8 --use_env train.py\\\n","     --model mobilenet_v2 --epochs 300 --lr 0.045 --wd 0.00004\\\n","     --lr-step-size 1 --lr-gamma 0.98\n","```\n","\n","or\n","\n","```\n","torchrun --nproc_per_node=8 train.py --model resnet50 --batch-size 128 --lr 0.5 \\\n","--lr-scheduler cosineannealinglr --lr-warmup-epochs 5 --lr-warmup-method linear \\\n","--auto-augment ta_wide --epochs 600 --random-erase 0.1 --weight-decay 0.00002 \\\n","--norm-weight-decay 0.0 --label-smoothing 0.1 --mixup-alpha 0.2 --cutmix-alpha 1.0 \\\n","--train-crop-size 176 --model-ema --val-resize-size 232 --ra-sampler --ra-reps 4\n","```\n","    "],"metadata":{"id":"Q1zBSWMn5ksl"}},{"cell_type":"markdown","source":["PyTorch command line training script recipe for training state-of-the-art computer vision models with 8 GPUs. Source:\n","https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#the-training-recipe"],"metadata":{"id":"oZnL7_u88L15"}},{"cell_type":"markdown","source":["####**What we're going to cover**\n","The main concept of this section is: turn useful notebook code cells into reusable Python files.\n","\n","Doing this will save us writing the same code over and over again.\n","\n","There are two notebooks for this section:\n","\n","- **05. Going Modular: Part 1 (cell mode)** - this notebook is run as a traditional Jupyter Notebook/Google Colab notebook and is a condensed version of notebook 04.\n","- **05. Going Modular: Part 2 (script mode)** - this notebook is the same as number 1 but with added functionality to turn each of the major sections into Python scripts, such as, data_setup.py and train.py.\n","\n","The text in this document focuses on the code cells `05. Going Modular: Part 2 (script mode)`, the ones with `%%writefile` ... at the top.\n","\n","**Why two parts?**\n","\n","Because sometimes the best way to learn something is to see how it differs from something else.\n","\n","If you run each notebook side-by-side you'll see how they differ and that's where the key learnings are.\n","\n","Running the two notebooks for section 05 side-by-side. You'll notice that the script mode notebook has extra code cells to turn code from the cell mode notebook into Python scripts.\n","\n","####**What we're working towards**\n","By the end of this section we want to have two things:\n","\n","1. The ability to train the model we built in notebook 04 (Food Vision Mini) with one line of code on the command line: `python train.py`.\n","2. A directory structure of reusable Python scripts, such as:\n","\n","```\n","going_modular/\n","├── going_modular/\n","│   ├── data_setup.py\n","│   ├── engine.py\n","│   ├── model_builder.py\n","│   ├── train.py\n","│   └── utils.py\n","├── models/\n","│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth\n","│   └── 05_going_modular_script_mode_tinyvgg_model.pth\n","└── data/\n","    └── pizza_steak_sushi/\n","        ├── train/\n","        │   ├── pizza/\n","        │   │   ├── image01.jpeg\n","        │   │   └── ...\n","        │   ├── steak/\n","        │   └── sushi/\n","        └── test/\n","            ├── pizza/\n","            ├── steak/\n","            └── sushi/\n","```"],"metadata":{"id":"cb6qh48p8Seb"}},{"cell_type":"markdown","source":["**Things to note**\n","- `Docstrings` - Writing reproducible and understandable code is important. And with this in mind, each of the functions/classes we'll be putting into scripts has been created with Google's Python docstring style in mind.\n","- `Imports at the top of scripts` - Since all of the Python scripts we're going to create could be considered a small program on their own, all of the scripts require their input modules be imported at the start of the script for example:\n","\n","```\n","# Import modules required for train.py\n","import os\n","import torch\n","import data_setup, engine, model_builder, utils\n","\n","from torchvision import transforms\n","```\n","\n","####**0. Cell mode vs. script mode**\n","A cell mode notebook such as `05. Going Modular Part 1 (cell mode)` is a notebook run normally, each cell in the notebook is either code or markdown.\n","\n","A script mode notebook such as `05. Going Modular Part 2 (script mode)` is very similar to a cell mode notebook, however, many of the code cells may be turned into Python scripts.\n","\n","**Note**: You don't need to create Python scripts via a notebook, you can create them directly through an IDE (integrated developer environment) such as VS Code. Having the script mode notebook as part of this section is just to demonstrate one way of going from notebooks to Python scripts.\n","\n","####**1. Get data**\n","Getting the data in each of the 05 notebooks happens the same as in notebook 04.\n","\n","A call is made to GitHub via Python's requests module to download a .zip file and unzip it."],"metadata":{"id":"Xr7pAR7WIpr-"}},{"cell_type":"code","source":["import requests\n","from pathlib import Path\n","import zipfile\n","import os\n","\n","data_path = Path(\"./data\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","        print(\"Downloading pizza, steak, sushi data...\")\n","        f.write(request.content)\n","\n","    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","        print(\"Unzipping pizza, steak, sushi data...\")\n","        zip_ref.extractall(image_path)\n","\n","    # Remove zip file\n","    os.remove(data_path / \"pizza_steak_sushi.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8VvUCAKM5GN","executionInfo":{"status":"ok","timestamp":1703343813150,"user_tz":-60,"elapsed":2138,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"13b6f75f-7fe5-4eb5-c55f-252f3ba123c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi directory, creating one...\n","Unzipping pizza, steak, sushi data...\n"]}]},{"cell_type":"markdown","source":["```\n","\n","```\n","\n","This results in having a file called data that contains another directory called pizza_steak_sushi with images of pizza, steak and sushi in standard image classification format.\n","\n","```\n","data/\n","└── pizza_steak_sushi/\n","    ├── train/\n","    │   ├── pizza/\n","    │   │   ├── train_image01.jpeg\n","    │   │   ├── test_image02.jpeg\n","    │   │   └── ...\n","    │   ├── steak/\n","    │   │   └── ...\n","    │   └── sushi/\n","    │       └── ...\n","    └── test/\n","        ├── pizza/\n","        │   ├── test_image01.jpeg\n","        │   └── test_image02.jpeg\n","        ├── steak/\n","        └── sushi/\n","```\n","\n","####**2. Create Datasets and DataLoaders (data_setup.py)**\n","\n","Once we've got data, we can then turn it into PyTorch Dataset's and DataLoader's (one for training data and one for testing data).\n","\n","We convert the useful Dataset and DataLoader creation code into a function called `create_dataloaders()`.\n","\n","And we write it to file using the line `%%writefile going_modular/data_setup.py`."],"metadata":{"id":"iQjQSXop11mG"}},{"cell_type":"code","source":["#creating the directory path\n","modular_path = Path(\"./going_modular\")\n","modular_path.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"xwy73DP_QeV2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Imp Note: Before turning the code to scripts, make sure to execute autoreload command like below, without that, the any modificaiton in the script files wont get refelected and old code will keep executing\n","\n","```\n","%load_ext autoreload\n","%autoreload 2\n","```"],"metadata":{"id":"6RvLQO1zfij-"}},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Esh5Vcwyf1oq","executionInfo":{"status":"ok","timestamp":1703348758077,"user_tz":-60,"elapsed":9,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"698f08a4-2afd-4306-9153-751487b1d2eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\n","import torch\n","import torchvision\n","import os\n","from torchvision import datasets, transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, Dataset\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    num_workers: int=NUM_WORKERS):\n","    \"\"\"Creates training and testing DataLoaders.\n","\n","    Takes in a training directory and testing directory path and turns\n","    them into PyTorch Datasets and then into PyTorch DataLoaders.\n","\n","    Args:\n","    train_dir: Path to training directory.\n","    test_dir: Path to testing directory.\n","    transform: torchvision transforms to perform on training and testing data.\n","    batch_size: Number of samples per batch in each of the DataLoaders.\n","    num_workers: An integer for number of workers per DataLoader.\n","\n","    Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names).\n","    Where class_names is a list of the target classes.\n","    Example usage:\n","        train_dataloader, test_dataloader, class_names = \\\n","        = create_dataloaders(train_dir=path/to/train_dir,\n","                                test_dir=path/to/test_dir,\n","                                transform=some_transform,\n","                                batch_size=32,\n","                                num_workers=4)\n","    \"\"\"\n","    # Use ImageFolder to create dataset(s)\n","    train_dataset = ImageFolder(root=train_dir, transform=transform)\n","    test_dataset = ImageFolder(root=test_dir, transform=transform)\n","\n","    # Get class names\n","    class_names = train_dataset.classes\n","\n","    # Turn images into data loaders\n","    train_dataloader = DataLoader(dataset=train_dataset,\n","                                  batch_size=batch_size,\n","                                  num_workers=num_workers,\n","                                  shuffle=True,\n","                                  pin_memory=True\n","                                  )\n","    test_dataloader = DataLoader(dataset=test_dataset,\n","                                  batch_size=batch_size,\n","                                  num_workers=num_workers,\n","                                  shuffle=False,\n","                                  pin_memory=True\n","    )\n","    return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftBZRVgGMuQZ","executionInfo":{"status":"ok","timestamp":1703348645484,"user_tz":-60,"elapsed":376,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ac4755f7-64df-4cae-cde1-5851e12abf85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/data_setup.py\n"]}]},{"cell_type":"markdown","source":["If we'd like to make `DataLoader's` we can now use the function within `data_setup.py` like so:"],"metadata":{"id":"ObLpEs7eRGY2"}},{"cell_type":"code","source":["image_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z7i_glZsS2wZ","executionInfo":{"status":"ok","timestamp":1703345906213,"user_tz":-60,"elapsed":809,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3fd9837a-1238-4b14-a7dc-5488deb64d3c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('data/pizza_steak_sushi')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["from torchvision import transforms\n","from going_modular import data_setup\n","\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=transforms.Compose([\n","        transforms.Resize((64, 64)),\n","        transforms.ToTensor()\n","    ]),\n","    batch_size=32\n",")"],"metadata":{"id":"moZHaNvrNRGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwTsHmtqSTG0","executionInfo":{"status":"ok","timestamp":1703345676849,"user_tz":-60,"elapsed":18,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"7a5aea3a-2610-4966-cea8-5aeb793994f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pizza', 'steak', 'sushi']"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["len(train_dataloader), len(test_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0FgegDdSvjl","executionInfo":{"status":"ok","timestamp":1703348652005,"user_tz":-60,"elapsed":12,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"ec3c8946-50b1-4f8c-aa92-fd3b5fde9225"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8, 3)"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","source":["####**3. Making a model (model_builder.py)**\n","Over the past few notebooks (notebook 03 and notebook 04), we've built the TinyVGG model a few times.\n","\n","So it makes sense to put the model into its file so we can reuse it again and again.\n","\n","Let's put our TinyVGG() model class into a script with the line `%%writefile going_modular/model_builder.py`"],"metadata":{"id":"tX10pJpiVHUY"}},{"cell_type":"code","source":["%%writefile going_modular/model_builder.py\n","\"\"\"\n","Contains PyTorch model code to instantiate a TinyVGG model.\n","\"\"\"\n","import torch\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"Creates the TinyVGG architecture.\n","\n","  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","  Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","  \"\"\"\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","      super().__init__()\n","      self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2)\n","      )\n","      self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","      )\n","      self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","      )\n","\n","  def forward(self, x: torch.Tensor):\n","    return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1nPIFssS0EB","executionInfo":{"status":"ok","timestamp":1703349684117,"user_tz":-60,"elapsed":356,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"de3f321a-ecb4-4d31-d798-87b27419fd91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/model_builder.py\n"]}]},{"cell_type":"markdown","source":["Now instead of coding the TinyVGG model from scratch every time, we can import it using:"],"metadata":{"id":"gx-LGpXQVzPq"}},{"cell_type":"code","source":["import torch\n","from going_modular import model_builder\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Instantiate an instance of the model from the \"model_builder.py\" script\n","torch.manual_seed(42)\n","model = model_builder.TinyVGG(input_shape=3,\n","                              hidden_units=10,\n","                              output_shape=len(class_names)).to(device)\n","\n","# model(torch.randn(1, 3, 64, 64))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VW6Jutl9Vjbs","executionInfo":{"status":"ok","timestamp":1703347619560,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"0288efb0-f98a-4e96-e6be-91f57f40d85d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0216, -0.0143, -0.0036]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["####**4. Creating `train_step()` and `test_step()` functions and `train()` to combine them**\n","We wrote several training functions in notebook 04:\n","\n","- `train_step()` - takes in a model, a DataLoader, a loss function and an optimizer and trains the model on the DataLoader.\n","- `test_step()` - takes in a model, a DataLoader and a loss function and evaluates the model on the DataLoader.\n","- `train()` - performs 1. and 2. together for a given number of epochs and returns a results dictionary.\n","\n","Since these will be the engine of our model training, we can put them all into a Python script called engine.py with the line `%%writefile going_modular/engine.py`"],"metadata":{"id":"K9mkAA3oV-QA"}},{"cell_type":"code","source":["%%writefile going_modular/engine.py\n","\"\"\"\n","Contains functions for training and testing a PyTorch model.\n","\"\"\"\n","import torch\n","\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","  \"\"\"Trains a PyTorch model for a single epoch.\n","\n","  Turns a target PyTorch model to training mode and then\n","  runs through all of the required training steps (forward\n","  pass, loss calculation, optimizer step).\n","\n","  Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","\n","    (0.1112, 0.8743)\n","  \"\"\"\n","  # Put model in train mode\n","  model.train()\n","\n","  # Setup train loss and train accuracy values\n","  train_loss, train_acc = 0, 0\n","\n","  # Loop through data loader data batches\n","  for batch, (X, y) in enumerate(dataloader):\n","      # Send data to target device\n","      X, y = X.to(device), y.to(device)\n","\n","      # 1. Forward pass\n","      y_pred = model(X)\n","\n","      # 2. Calculate  and accumulate loss\n","      loss = loss_fn(y_pred, y)\n","      train_loss += loss.item()\n","\n","      # 3. Optimizer zero grad\n","      optimizer.zero_grad()\n","\n","      # 4. Loss backward\n","      loss.backward()\n","\n","      # 5. Optimizer step\n","      optimizer.step()\n","\n","      # Calculate and accumulate accuracy metric across all batches\n","      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  train_loss = train_loss / len(dataloader)\n","  train_acc = train_acc / len(dataloader)\n","  return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","  \"\"\"Tests a PyTorch model for a single epoch.\n","\n","  Turns a target PyTorch model to \"eval\" mode and then performs\n","  a forward pass on a testing dataset.\n","\n","  Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","\n","    (0.0223, 0.8985)\n","  \"\"\"\n","  # Put model in eval mode\n","  model.eval()\n","\n","  # Setup test loss and test accuracy values\n","  test_loss, test_acc = 0, 0\n","\n","  # Turn on inference context manager\n","  with torch.inference_mode():\n","      # Loop through DataLoader batches\n","      for batch, (X, y) in enumerate(dataloader):\n","          # Send data to target device\n","          X, y = X.to(device), y.to(device)\n","\n","          # 1. Forward pass\n","          test_pred_logits = model(X)\n","\n","          # 2. Calculate and accumulate loss\n","          loss = loss_fn(test_pred_logits, y)\n","          test_loss += loss.item()\n","\n","          # Calculate and accumulate accuracy\n","          test_pred_labels = test_pred_logits.argmax(dim=1)\n","          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  test_loss = test_loss / len(dataloader)\n","  test_acc = test_acc / len(dataloader)\n","  return test_loss, test_acc\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List]:\n","  \"\"\"Trains and tests a PyTorch model.\n","\n","  Passes a target PyTorch models through train_step() and test_step()\n","  functions for a number of epochs, training and testing the model\n","  in the same epoch loop.\n","\n","  Calculates, prints and stores evaluation metrics throughout.\n","\n","  Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for\n","    each epoch.\n","    In the form: {train_loss: [...],\n","                  train_acc: [...],\n","                  test_loss: [...],\n","                  test_acc: [...]}\n","    For example if training for epochs=2:\n","                 {train_loss: [2.0616, 1.0537],\n","                  train_acc: [0.3945, 0.3945],\n","                  test_loss: [1.2641, 1.5706],\n","                  test_acc: [0.3400, 0.2973]}\n","  \"\"\"\n","  # Create empty results dictionary\n","  results = {\"train_loss\": [],\n","      \"train_acc\": [],\n","      \"test_loss\": [],\n","      \"test_acc\": []\n","  }\n","\n","  # Loop through training and testing steps for a number of epochs\n","  for epoch in tqdm(range(epochs)):\n","      train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","      test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          loss_fn=loss_fn,\n","          device=device)\n","\n","      # Print out what's happening\n","      print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","      )\n","\n","      # Update results dictionary\n","      results[\"train_loss\"].append(train_loss)\n","      results[\"train_acc\"].append(train_acc)\n","      results[\"test_loss\"].append(test_loss)\n","      results[\"test_acc\"].append(test_acc)\n","\n","  # Return the filled results at the end of the epochs\n","  return results\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OveYWpouV7H6","executionInfo":{"status":"ok","timestamp":1703347633023,"user_tz":-60,"elapsed":364,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"a5550233-2876-492f-9181-47a88cffba14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/engine.py\n"]}]},{"cell_type":"markdown","source":["Now we've got the engine.py script, we can import functions from it via:"],"metadata":{"id":"j6rckuhkWkZ3"}},{"cell_type":"code","source":["from going_modular import engine\n","\n","model_results = engine.train(model=model,\n","                             train_dataloader=train_dataloader,\n","                             test_dataloader=test_dataloader,\n","                             optimizer=torch.optim.Adam(params=model.parameters(), lr=0.01),\n","                             loss_fn=torch.nn.CrossEntropyLoss(),\n","                             epochs=5,\n","                             device=device)\n","\n","model_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344,"referenced_widgets":["81bc5b1a1455403da6f9fdf3eb22fe8d","dd8f8fd26a6c446fa5694eda9f51efde","a4535264a0d740a99966713898a5b67c","f416368fdaed42d4ad1646ab1a8afbe3","70acaf714c20470694e0fd54b9970e95","895059d594be4d3eb4a7b31f91eec5a3","f1a0b79064374169b2ad99296815b23d","9c3bb43ae0364b5bb52de3e895f5bfdd","9eccda46c4f44c9f996cff824e760f3e","b9d2b37b94d74636b1354a7cda10136b","cb02a755123f41fc9db4329d63691a53"]},"id":"mAVOuXPCWh6B","executionInfo":{"status":"ok","timestamp":1703347650144,"user_tz":-60,"elapsed":12715,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3aac45a7-620c-4b78-bb0e-4e15511e80d0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81bc5b1a1455403da6f9fdf3eb22fe8d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 1.2091 | train_acc: 0.2852 | test_loss: 1.1027 | test_acc: 0.3047\n","Epoch: 2 | train_loss: 1.1002 | train_acc: 0.2852 | test_loss: 1.0976 | test_acc: 0.4023\n","Epoch: 3 | train_loss: 1.0953 | train_acc: 0.4023 | test_loss: 1.0953 | test_acc: 0.4023\n","Epoch: 4 | train_loss: 1.1032 | train_acc: 0.2812 | test_loss: 1.0935 | test_acc: 0.4023\n","Epoch: 5 | train_loss: 1.1059 | train_acc: 0.2812 | test_loss: 1.0941 | test_acc: 0.4023\n"]},{"output_type":"execute_result","data":{"text/plain":["{'train_loss': [1.209054708480835,\n","  1.1002424955368042,\n","  1.095258504152298,\n","  1.1031782627105713,\n","  1.1059248447418213],\n"," 'train_acc': [0.28515625, 0.28515625, 0.40234375, 0.28125, 0.28125],\n"," 'test_loss': [1.1026849746704102,\n","  1.0975976139307022,\n","  1.0952827483415604,\n","  1.0935154110193253,\n","  1.0941214114427567],\n"," 'test_acc': [0.3046875, 0.40234375, 0.40234375, 0.40234375, 0.40234375]}"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["#### 5. Creating a function to save the model (utils.py)\n","Often you'll want to save a model whilst it's training or after training.\n","\n","Since we've written the code to save a model a few times now in previous notebooks, it makes sense to turn it into a function and save it to file.\n","\n","It's common practice to store helper functions in a file called `utils.py` (short for utilities).\n","\n","Let's save our `save_model()` function to a file called `utils.py` with the line `%%writefile going_modular/utils.py`:"],"metadata":{"id":"QHaTOxnWbqEH"}},{"cell_type":"code","source":["%%writefile going_modular/utils.py\n","\"\"\"\n","Contains various utility functions for PyTorch model training and saving.\n","\"\"\"\n","import torch\n","from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","    \"\"\"Saves a PyTorch model to a target directory.\n","\n","    Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","        either \".pth\" or \".pt\" as the file extension.\n","\n","    Example usage:\n","    save_model(model=model_0,\n","                target_dir=\"models\",\n","                model_name=\"05_going_modular_tingvgg_model.pth\")\n","    \"\"\"\n","    # Create target directory\n","    target_dir_path = Path(target_dir)\n","    target_dir_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Create model save path\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","    model_name = model_name\n","    model_save_path = target_dir_path / model_name\n","\n","    # Save the model state_dict()\n","    print(f\"[INFO] Saving model to: {model_save_path}\")\n","    torch.save(obj=model.state_dict(), f=model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRgLRY8-X9EJ","executionInfo":{"status":"ok","timestamp":1703348618438,"user_tz":-60,"elapsed":370,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"44cbe750-77b5-4740-9705-c1f91fee99a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/utils.py\n"]}]},{"cell_type":"markdown","source":["Now if we wanted to use our `save_model()` function, instead of writing it all over again, we can import it and use it via:"],"metadata":{"id":"Xx8OSQI9dT-h"}},{"cell_type":"code","source":["# Import utils.py\n","\n","from going_modular import utils\n","\n","# Save a model to file\n","utils.save_model(model=model,\n","           target_dir=\"./models\",\n","           model_name=\"mymodel.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RDxWH5fQdaqp","executionInfo":{"status":"ok","timestamp":1703348622456,"user_tz":-60,"elapsed":381,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"13defe5f-cef5-4f69-efe1-25e152342002"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","[INFO] Saving model to: models/mymodel.pth\n"]}]},{"cell_type":"markdown","source":["###**6. Train, evaluate and save the model (train.py)**\n","As previously discussed, you'll often come across PyTorch repositories that combine all of their functionality together in a `train.py` file.\n","\n","This file is essentially saying \"train the model using whatever data is available\".\n","\n","In our `train.py` file, we'll combine all of the functionality of the other Python scripts we've created and use it to train a model.\n","\n","This way we can train a PyTorch model using a single line of code on the command line:\n","\n","` python train.py`\n","\n","Note: We can also execute all other scripts using this command `python pyfilename.py` and if the classes or functions inside the file that you are trying to execute has arguments, then you can `argparse` to pass the args"],"metadata":{"id":"4e2R8QYCf61R"}},{"cell_type":"markdown","source":["To create `train.py` we'll go through the following steps:\n","\n","1. Import the various dependencies, namely `torch, os, torchvision.transforms and all of the scripts from the going_modular directory, data_setup, engine, model_builder, utils`.\n","2. Note: Since `train.py` will be inside the `going_modular` directory, we can import the other modules via `import ...` rather than `from going_modular import ....`\n","- Setup various hyperparameters such as `batch size, number of epochs, learning rate and number of hidden units` (these could be set in the future via Python's `argparse`).\n","- Setup the training and test directories.\n","- Setup device-agnostic code.\n","- Create the necessary data transforms.\n","- Create the DataLoaders using `data_setup.py`.\n","- Create the model using `model_builder.py`.\n","- Setup the `loss function and optimizer`.\n","- Train the model using `engine.py`.\n","- Save the model using `utils.py`.\n","\n","And we can create the file from a notebook cell using the line `%%writefile going_modular/train.py`"],"metadata":{"id":"mqESctdfgsXr"}},{"cell_type":"code","source":["%%writefile going_modular/train.py\n","\n","import torch\n","import os\n","from torchvision import transforms\n","import data_setup, engine, model_builder, utils\n","\n","# Setup hyperparameters\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 32\n","HIDDEN_UNITS = 10\n","LEARNING_RATE = 0.001\n","\n","# Setup directories\n","train_dir = \"data/pizza_steak_sushi/train\"\n","test_dir = \"data/pizza_steak_sushi/test\"\n","\n","# Setup target device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","  transforms.Resize((64, 64)),\n","  transforms.ToTensor()\n","])\n","\n","# Create DataLoaders with help from data_setup.py\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Create model with help from model_builder.py\n","model = model_builder.TinyVGG(\n","    input_shape=3,\n","    hidden_units=HIDDEN_UNITS,\n","    output_shape=len(class_names)\n",").to(device)\n","\n","# Set loss and optimizer\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),\n","                             lr=LEARNING_RATE)\n","\n","# Start training with help from engine.py\n","engine.train(model=model,\n","             train_dataloader=train_dataloader,\n","             test_dataloader=test_dataloader,\n","             loss_fn=loss_fn,\n","             optimizer=optimizer,\n","             epochs=NUM_EPOCHS,\n","             device=device)\n","\n","# Save the model with help from utils.py\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0EK4vK9diGN","executionInfo":{"status":"ok","timestamp":1703349697252,"user_tz":-60,"elapsed":409,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e12473d5-67c8-4530-8734-fbb4ea132aa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/train.py\n"]}]},{"cell_type":"markdown","source":["Woohoo!\n","\n","Now we can train a PyTorch model by running the following line on the command line:"],"metadata":{"id":"dQUAF0C5ibAy"}},{"cell_type":"code","source":["!python going_modular/train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRL22L2OikIp","executionInfo":{"status":"ok","timestamp":1703349712831,"user_tz":-60,"elapsed":13585,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3096b5b5-7754-4806-ea3e-6284f5a8f590"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  0% 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1042 | train_acc: 0.2695 | test_loss: 1.0942 | test_acc: 0.5417\n"," 20% 1/5 [00:01<00:06,  1.71s/it]Epoch: 2 | train_loss: 1.0985 | train_acc: 0.4336 | test_loss: 1.0981 | test_acc: 0.3438\n"," 40% 2/5 [00:03<00:05,  1.67s/it]Epoch: 3 | train_loss: 1.0972 | train_acc: 0.3008 | test_loss: 1.1050 | test_acc: 0.2604\n"," 60% 3/5 [00:04<00:03,  1.62s/it]Epoch: 4 | train_loss: 1.0833 | train_acc: 0.4180 | test_loss: 1.1419 | test_acc: 0.2500\n"," 80% 4/5 [00:06<00:01,  1.63s/it]Epoch: 5 | train_loss: 1.0713 | train_acc: 0.4844 | test_loss: 1.1228 | test_acc: 0.3438\n","100% 5/5 [00:09<00:00,  1.80s/it]\n","[INFO] Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"]}]},{"cell_type":"markdown","source":["Doing this will leverage all of the other code scripts we've created.\n","\n","And if we wanted to, we could adjust our train.py file to use argument flag inputs with Python's argparse module, this would allow us to provide different hyperparameter settings like previously discussed:\n","\n","```\n","python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS\n","```\n"],"metadata":{"id":"Sl-U05gZjkOH"}},{"cell_type":"markdown","source":["###**Exercises**\n","####**Resources:**\n","\n","- Exercise template notebook for 05 - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/05_pytorch_going_modular_exercise_template.ipynb\n","- Example solutions notebook for 05 - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/05_pytorch_going_modular_exercise_solutions.ipynb\n","    - Live coding run through of solutions notebook for 05 on YouTube https://youtu.be/ijgFhMK3pp4\n","\n","####**Exercises:**\n","\n","1. Turn the code to get the data (from section 1. Get Data above where we didnt use script mode but used cell mode) into a Python script, such as `get_data.py`.\n","    - When you run the script using `python get_data.py` it should check if the data already exists and skip downloading if it does.\n","    - If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the data directory.\n","2. Use Python's `argparse` module to be able to send the `train.py` custom hyperparameter values for training procedures.\n","    - Add an argument for using a different:\n","        - Training/testing directory\n","        - Learning rate\n","        - Batch size\n","        - Number of epochs to train for\n","        - Number of hidden units in the TinyVGG model\n","    - Keep the default values for each of the above arguments as what they already are (as in notebook 05).\n","    - For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs:  `python train.py --learning_rate 0.003 --batch_size 64 --num_epochs 20`.\n","    - Note: Since `train.py` leverages the other scripts we created in section 05, such as, `model_builder.py`, `utils.py` and `engine.py`, you'll have to make sure they're available to use too. You can find these in the `going_modular` folder on the course GitHub.\n","3. Create a script to predict (such as `predict.py`) on a target image given a file path with a saved model.\n","    - For example, you should be able to run the command python `predict.py some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n","    - To see example prediction code, check out the predicting on a custom image section in notebook 04.\n","    - You may also have to write code to load in a trained model.\n"],"metadata":{"id":"jVmiGzCHj0gG"}},{"cell_type":"markdown","source":["**1.Turn the code to get the data (from section 1. Get Data above where we didnt use script mode but used cell mode) into a Python script, such as `get_data.py`**"],"metadata":{"id":"O3-or8LInJbH"}},{"cell_type":"code","source":["%%writefile going_modular/get_data.py\n","\n","import requests\n","from pathlib import Path\n","import zipfile\n","import os\n","\n","data_path = Path(\"./data\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","        print(\"Downloading pizza, steak, sushi data...\")\n","        f.write(request.content)\n","\n","    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","        print(\"Unzipping pizza, steak, sushi data...\")\n","        zip_ref.extractall(image_path)\n","\n","    # Remove zip file\n","    os.remove(data_path / \"pizza_steak_sushi.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jegaQyMFim0z","executionInfo":{"status":"ok","timestamp":1703351992871,"user_tz":-60,"elapsed":432,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"9af2675e-308f-4a32-9f17-1bd4d5536d8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/get_data.py\n"]}]},{"cell_type":"code","source":["#we can even execute this script using python command instead of importing and executing\n","#!python going_modular/get_data.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcrLS40mmv1x","executionInfo":{"status":"ok","timestamp":1703350624439,"user_tz":-60,"elapsed":13,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"efaf84b3-f26e-45fd-9791-b2b08f4a35e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data/pizza_steak_sushi directory exists.\n"]}]},{"cell_type":"markdown","source":["**2. Use Python's argparse module to be able to send the train.py custom hyperparameter values for training procedures.**\n","\n","Also adding remaining script files for completeness eventhough its there in the file"],"metadata":{"id":"TzURkTFEnBgh"}},{"cell_type":"code","source":["%%writefile going_modular/data_setup.py\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoaders for\n","image classification data.\n","\"\"\"\n","import os\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    num_workers: int=NUM_WORKERS\n","):\n","  \"\"\"Creates training and testing DataLoaders.\n","  Takes in a training directory and testing directory path and turns\n","  them into PyTorch Datasets and then into PyTorch DataLoaders.\n","  Args:\n","    train_dir: Path to training directory.\n","    test_dir: Path to testing directory.\n","    transform: torchvision transforms to perform on training and testing data.\n","    batch_size: Number of samples per batch in each of the DataLoaders.\n","    num_workers: An integer for number of workers per DataLoader.\n","  Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names).\n","    Where class_names is a list of the target classes.\n","    Example usage:\n","      train_dataloader, test_dataloader, class_names = \\\n","        = create_dataloaders(train_dir=path/to/train_dir,\n","                             test_dir=path/to/test_dir,\n","                             transform=some_transform,\n","                             batch_size=32,\n","                             num_workers=4)\n","  \"\"\"\n","  # Use ImageFolder to create dataset(s)\n","  train_data = datasets.ImageFolder(train_dir, transform=transform)\n","  test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Turn images into data loaders\n","  train_dataloader = DataLoader(\n","      train_data,\n","      batch_size=batch_size,\n","      shuffle=True,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","  test_dataloader = DataLoader(\n","      test_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PNEwlMLoea6","executionInfo":{"status":"ok","timestamp":1703352003537,"user_tz":-60,"elapsed":424,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"8c133820-1b5e-46fc-d704-8e150549bcc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/data_setup.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/engine.py\n","\"\"\"\n","Contains functions for training and testing a PyTorch model.\n","\"\"\"\n","import torch\n","\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Trains a PyTorch model for a single epoch.\n","    Turns a target PyTorch model to training mode and then\n","    runs through all of the required training steps (forward\n","    pass, loss calculation, optimizer step).\n","    Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","    Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","    (0.1112, 0.8743)\n","    \"\"\"\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Tests a PyTorch model for a single epoch.\n","    Turns a target PyTorch model to \"eval\" mode and then performs\n","    a forward pass on a testing dataset.\n","    Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","    Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","    (0.0223, 0.8985)\n","    \"\"\"\n","    # Put model in eval mode\n","    model.eval()\n","\n","    # Setup test loss and test accuracy values\n","    test_loss, test_acc = 0, 0\n","\n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # 1. Forward pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss = loss_fn(test_pred_logits, y)\n","            test_loss += loss.item()\n","\n","            # Calculate and accumulate accuracy\n","            test_pred_labels = test_pred_logits.argmax(dim=1)\n","            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List]:\n","    \"\"\"Trains and tests a PyTorch model.\n","    Passes a target PyTorch models through train_step() and test_step()\n","    functions for a number of epochs, training and testing the model\n","    in the same epoch loop.\n","    Calculates, prints and stores evaluation metrics throughout.\n","    Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","    Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for\n","    each epoch.\n","    In the form: {train_loss: [...],\n","              train_acc: [...],\n","              test_loss: [...],\n","              test_acc: [...]}\n","    For example if training for epochs=2:\n","             {train_loss: [2.0616, 1.0537],\n","              train_acc: [0.3945, 0.3945],\n","              test_loss: [1.2641, 1.5706],\n","              test_acc: [0.3400, 0.2973]}\n","    \"\"\"\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"test_loss\": [],\n","               \"test_acc\": []\n","    }\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","        test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          loss_fn=loss_fn,\n","          device=device)\n","\n","        # Print out what's happening\n","        print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","    # Return the filled results at the end of the epochs\n","    return results\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMxypvqEomFx","executionInfo":{"status":"ok","timestamp":1703352014046,"user_tz":-60,"elapsed":513,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"6621c0b3-6a62-45e3-ad37-cf81c07191fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/engine.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/model_builder.py\n","\"\"\"\n","Contains PyTorch model code to instantiate a TinyVGG model.\n","\"\"\"\n","import torch\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","    \"\"\"Creates the TinyVGG architecture.\n","    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","    Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","    \"\"\"\n","    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2)\n","        )\n","        self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","        )\n","        self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          # Where did this in_features shape come from?\n","          # It's because each layer of our network compresses and changes the shape of our inputs data.\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","        )\n","\n","    def forward(self, x: torch.Tensor):\n","        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GBcwX-_ootq","executionInfo":{"status":"ok","timestamp":1703352016933,"user_tz":-60,"elapsed":423,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e9ecedff-659d-4026-dcbf-069689b4021d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/model_builder.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/utils.py\n","\"\"\"\n","Contains various utility functions for PyTorch model training and saving.\n","\"\"\"\n","import torch\n","from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","    \"\"\"Saves a PyTorch model to a target directory.\n","    Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","      either \".pth\" or \".pt\" as the file extension.\n","    Example usage:\n","    save_model(model=model_0,\n","               target_dir=\"models\",\n","               model_name=\"05_going_modular_tingvgg_model.pth\")\n","    \"\"\"\n","    # Create target directory\n","    target_dir_path = Path(target_dir)\n","    target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","    # Create model save path\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","    model_save_path = target_dir_path / model_name\n","\n","    # Save the model state_dict()\n","    print(f\"[INFO] Saving model to: {model_save_path}\")\n","    torch.save(obj=model.state_dict(),\n","             f=model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eh7KLn2_orcT","executionInfo":{"status":"ok","timestamp":1703352020070,"user_tz":-60,"elapsed":406,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"c2000ac7-2b49-45fe-db2c-a014a7690d26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/utils.py\n"]}]},{"cell_type":"code","source":["%%writefile going_modular/train.py\n","\"\"\"\n","Trains a PyTorch image classification model using device-agnostic code.\n","\"\"\"\n","import os\n","import argparse\n","\n","import torch\n","\n","from torchvision import transforms\n","\n","import data_setup, engine, model_builder, utils, get_data\n","\n","# Create a parser\n","parser = argparse.ArgumentParser(description=\"Get some hyperparameters.\")\n","# Create an arg for training directory\n","parser.add_argument(\n","    \"--train_dir\", type=str, default=\"./data/pizza_steak_sushi/train\",\n","    help=\"directory file path to training data in standard image classification format\")\n","# Create an arg for test directory\n","parser.add_argument(\n","    \"--test_dir\", type=str, default=\"./data/pizza_steak_sushi/test\",\n","    help=\"directory file path to testing data in standard image classification format\")\n","# Get an arg for learning_rate\n","parser.add_argument(\n","    \"--lr\", type=float, default=0.001, help=\"learning rate to use for model\")\n","# Get an arg for batch_size\n","parser.add_argument(\n","    \"--batch_size\", type=int, default=32, help=\"number of samples per batch\")\n","# Get an arg for num_epochs\n","parser.add_argument(\n","    \"--num_epochs\", type=int, default=10, help=\"the number of epochs to train for\")\n","# Get an arg for hidden_units\n","parser.add_argument(\n","    \"--hidden_units\", type=int, default=10, help=\"number of hidden units in hidden layers\")\n","args = parser.parse_args()\n","\n","# Setup hyperparameters\n","NUM_EPOCHS = args.num_epochs\n","BATCH_SIZE = args.batch_size\n","HIDDEN_UNITS = args.hidden_units\n","LEARNING_RATE = args.lr\n","print(f\"[INFO] Training a model for {NUM_EPOCHS} epochs with batch size {BATCH_SIZE} using {HIDDEN_UNITS} hidden units and a learning rate of {LEARNING_RATE}\")\n","\n","# Setup directories\n","train_dir = args.train_dir\n","test_dir = args.test_dir\n","print(f\"[INFO] Training data file: {train_dir}\")\n","print(f\"[INFO] Testing data file: {test_dir}\")\n","\n","# Setup target device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Create transforms\n","data_transform = transforms.Compose([\n","  transforms.Resize((64, 64)),\n","  transforms.ToTensor()\n","])\n","\n","# Create DataLoaders with help from data_setup.py\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE\n",")\n","\n","# Create model with help from model_builder.py\n","model = model_builder.TinyVGG(\n","    input_shape=3,\n","    hidden_units=HIDDEN_UNITS,\n","    output_shape=len(class_names)\n",").to(device)\n","\n","# Set loss and optimizer\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),\n","                             lr=LEARNING_RATE)\n","\n","# Start training with help from engine.py\n","engine.train(model=model,\n","             train_dataloader=train_dataloader,\n","             test_dataloader=test_dataloader,\n","             loss_fn=loss_fn,\n","             optimizer=optimizer,\n","             epochs=NUM_EPOCHS,\n","             device=device)\n","\n","# Save the model with help from utils.py\n","utils.save_model(model=model,\n","                 target_dir=\"models\",\n","                 model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRtdEfmRot5M","executionInfo":{"status":"ok","timestamp":1703352084165,"user_tz":-60,"elapsed":62,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3fef6c04-7bd7-4528-87de-3bc11d8c7083"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/train.py\n"]}]},{"cell_type":"code","source":["!python going_modular/train.py --num_epochs 5 --batch_size 128 --hidden_units 128 --lr 0.0003"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lqfFjHKnAyW","executionInfo":{"status":"ok","timestamp":1703352246085,"user_tz":-60,"elapsed":158919,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"2a6197a6-98b9-4212-cf1d-5acee82d5844"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data/pizza_steak_sushi directory exists.\n","[INFO] Training a model for 5 epochs with batch size 128 using 128 hidden units and a learning rate of 0.0003\n","[INFO] Training data file: ./data/pizza_steak_sushi/train\n","[INFO] Testing data file: ./data/pizza_steak_sushi/test\n","  0% 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.1009 | train_acc: 0.3512 | test_loss: 1.0976 | test_acc: 0.3467\n"," 20% 1/5 [00:30<02:00, 30.24s/it]Epoch: 2 | train_loss: 1.0886 | train_acc: 0.4116 | test_loss: 1.0836 | test_acc: 0.4267\n"," 40% 2/5 [00:59<01:28, 29.44s/it]Epoch: 3 | train_loss: 1.0715 | train_acc: 0.4973 | test_loss: 1.0597 | test_acc: 0.4133\n"," 60% 3/5 [01:32<01:02, 31.25s/it]Epoch: 4 | train_loss: 1.0354 | train_acc: 0.5015 | test_loss: 1.0595 | test_acc: 0.3600\n"," 80% 4/5 [02:01<00:30, 30.16s/it]Epoch: 5 | train_loss: 0.9825 | train_acc: 0.5546 | test_loss: 1.0082 | test_acc: 0.3867\n","100% 5/5 [02:32<00:00, 30.56s/it]\n","[INFO] Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"]}]},{"cell_type":"markdown","source":["**3. Create a Python script to predict (such as predict.py) on a target image given a file path with a saved model.**"],"metadata":{"id":"9bKjuokOrL-i"}},{"cell_type":"code","source":["%%writefile going_modular/predict.py\n","import model_builder\n","import torch, torchvision\n","import argparse\n","\n","parser = argparse.ArgumentParser(description=\"Get the image for prediction\")\n","# Get an image path\n","parser.add_argument(\n","    \"--image_path\", type=str, required=True,\n","    help=\"target image filepath to predict on\")\n","\n","# Get model path\n","parser.add_argument(\n","    \"--model_path\", type=str,\n","    default=\"models/05_going_modular_script_mode_tinyvgg_model.pth\",\n","    help=\"target model to use for prediction filepath\")\n","args = parser.parse_args()\n","\n","img_path = args.image_path\n","print(f\"[INFO] Predicting on {img_path}\")\n","\n","model_path = args.model_path\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Setup class names\n","class_names = [\"pizza\", \"steak\", \"sushi\"]\n","\n","# Function to load in the model\n","def load_saved_model(filepath=model_path):\n","    # Need to use same hyperparameters as saved model\n","    model = model_builder.TinyVGG(\n","        input_shape=3,\n","        hidden_units=128,\n","        output_shape=3\n","    ).to(device)\n","\n","    # Load in the saved model state dictionary from file\n","    print(f\"[INFO] Loading in model from: {filepath}\")\n","    model.load_state_dict(torch.load(f=filepath))\n","    return model\n","\n","# Function to load in model + predict on select image\n","def predict_on_image(image_path=img_path, filepath=model_path):\n","    print(\"inside\")\n","    # Load the model\n","    model = load_saved_model(filepath)\n","    # Load in the image and turn it into torch.float32 (same type as model)\n","    img = torchvision.io.read_image(str(image_path))\n","\n","    # Preprocess the image to get it between 0 and 1\n","    img = img / 255.\n","    # Resize the image to be the same size as the model\n","    transform = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize((64, 64), antialias=True)])\n","    transformed_img = transform(img)\n","    # Predict on image\n","    model.eval()\n","    with torch.inference_mode():\n","        # Put image to target device\n","        transformed_img = transformed_img.to(device)\n","        # Get pred logits\n","        pred_logits = model(transformed_img.unsqueeze(dim=0)) # make sure image has batch dimension (shape: [batch_size, height, width, color_channels])\n","        # Get pred probs\n","        pred_prob = torch.softmax(pred_logits, dim=1)\n","        # Get pred labels\n","        pred_label = torch.argmax(pred_prob, dim=1)\n","        pred_label_class = class_names[pred_label]\n","\n","    print(f\"[INFO] Pred class: {pred_label_class}, Pred prob: {pred_prob.max():.3f}\")\n","\n","if __name__ == \"__main__\":\n","    predict_on_image()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8yIrymqwsyus","executionInfo":{"status":"ok","timestamp":1703354098444,"user_tz":-60,"elapsed":378,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"e8bd19f5-9a73-4074-e5a5-acc89b1ac89c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting going_modular/predict.py\n"]}]},{"cell_type":"code","source":["!python going_modular/predict.py --image_path \"./data/pizza_steak_sushi/test/sushi/175783.jpg\" --model_path \"./models/05_going_modular_script_mode_tinyvgg_model.pth\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_y3OF3KyF7H","executionInfo":{"status":"ok","timestamp":1703354105323,"user_tz":-60,"elapsed":3965,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"85d7df83-bcf5-41fb-ef5d-53ea748ae028"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Predicting on ./data/pizza_steak_sushi/test/sushi/175783.jpg\n","inside\n","[INFO] Loading in model from: ./models/05_going_modular_script_mode_tinyvgg_model.pth\n","[INFO] Pred class: pizza, Pred prob: 0.393\n"]}]},{"cell_type":"markdown","source":["###**Extra-curriculum**\n","- To learn more about structuring a Python project, check out Real Python's guide on Python Application Layouts. https://realpython.com/python-application-layouts/\n","- For ideas on styling your PyTorch code, check out the PyTorch style guide by Igor Susmelj https://github.com/IgorSusmelj/pytorch-styleguide#recommended-code-structure-for-training-your-model (much of styling in this chapter is based off this guide + various similar PyTorch repositories).\n","- For an example `train.py` script and various other PyTorch scripts written by the PyTorch team to train state-of-the-art image classification models, check out their classification repository on GitHub.\n","https://github.com/pytorch/vision/tree/main/references/classification\n"],"metadata":{"id":"VEWjDZFcllrJ"}},{"cell_type":"code","source":[],"metadata":{"id":"70JuT-WKl-Xh"},"execution_count":null,"outputs":[]}]}