{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMy7d29iQPZ3qrWuVNijowp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# import locale\n","# locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"3n6zM3s3tg0Z","executionInfo":{"status":"ok","timestamp":1709719669095,"user_tz":-60,"elapsed":616,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpPZJvfbrrbB","executionInfo":{"status":"ok","timestamp":1709719699785,"user_tz":-60,"elapsed":30058,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"3c2e8f7e-8449-4286-ad02-391c2d50f460"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-_qegz213\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-_qegz213\n","  Resolved https://github.com/huggingface/transformers to commit 2890116ab761256c8d7e806c6cbf8f7e841b2abc\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2024.2.2)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8662221 sha256=5acd25f0e683b362b08db15d39e35643074582bf3e29147515ed2fb69eb46a4f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-q2tpz43s/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.38.1\n","    Uninstalling transformers-4.38.1:\n","      Successfully uninstalled transformers-4.38.1\n","Successfully installed transformers-4.39.0.dev0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMuIk94rMAOz","executionInfo":{"status":"ok","timestamp":1709719710591,"user_tz":-60,"elapsed":10819,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"1e474fbf-88c6-4b49-8f0f-f24172af55a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchmetrics\n","  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","Installing collected packages: torchinfo, smmap, setproctitle, sentry-sdk, lightning-utilities, docker-pycreds, dill, responses, multiprocess, gitdb, torchmetrics, GitPython, wandb, datasets, evaluate\n","Successfully installed GitPython-3.1.42 datasets-2.18.0 dill-0.3.8 docker-pycreds-0.4.0 evaluate-0.4.1 gitdb-4.0.11 lightning-utilities-0.10.1 multiprocess-0.70.16 responses-0.18.0 sentry-sdk-1.40.6 setproctitle-1.3.3 smmap-5.0.1 torchinfo-1.8.0 torchmetrics-1.3.1 wandb-0.16.4\n"]}],"source":["!pip install datasets evaluate wandb torchmetrics torchinfo"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn.functional as F\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.cuda.amp import GradScaler, autocast\n","from transformers import AutoModelForUniversalSegmentation, Mask2FormerImageProcessor\n","import torchvision.transforms as tvt\n","from torchvision.transforms.functional import crop\n","from torchmetrics.classification import Accuracy, MulticlassAccuracy, MulticlassJaccardIndex, JaccardIndex\n","import albumentations as A\n","from tqdm.auto import tqdm\n","from huggingface_hub import notebook_login\n","from datasets import load_dataset\n","import wandb\n","import evaluate\n","import statistics\n","from copy import deepcopy\n","from huggingface_hub import hf_hub_download\n","import torchinfo\n","\n","import numpy as np\n","import pandas as pd\n","import random\n","import requests\n","import json\n","from pathlib import Path\n","import os\n","from typing import List, Dict, Tuple\n","import warnings\n","from PIL import Image as PILImage\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","#warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","def set_seeds(seed):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.empty_cache()\n","    torch.backends.cudnn.benchmark = True\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.enabled = True"],"metadata":{"id":"5-zKn2VURvcK","executionInfo":{"status":"ok","timestamp":1709719723041,"user_tz":-60,"elapsed":12481,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# import os\n","# os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"],"metadata":{"id":"iQL9HbLRiPaT","executionInfo":{"status":"ok","timestamp":1709719723041,"user_tz":-60,"elapsed":13,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#!huggingface-cli login\n","from huggingface_hub import login\n","from google.colab import userdata\n","import wandb\n","\n","login(token=userdata.get('HF_TOKEN'))\n","wandb.login(key=userdata.get('WANDB_API_KEY'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-3lOygnRzIe","executionInfo":{"status":"ok","timestamp":1709719728965,"user_tz":-60,"elapsed":5937,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"248695fe-8261-44bd-f5b2-d4a042bcfc8d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def get_labels():\n","    data_directory = Path(\".\")\n","    json_file_path = data_directory / \"labels_info.json\"\n","    if json_file_path.is_file():\n","        print(f\"[INFO]: Found {json_file_path}.Skipping Download...\")\n","    else:\n","        print(\"[INFO]: Downloading labels_info.json from hub\")\n","        json_file_path = hf_hub_download(\n","            repo_id=\"BhavanaMalla/railsem19-semantic-expanded\",\n","            filename=\"labels_info.json\",\n","            repo_type=\"dataset\",\n","            local_dir=data_directory\n","        )\n","    with open(json_file_path, \"r\") as f:\n","        labels_info = json.load(f)\n","    id2label = labels_info[\"id2label\"]\n","    label2id = labels_info[\"label2id\"]\n","    labels = labels_info[\"labels\"]\n","    color_palette = labels_info[\"color_palette\"]\n","\n","    # add the background label\n","    id2label[\"19\"] = \"background\"\n","    label2id[\"background\"] = 19\n","    labels.append(\"background\")\n","    color_palette.append([0, 0, 0])\n","\n","    # correcting the labels\n","    id2label = {int(key): value.replace('-', '_') \\\n","                for key, value in id2label.items()}\n","    label2id = {key.replace('-', '_'): value for key, value in label2id.items()}\n","    labels = [label.replace('-', '_') for label in labels]\n","    return {\"id2label\": id2label, \"label2id\": label2id, \"labels\": labels,\n","            \"color_palette\": color_palette}"],"metadata":{"id":"v6T8bqbUOipW","executionInfo":{"status":"ok","timestamp":1709719728965,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def load_railsem_dataset():\n","    print(f\"[INFO]: Extracting Railsem19 dataset from hub on\")\n","    railsem_ds = load_dataset(\"BhavanaMalla/railsem19-semantic-expanded\")\n","    return railsem_ds"],"metadata":{"id":"OWCZWNLkOl7X","executionInfo":{"status":"ok","timestamp":1709719728966,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def get_modified_labels():\n","    modified_id2label = {\n","        0: \"road\", 1: \"sidewalk\", 2: \"construction_fence\",\n","        3: \"rail_raised_rail_embedded\", 4: \"pole_traffic_light_traffic_sign\",\n","        5: \"sky\", 6: \"human\", 7: \"tram_track_rail_track\", 8: \"car_truck\",\n","        9: \"on_rails\", 10: \"vegetation\", 11: \"trackbed\",\n","        12: \"background_terrain\"\n","    }\n","    modified_label2id = {\n","        label: id for id, label in modified_id2label.items()\n","    }\n","    modified_labels = [label for label in modified_id2label.values()]\n","    return modified_id2label, modified_label2id, modified_labels"],"metadata":{"id":"vjwF6kvLOnzG","executionInfo":{"status":"ok","timestamp":1709719728966,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class RemapBackground():\n","    \"\"\" Remap background to label 19 \"\"\"\n","    def __call__(self, mask):\n","        return torch.where(mask > 18, 19, mask)\n","\n","\n","class RemapLabels():\n","    def __init__(self):\n","        self.class_mapping = get_labels()[\"id2label\"]\n","        self.class_coding = {v: k for k, v in self.class_mapping.items()}\n","\n","        # Remapping of original 20 labels to 13 labels\n","        self.modified_labels = {\n","            0: [\"road\"], 1: [\"sidewalk\"],\n","            2: [\"construction\", \"fence\"],\n","            3: [\"rail_raised\", \"rail_embedded\"],\n","            4: [\"pole\", \"traffic_light\", \"traffic_sign\"],\n","            5: [\"sky\"], 6: [\"human\"],\n","            7: [\"tram_track\", \"rail_track\"],\n","            8: [\"car\", \"truck\"], 9: [\"on_rails\"],\n","            10: [\"vegetation\"], 11: [\"trackbed\"],\n","            12: [\"background\", \"terrain\"]\n","        }\n","        self.modified_ids = {}\n","        for k, v in self.modified_labels.items():\n","            self.modified_ids[k] = [self.class_coding[label] for label in v]\n","\n","    def __call__(self, mask):\n","        final_label = np.zeros_like(mask)\n","        for key, val in self.modified_ids.items():\n","            specific_label = np.zeros_like(mask)\n","            specific_label = np.where(np.isin(mask, np.array(val)), 1, 0)\n","            specific_label *= key\n","            final_label = np.add(final_label, specific_label)\n","        return torch.from_numpy(final_label)\n","\n"],"metadata":{"id":"lqdJP_AqOVEf","executionInfo":{"status":"ok","timestamp":1709719728966,"user_tz":-60,"elapsed":10,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class PatchQueue(Dataset):\n","    '''\n","    Extract random patches from an image -> put them in queue\n","    -> feed them to the dataloader\n","    ref : https://github.com/fepegar/torchio/blob/main/src/torchio/data/queue.py\n","    '''\n","    def __init__(self, dataset, max_length,  # Queue Length\n","                 samples_per_image,  # Patches per image\n","                 queue_workers=4,  # Num Workers\n","                 patch_size=[512, 512],  # Patch Size\n","                 shuffle=False):\n","        self.dataset = dataset\n","        self.max_length = max_length\n","        self.queue_workers = queue_workers\n","        self.samples_per_image = samples_per_image\n","        self.shuffle_queue = shuffle\n","        self.patch_size = patch_size\n","        self._images_iterable = None\n","        self.patch_list = list()\n","        self._num_sampled_images = 0\n","        self.steps_per_epoch = len(self.dataset) * self.samples_per_image\n","        self.resize_transform = tvt.Resize(patch_size[::-1])\n","\n","    def __len__(self):\n","        return self.steps_per_epoch\n","\n","    def __getitem__(self, item):\n","        if not self.patch_list:\n","            print(\"[WARN]: Patch List is empty...\")\n","            self._fill()\n","            self.patch_list.reverse()\n","        sample_patch = self.patch_list.pop()\n","        return sample_patch\n","\n","    @staticmethod\n","    def _get_first_item(batch):\n","        return batch[0]\n","\n","    def initialize_images_iterable(self):\n","        self._images_iterable = self._get_images_iterable()\n","\n","    @property\n","    def images_iterable(self):\n","        if self._images_iterable is None:\n","            self.initialize_images_iterable()\n","        return self.images_iterable\n","\n","    def _get_images_iterable(self):\n","        if torch.distributed.is_available() and torch.distributed.is_initialized():\n","            sampler = torch.utils.data.DistributedSampler(\n","                self.dataset,\n","                num_replicas=torch.distributed.get_world_size(),\n","                rank=torch.distributed.get_rank(), shuffle=self.shuffle_queue\n","            )\n","        else:\n","            sampler = None\n","        loader = DataLoader(\n","            self.dataset,  # num_workers=self.queue_workers, #in multigpu, >0 not wrkng\n","            batch_size=1, collate_fn=self._get_first_item, pin_memory=True,\n","            shuffle=False, sampler=sampler\n","        )\n","        self._num_sampled_images = 0\n","        return iter(loader)\n","\n","    def _get_next_image(self):\n","        try:\n","            image = next(self._images_iterable)\n","        except Exception as e:\n","            print(f\"[WARN]:Exception while getting image for patching: {e}\")\n","            self.initialize_images_iterable()\n","            image = next(self._images_iterable)\n","        return image\n","\n","    def extract_patches(self, image_pair, samples_per_image, patch_size):\n","        image_patches = []\n","        img_height = image_pair['image'].shape[-2]\n","        img_width = image_pair['image'].shape[-1]\n","        # Check if image size is smaller than patch size\n","        if img_height < patch_size[0] or img_width < patch_size[1]:\n","            # Resize the image to match the patch size\n","            image_pair[\"image\"] = self.resize_transform(image_pair[\"image\"])\n","            image_pair[\"mask\"] = self.resize_transform(image_pair[\"mask\"])\n","            img_height = image_pair[\"image\"].shape[-2]\n","            img_width = image_pair[\"image\"].shape[-1]\n","        for _ in range(samples_per_image):\n","            left = torch.randint(\n","                low=0, high=img_width-patch_size[0], size=[1,]\n","            ).item()\n","            top = torch.randint(\n","                low=0, high=img_height-patch_size[1], size=[1,]\n","            ).item()\n","            cropped_image = crop(\n","                img=image_pair[\"image\"], top=top, left=left,\n","                height=patch_size[1], width=patch_size[0]\n","            )\n","            cropped_labels = crop(\n","                img=image_pair[\"mask\"], top=top, left=left,\n","                height=patch_size[1], width=patch_size[0]\n","            )\n","            image_patches.append({\"image\": cropped_image,\n","                                  \"mask\": cropped_labels})\n","        return image_patches\n","\n","    def _fill(self):\n","        while True:\n","            image_pair = self._get_next_image()\n","            samples_per_image = self.samples_per_image\n","            patch_size = self.patch_size\n","            patches = self.extract_patches(\n","                image_pair, samples_per_image, patch_size\n","            )\n","            self.patch_list.extend(patches)\n","            self._num_sampled_images += 1\n","            islistfull = len(self.patch_list) >= self.max_length\n","            if islistfull:\n","                break"],"metadata":{"id":"UPCD4IacPnBI","executionInfo":{"status":"ok","timestamp":1709719728966,"user_tz":-60,"elapsed":9,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def get_transforms():\n","    # Transforms\n","    image_transforms = tvt.Compose([tvt.PILToTensor(),])\n","    mask_transforms = tvt.Compose([tvt.PILToTensor(),\n","                                  RemapBackground(),\n","                                  RemapLabels(),])\n","    return image_transforms, mask_transforms"],"metadata":{"id":"IKTtSkwnOajS","executionInfo":{"status":"ok","timestamp":1709719728966,"user_tz":-60,"elapsed":9,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, dataset, transforms=None):\n","        self.dataset = dataset\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image = self.dataset[idx][\"image\"]\n","        semantic_mask = self.dataset[idx][\"semantic_mask_label\"]\n","        if self.transforms:\n","            image_transforms, mask_transforms = self.transforms\n","            transformed_image = image_transforms(image)\n","            transformed_mask = mask_transforms(semantic_mask)\n","        else:\n","            image_transforms, mask_transforms = get_transforms()\n","            transformed_image = image_transforms(image)\n","            transformed_mask = mask_transforms(semantic_mask)\n","        return {\n","            \"image\": transformed_image, \"mask\": transformed_mask\n","        }"],"metadata":{"id":"abSPValFOXsh","executionInfo":{"status":"ok","timestamp":1709719728966,"user_tz":-60,"elapsed":9,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def _collate_fn(batch):\n","    # images = torch.stack([sample[\"image\"] for sample in batch])\n","    # segmentation_maps = torch.cat([sample[\"mask\"] for sample in batch])\n","    images = tuple([sample[\"image\"] for sample in batch])\n","    segmentation_maps = tuple([sample[\"mask\"].squeeze() for sample in batch])\n","    # batch = processor(images, segmentation_maps=segmentation_maps, task_inputs=[\"semantic\"] * len(images), return_tensors=\"pt\")\n","    batch = processor(images, segmentation_maps=segmentation_maps, return_tensors=\"pt\")\n","    batch[\"original_images\"] = images\n","    batch[\"original_segmentation_maps\"] = segmentation_maps\n","    return batch\n","\n","def _prepare_dataloader(dataset: torch.utils.data.Dataset):\n","    sampler = None\n","    is_train=True\n","    dataloader = DataLoader(dataset, batch_size=4, pin_memory=True, shuffle=(is_train and sampler is None), sampler=sampler, collate_fn=_collate_fn)\n","    return dataloader"],"metadata":{"id":"cjskHobAR8XE","executionInfo":{"status":"ok","timestamp":1709724158629,"user_tz":-60,"elapsed":333,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation,  AutoConfig\n","import torch.nn.functional as F\n","from torch import nn\n","import gc\n","from torch.cuda.amp import GradScaler, autocast\n","\n","\n","# id2label\n","id2label, label2id, labels = get_modified_labels()\n","# model and processor\n","model_ckpt = \"facebook/mask2former-swin-tiny-cityscapes-semantic\"\n","model_config = AutoConfig.from_pretrained(model_ckpt, id2label=id2label, label2id=label2id, num_labels=len(id2label))\n","model = AutoModelForUniversalSegmentation.from_pretrained(model_ckpt, ignore_mismatched_sizes=True, config=model_config)\n","\n","processor = AutoImageProcessor.from_pretrained(model_ckpt, ignore_index=255, do_reduce_labels=False, do_resize=False) #384, 384 without do_resize=False\n","#default - \"do_normalize\": true, \"do_rescale\": true, \"do_resize\": true, \"ignore_index\": 255, \"reduce_labels\": false,\n","processor.num_labels = len(id2label)\n","\n","#dataset\n","mydataset = load_railsem_dataset()\n","total_size = len(mydataset[\"data\"])\n","print(f\"[INFO]: Total images: {total_size}\")\n","train_size = 8160\n","train_percentage = train_size / total_size\n","# Use train_test_split with specified percentages\n","splits = mydataset[\"data\"].train_test_split(train_size=train_percentage, shuffle=True)\n","train_split = splits[\"train\"]\n","val_split = splits[\"test\"].select(indices=(range(320))) #320\n","test_split = splits[\"test\"].select(indices=(range(20)))\n","print(f\"[INFO]: Total Training images: {len(train_split)}\")\n","print(f\"[INFO]: Total Validation images: {len(val_split)}\")\n","print(f\"[INFO]: Total Test images: {len(test_split)}\")\n","\n","# transforms\n","transforms = get_transforms()\n","customdataset = CustomDataset(train_split.select(range(0, 6)), transforms) #1080, 1920\n","# customdataset = CustomDataset(train_split, transforms)\n","\n","patch_size = [1024, 1024] #[512, 512] #[1024, 1024]\n","train_queue = PatchQueue(customdataset, max_length=10, samples_per_image=2, patch_size=patch_size) #1024, 1024\n","dataloader = _prepare_dataloader(train_queue) #train_queue #customdataset\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","if torch.cuda.is_available():\n","    torch.cuda.reset_max_memory_allocated()\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","optimizer = AdamW(params=model.parameters(), lr=1e-4)\n","scaler = GradScaler()\n","epochs = 2\n","\n","model.to(device)\n","model.train()\n","for i in range(epochs):\n","    print(f\"------------Epoch: {i}-----------------\")\n","    running_train_loss = 0.0\n","    for step, batch in enumerate(dataloader):\n","        print(batch.keys())\n","        print(f'pixel_values: {batch[\"pixel_values\"].shape}')\n","        batch_dict = {\n","                \"pixel_values\": batch[\"pixel_values\"].to(device),\n","                \"mask_labels\": [labels.to(device)\n","                                for labels in batch[\"mask_labels\"]],\n","                \"class_labels\": [labels.to(device)\n","                                    for labels in batch[\"class_labels\"]],\n","                \"pixel_mask\": batch[\"pixel_mask\"].to(device),}\n","        # with torch.autocast(device_type='cpu', dtype=torch.bfloat16):\n","        with autocast():\n","            print(f'mask_labels: {batch[\"mask_labels\"][0].shape}, {batch[\"mask_labels\"][1].shape}') # mask_labels: torch.Size([8, 384, 384]), torch.Size([11, 384, 384])\n","            print(f'class_labels: {batch[\"class_labels\"][0]}, {batch[\"class_labels\"][1]}') # class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","            outputs = model(**batch_dict)\n","            train_loss = outputs.loss\n","        # print(outputs.keys())  # dict_keys(['loss', 'class_queries_logits', 'masks_queries_logits', 'encoder_last_hidden_state', 'pixel_decoder_last_hidden_state', 'transformer_decoder_last_hidden_state'])\n","        print(f\"Step: {step}, Train Loss: {train_loss.item()}\")\n","        batch_size = batch[\"pixel_values\"].size(0)\n","        running_train_loss += train_loss.item() * batch_size\n","        scaler.scale(train_loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        del batch, outputs\n","    running_train_loss = torch.tensor([running_train_loss], device=device)\n","    train_epoch_loss = running_train_loss.item() / len(train_queue) #customdataset\n","    print(f\"Epoch: {i}, Train Loss: {train_epoch_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzgXhxu0JbKn","executionInfo":{"status":"ok","timestamp":1709722536873,"user_tz":-60,"elapsed":51798,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}},"outputId":"66895b98-6880-4209-cc1e-7598e94236dc"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-tiny-cityscapes-semantic and are newly initialized because the shapes did not match:\n","- class_predictor.bias: found shape torch.Size([20]) in the checkpoint and torch.Size([14]) in the model instantiated\n","- class_predictor.weight: found shape torch.Size([20, 256]) in the checkpoint and torch.Size([14, 256]) in the model instantiated\n","- criterion.empty_weight: found shape torch.Size([20]) in the checkpoint and torch.Size([14]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["[INFO]: Extracting Railsem19 dataset from hub on\n","[INFO]: Total images: 8500\n","[INFO]: Total Training images: 8160\n","[INFO]: Total Validation images: 320\n","[INFO]: Total Test images: 20\n","[INFO]: Found labels_info.json.Skipping Download...\n","------------Epoch: 0-----------------\n","[WARN]: Patch List is empty...\n","[WARN]:Exception while getting image for patching: 'NoneType' object is not an iterator\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([10, 1024, 1024]), torch.Size([9, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5, 10, 11, 12])\n","Step: 0, Train Loss: 113.28421020507812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([11, 1024, 1024]), torch.Size([12, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 1, Train Loss: 108.56378936767578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([12, 1024, 1024]), torch.Size([11, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 2, Train Loss: 105.67524719238281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([10, 1024, 1024]), torch.Size([10, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 3, Train Loss: 115.48103332519531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([11, 1024, 1024]), torch.Size([12, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 4, Train Loss: 109.83306884765625\n","[WARN]: Patch List is empty...\n","[WARN]:Exception while getting image for patching: \n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([10, 1024, 1024]), torch.Size([10, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 5, Train Loss: 112.04863739013672\n","Epoch: 0, Train Loss: 110.8143310546875\n","------------Epoch: 1-----------------\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([10, 1024, 1024]), torch.Size([11, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 0, Train Loss: 108.44051361083984\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([12, 1024, 1024]), torch.Size([12, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 1, Train Loss: 111.82447814941406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([11, 1024, 1024]), torch.Size([11, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 2, Train Loss: 114.80219268798828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([10, 1024, 1024]), torch.Size([10, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 3, Train Loss: 114.97059631347656\n","[WARN]: Patch List is empty...\n","[WARN]:Exception while getting image for patching: \n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([12, 1024, 1024]), torch.Size([13, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n","Step: 4, Train Loss: 112.31814575195312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([2, 3, 1024, 1024])\n","mask_labels: torch.Size([10, 1024, 1024]), torch.Size([10, 1024, 1024])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 5, Train Loss: 111.75819396972656\n","Epoch: 1, Train Loss: 112.35235595703125\n"]}]},{"cell_type":"code","source":["from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation,  AutoConfig\n","import torch.nn.functional as F\n","from torch import nn\n","import gc\n","from torch.cuda.amp import GradScaler, autocast\n","\n","\n","# id2label\n","id2label, label2id, labels = get_modified_labels()\n","# model and processor\n","model_ckpt = \"facebook/mask2former-swin-tiny-cityscapes-semantic\"\n","model_config = AutoConfig.from_pretrained(model_ckpt, id2label=id2label, label2id=label2id, num_labels=len(id2label))\n","model = AutoModelForUniversalSegmentation.from_pretrained(model_ckpt, ignore_mismatched_sizes=True, config=model_config)\n","\n","processor = AutoImageProcessor.from_pretrained(model_ckpt, ignore_index=255, do_reduce_labels=False, do_resize=False) #384, 384 without do_resize=False\n","#default - \"do_normalize\": true, \"do_rescale\": true, \"do_resize\": true, \"ignore_index\": 255, \"reduce_labels\": false,\n","processor.num_labels = len(id2label)\n","\n","#dataset\n","mydataset = load_railsem_dataset()\n","total_size = len(mydataset[\"data\"])\n","print(f\"[INFO]: Total images: {total_size}\")\n","train_size = 8160\n","train_percentage = train_size / total_size\n","# Use train_test_split with specified percentages\n","splits = mydataset[\"data\"].train_test_split(train_size=train_percentage, shuffle=True)\n","train_split = splits[\"train\"]\n","val_split = splits[\"test\"].select(indices=(range(320))) #320\n","test_split = splits[\"test\"].select(indices=(range(20)))\n","print(f\"[INFO]: Total Training images: {len(train_split)}\")\n","print(f\"[INFO]: Total Validation images: {len(val_split)}\")\n","print(f\"[INFO]: Total Test images: {len(test_split)}\")\n","\n","# transforms\n","transforms = get_transforms()\n","# customdataset = CustomDataset(train_split.select(range(0, 6)), transforms) #1080, 1920\n","customdataset = CustomDataset(train_split, transforms)\n","\n","patch_size = [512, 512] # [512, 512] #[1024, 1024]\n","train_queue = PatchQueue(customdataset, max_length=10, samples_per_image=5, patch_size=patch_size) #1024, 1024\n","dataloader = _prepare_dataloader(train_queue) #train_queue #customdataset\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","if torch.cuda.is_available():\n","    torch.cuda.reset_max_memory_allocated()\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","optimizer = AdamW(params=model.parameters(), lr=1e-4)\n","scaler = GradScaler()\n","epochs = 1\n","print(f\"Train Queue: {len(train_queue)}\")\n","\n","model.to(device)\n","model.train()\n","for i in range(epochs):\n","    print(f\"------------Epoch: {i}-----------------\")\n","    running_train_loss = 0.0\n","    for step, batch in enumerate(dataloader):\n","        print(batch.keys())\n","        print(f'pixel_values: {batch[\"pixel_values\"].shape}')\n","        batch_dict = {\n","                \"pixel_values\": batch[\"pixel_values\"].to(device),\n","                \"mask_labels\": [labels.to(device)\n","                                for labels in batch[\"mask_labels\"]],\n","                \"class_labels\": [labels.to(device)\n","                                    for labels in batch[\"class_labels\"]],\n","                \"pixel_mask\": batch[\"pixel_mask\"].to(device),}\n","        # with torch.autocast(device_type='cpu', dtype=torch.bfloat16):\n","        with autocast():\n","            print(f'mask_labels: {batch[\"mask_labels\"][0].shape}, {batch[\"mask_labels\"][1].shape}') # mask_labels: torch.Size([8, 384, 384]), torch.Size([11, 384, 384])\n","            print(f'class_labels: {batch[\"class_labels\"][0]}, {batch[\"class_labels\"][1]}') # class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","            outputs = model(**batch_dict)\n","            train_loss = outputs.loss\n","        # print(outputs.keys())  # dict_keys(['loss', 'class_queries_logits', 'masks_queries_logits', 'encoder_last_hidden_state', 'pixel_decoder_last_hidden_state', 'transformer_decoder_last_hidden_state'])\n","        print(f\"Step: {step}, Train Loss: {train_loss.item()}\")\n","        batch_size = batch[\"pixel_values\"].size(0)\n","        running_train_loss += train_loss.item() * batch_size\n","        scaler.scale(train_loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        del batch, outputs\n","    running_train_loss = torch.tensor([running_train_loss], device=device)\n","    train_epoch_loss = running_train_loss.item() / len(train_queue) #customdataset\n","    print(f\"Epoch: {i}, Train Loss: {train_epoch_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVN822DxZ_FK","outputId":"c034c9d5-dab1-4a71-c250-b3f8d0f6b318"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-tiny-cityscapes-semantic and are newly initialized because the shapes did not match:\n","- class_predictor.bias: found shape torch.Size([20]) in the checkpoint and torch.Size([14]) in the model instantiated\n","- class_predictor.weight: found shape torch.Size([20, 256]) in the checkpoint and torch.Size([14, 256]) in the model instantiated\n","- criterion.empty_weight: found shape torch.Size([20]) in the checkpoint and torch.Size([14]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  5, 11, 12]), tensor([ 2,  3,  4,  5, 11, 12])\n","Step: 8454, Train Loss: 97.7938461303711\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8455, Train Loss: 99.00200653076172\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  6,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8456, Train Loss: 100.3018798828125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8457, Train Loss: 95.64733123779297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 12]), tensor([ 1,  2,  4,  6,  8, 12])\n","Step: 8458, Train Loss: 94.0289077758789\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8459, Train Loss: 113.23018646240234\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 8460, Train Loss: 101.62566375732422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8461, Train Loss: 105.8584976196289\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  3,  4,  7, 10, 11, 12]), tensor([ 1,  3,  4,  7, 10, 11, 12])\n","Step: 8462, Train Loss: 106.8009262084961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10]), tensor([ 0,  1,  2,  4,  8, 10, 12])\n","Step: 8463, Train Loss: 101.0241928100586\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 11, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 8464, Train Loss: 109.73887634277344\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  8, 11]), tensor([ 1,  2,  3,  4,  5,  7,  8, 11])\n","Step: 8465, Train Loss: 107.2252197265625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 11]), tensor([ 3,  7, 10, 11, 12])\n","Step: 8466, Train Loss: 113.72055053710938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  4,  5,  8, 10, 11, 12])\n","Step: 8467, Train Loss: 100.75271606445312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  3,  5, 10, 11, 12]), tensor([10, 12])\n","Step: 8468, Train Loss: 96.7356185913086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11, 12]), tensor([ 2,  3,  7, 10, 11, 12])\n","Step: 8469, Train Loss: 113.68399047851562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8470, Train Loss: 104.44867706298828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([2, 5])\n","Step: 8471, Train Loss: 101.335205078125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11]), tensor([ 2,  4,  5, 10])\n","Step: 8472, Train Loss: 112.56259155273438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8473, Train Loss: 109.49790954589844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8474, Train Loss: 99.47098541259766\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8475, Train Loss: 106.01834869384766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  7, 10, 11, 12])\n","Step: 8476, Train Loss: 110.53559875488281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8477, Train Loss: 108.41915130615234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8478, Train Loss: 101.77703857421875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8479, Train Loss: 99.7118911743164\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  6,  9, 11]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8480, Train Loss: 104.662109375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  6,  8,  9, 10, 11, 12]), tensor([ 4,  5, 10])\n","Step: 8481, Train Loss: 102.11732482910156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8482, Train Loss: 94.30865478515625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 8483, Train Loss: 94.9956283569336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  3,  7,  9, 10, 11, 12])\n","Step: 8484, Train Loss: 105.89386749267578\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([0, 1, 2, 4, 6, 8]), tensor([ 0,  1,  3,  6,  7, 12])\n","Step: 8485, Train Loss: 103.31817626953125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([0, 3, 7]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8486, Train Loss: 105.99837493896484\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8487, Train Loss: 108.2800521850586\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10])\n","Step: 8488, Train Loss: 95.08903503417969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  6,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  6,  7, 10, 11, 12])\n","Step: 8489, Train Loss: 100.03290557861328\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8490, Train Loss: 96.39010620117188\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  5,  8, 10, 12]), tensor([ 0,  1,  2,  4,  5, 10, 12])\n","Step: 8491, Train Loss: 102.51235961914062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8492, Train Loss: 95.94214630126953\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12])\n","Step: 8493, Train Loss: 96.6817855834961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8494, Train Loss: 85.47347259521484\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7,  9, 11, 12]), tensor([ 1,  2,  3,  4,  7, 11, 12])\n","Step: 8495, Train Loss: 109.9085693359375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 11]), tensor([ 0,  1,  3,  4,  7, 10, 11, 12])\n","Step: 8496, Train Loss: 98.88847351074219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11]), tensor([ 1,  3,  7, 11, 12])\n","Step: 8497, Train Loss: 98.1379623413086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([10]), tensor([ 2, 10])\n","Step: 8498, Train Loss: 79.97947692871094\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 4, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8499, Train Loss: 103.03849792480469\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([10, 11]), tensor([10])\n","Step: 8500, Train Loss: 91.60191345214844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8501, Train Loss: 114.24171447753906\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6, 10, 12])\n","Step: 8502, Train Loss: 110.43865966796875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5,  8,  9, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8503, Train Loss: 105.24886322021484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  9, 10, 11, 12]), tensor([ 1,  2,  9, 11, 12])\n","Step: 8504, Train Loss: 104.14715576171875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8505, Train Loss: 105.03511047363281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8506, Train Loss: 99.31217193603516\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8507, Train Loss: 105.88815307617188\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 8508, Train Loss: 99.11551666259766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8509, Train Loss: 104.8167495727539\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8510, Train Loss: 104.574951171875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  4,  6,  8, 10])\n","Step: 8511, Train Loss: 97.58245849609375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10])\n","Step: 8512, Train Loss: 96.18217468261719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  5, 10, 11, 12])\n","Step: 8513, Train Loss: 101.89851379394531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8514, Train Loss: 102.22097778320312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 4, 10]), tensor([ 2,  3,  4, 10, 11, 12])\n","Step: 8515, Train Loss: 92.17523956298828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8516, Train Loss: 99.98998260498047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8517, Train Loss: 116.40445709228516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8518, Train Loss: 105.13224792480469\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  7,  9, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8519, Train Loss: 99.7385482788086\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8520, Train Loss: 99.66574096679688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8521, Train Loss: 95.15100860595703\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 8522, Train Loss: 87.76754760742188\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8523, Train Loss: 101.17707824707031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8524, Train Loss: 112.31776428222656\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 12]), tensor([ 0,  2,  3,  4,  5, 10, 12])\n","Step: 8525, Train Loss: 96.11876678466797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8526, Train Loss: 97.6998062133789\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([10, 12]), tensor([ 5, 10, 12])\n","Step: 8527, Train Loss: 93.96648406982422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10, 11, 12])\n","Step: 8528, Train Loss: 100.7497787475586\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8529, Train Loss: 98.32330322265625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 8530, Train Loss: 94.02011108398438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11, 12]), tensor([1, 2])\n","Step: 8531, Train Loss: 101.97069549560547\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2, 12])\n","Step: 8532, Train Loss: 109.97803497314453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8533, Train Loss: 101.87970733642578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 11, 12]), tensor([ 2,  4, 10, 11, 12])\n","Step: 8534, Train Loss: 94.13130950927734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11])\n","Step: 8535, Train Loss: 102.65206146240234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8536, Train Loss: 99.32200622558594\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8537, Train Loss: 107.69571685791016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([2]), tensor([ 2, 11])\n","Step: 8538, Train Loss: 93.22713470458984\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 8539, Train Loss: 108.89192199707031\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  4,  5, 10, 12])\n","Step: 8540, Train Loss: 101.22210693359375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8541, Train Loss: 105.34245300292969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  9, 11])\n","Step: 8542, Train Loss: 106.39057159423828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8543, Train Loss: 110.52024841308594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 12]), tensor([ 0,  1,  2,  4,  6,  8, 10, 12])\n","Step: 8544, Train Loss: 97.43156433105469\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([2, 4, 5]), tensor([ 2,  4,  5, 11])\n","Step: 8545, Train Loss: 95.93694305419922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([2, 9]), tensor([ 2,  4, 10, 12])\n","Step: 8546, Train Loss: 91.569091796875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  4, 10, 11, 12])\n","Step: 8547, Train Loss: 109.04165649414062\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11, 12])\n","Step: 8548, Train Loss: 107.11451721191406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 3,  4,  7,  8, 10, 11, 12])\n","Step: 8549, Train Loss: 111.38135528564453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8550, Train Loss: 94.22889709472656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8551, Train Loss: 112.34385681152344\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8552, Train Loss: 108.99930572509766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  9, 10, 11, 12]), tensor([ 3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8553, Train Loss: 106.43231964111328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8554, Train Loss: 108.86715698242188\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  5, 10, 11, 12])\n","Step: 8555, Train Loss: 107.61048126220703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8556, Train Loss: 111.31221771240234\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  9, 10, 12]), tensor([ 2,  4,  5,  8,  9, 10, 12])\n","Step: 8557, Train Loss: 103.74356842041016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8558, Train Loss: 94.602783203125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 2,  4,  5,  9, 10])\n","Step: 8559, Train Loss: 103.01262664794922\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8560, Train Loss: 106.46728515625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  3,  7, 10, 11, 12])\n","Step: 8561, Train Loss: 107.6716079711914\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8562, Train Loss: 107.06742858886719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  3,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12])\n","Step: 8563, Train Loss: 109.06529998779297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8564, Train Loss: 105.0829849243164\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8565, Train Loss: 105.24353790283203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 10, 11]), tensor([10, 12])\n","Step: 8566, Train Loss: 97.55050659179688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 8567, Train Loss: 103.03528594970703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8568, Train Loss: 113.85492706298828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11, 12]), tensor([ 1,  2, 10, 12])\n","Step: 8569, Train Loss: 103.03626251220703\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 10, 11, 12]), tensor([ 3,  7, 10, 11, 12])\n","Step: 8570, Train Loss: 103.24290466308594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([2, 5])\n","Step: 8571, Train Loss: 102.4687271118164\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 11, 12])\n","Step: 8572, Train Loss: 107.78359985351562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12])\n","Step: 8573, Train Loss: 104.91645050048828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 8574, Train Loss: 109.94480895996094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8575, Train Loss: 119.64156341552734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8576, Train Loss: 116.37263488769531\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  7, 11]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8577, Train Loss: 106.82655334472656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 8578, Train Loss: 111.04778289794922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 12]), tensor([ 0,  1,  2,  4, 10, 11, 12])\n","Step: 8579, Train Loss: 115.34300994873047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  5,  7, 10, 11, 12])\n","Step: 8580, Train Loss: 112.30793762207031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  3,  7, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8581, Train Loss: 109.35440063476562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8582, Train Loss: 106.35289001464844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  5, 10])\n","Step: 8583, Train Loss: 100.65625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 8584, Train Loss: 102.00151062011719\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11, 12])\n","Step: 8585, Train Loss: 93.03399658203125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8586, Train Loss: 103.28227233886719\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8587, Train Loss: 102.37867736816406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8588, Train Loss: 94.96595001220703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  9, 10]), tensor([ 8,  9, 11])\n","Step: 8589, Train Loss: 101.83181762695312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  3,  4,  7, 10, 11, 12])\n","Step: 8590, Train Loss: 109.197265625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 10, 11, 12]), tensor([ 2,  4, 10, 12])\n","Step: 8591, Train Loss: 95.7796859741211\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  6,  8, 10, 12])\n","Step: 8592, Train Loss: 97.1606674194336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11])\n","Step: 8593, Train Loss: 104.09453582763672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 12]), tensor([0, 1, 2, 4, 6, 8])\n","Step: 8594, Train Loss: 87.4341049194336\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  4,  5,  8, 10, 12])\n","Step: 8595, Train Loss: 108.022216796875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12])\n","Step: 8596, Train Loss: 102.89112854003906\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 8597, Train Loss: 96.08708190917969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8598, Train Loss: 100.11254119873047\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8599, Train Loss: 107.95460510253906\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8600, Train Loss: 104.42122650146484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  3,  4,  7, 10, 11, 12])\n","Step: 8601, Train Loss: 100.994384765625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  5,  7, 10, 11, 12])\n","Step: 8602, Train Loss: 97.49819946289062\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 10, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8603, Train Loss: 100.41636657714844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([10, 11, 12])\n","Step: 8604, Train Loss: 99.27428436279297\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  9, 11])\n","Step: 8605, Train Loss: 95.96760559082031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8606, Train Loss: 107.43621826171875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8607, Train Loss: 107.55322265625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8608, Train Loss: 101.51653289794922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 8609, Train Loss: 87.60447692871094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8610, Train Loss: 90.03460693359375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8611, Train Loss: 96.68848419189453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8612, Train Loss: 103.74475860595703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12])\n","Step: 8613, Train Loss: 104.62898254394531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8614, Train Loss: 95.25283813476562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8615, Train Loss: 113.53922271728516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8616, Train Loss: 96.26516723632812\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 4,  5,  9, 10, 12]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8617, Train Loss: 98.98811340332031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 8618, Train Loss: 95.53964233398438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 1,  2,  4,  5, 10, 12])\n","Step: 8619, Train Loss: 104.31775665283203\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 5, 10, 12])\n","Step: 8620, Train Loss: 101.68428039550781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([10, 12]), tensor([ 4,  5, 10])\n","Step: 8621, Train Loss: 101.41119384765625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8622, Train Loss: 108.42024993896484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  4,  5, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8623, Train Loss: 106.36579132080078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2, 10, 11]), tensor([ 0,  2,  4,  5, 10, 11])\n","Step: 8624, Train Loss: 100.36105346679688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 2,  4, 10, 12])\n","Step: 8625, Train Loss: 114.78491973876953\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 8626, Train Loss: 110.63854217529297\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8627, Train Loss: 111.53363800048828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8628, Train Loss: 98.82804107666016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8629, Train Loss: 96.22122955322266\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 8630, Train Loss: 94.88021850585938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 4,  5, 10, 12])\n","Step: 8631, Train Loss: 101.43975067138672\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  4,  5, 10, 12]), tensor([ 0,  3,  4,  5, 10, 11, 12])\n","Step: 8632, Train Loss: 107.71006774902344\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 4,  5, 10])\n","Step: 8633, Train Loss: 99.3592529296875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8634, Train Loss: 99.68829345703125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  8,  9, 10, 11, 12])\n","Step: 8635, Train Loss: 100.3471450805664\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 4, 10])\n","Step: 8636, Train Loss: 91.5029525756836\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12]), tensor([ 0,  1,  3,  4,  7,  8, 10, 12])\n","Step: 8637, Train Loss: 98.39208984375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8638, Train Loss: 106.66614532470703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8639, Train Loss: 107.47637176513672\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 2,  4,  5, 12])\n","Step: 8640, Train Loss: 104.70097351074219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2, 11, 12])\n","Step: 8641, Train Loss: 96.42459106445312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11])\n","Step: 8642, Train Loss: 97.56787109375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 11]), tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11])\n","Step: 8643, Train Loss: 112.04802703857422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8644, Train Loss: 113.82904815673828\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8645, Train Loss: 113.80696868896484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 3,  4,  5,  9, 10, 11, 12])\n","Step: 8646, Train Loss: 104.41192626953125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8647, Train Loss: 106.19178009033203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8648, Train Loss: 103.74634552001953\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8649, Train Loss: 100.94285583496094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8650, Train Loss: 100.93511199951172\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([4, 5]), tensor([ 2,  5,  8, 10])\n","Step: 8651, Train Loss: 88.18290710449219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  5, 10])\n","Step: 8652, Train Loss: 92.53892517089844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8653, Train Loss: 109.14364624023438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 11]), tensor([ 0,  1,  2,  3,  5,  7,  8, 11])\n","Step: 8654, Train Loss: 99.59547424316406\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  5, 10, 12]), tensor([ 0,  3,  4,  7, 10, 11, 12])\n","Step: 8655, Train Loss: 99.9480209350586\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8656, Train Loss: 102.45864868164062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  5,  7, 10, 11, 12]), tensor([ 3,  5,  7, 10, 11, 12])\n","Step: 8657, Train Loss: 94.68452453613281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8658, Train Loss: 98.49198150634766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  6,  7, 10, 11, 12])\n","Step: 8659, Train Loss: 101.9667739868164\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8660, Train Loss: 102.27223205566406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  8,  9, 10, 11]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 8661, Train Loss: 105.16812133789062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 11, 12])\n","Step: 8662, Train Loss: 96.20724487304688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8663, Train Loss: 106.27902221679688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  3,  5,  7, 10, 11, 12]), tensor([ 0,  3,  7, 10, 11, 12])\n","Step: 8664, Train Loss: 101.61174011230469\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 12]), tensor([ 3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8665, Train Loss: 109.08495330810547\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 8666, Train Loss: 93.8107681274414\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 2, 10, 11, 12])\n","Step: 8667, Train Loss: 104.01132202148438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 12]), tensor([ 0,  1,  4,  5,  8, 10, 12])\n","Step: 8668, Train Loss: 103.29779815673828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7,  9, 10, 11]), tensor([ 2,  3,  4,  7, 10, 11])\n","Step: 8669, Train Loss: 107.99749755859375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8670, Train Loss: 104.75228118896484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8671, Train Loss: 102.0481948852539\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 10, 11]), tensor([ 5,  8, 10, 11])\n","Step: 8672, Train Loss: 100.04410552978516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 10]), tensor([ 0,  2,  4,  6, 12])\n","Step: 8673, Train Loss: 102.56694793701172\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 1,  2,  4,  5, 10, 11, 12])\n","Step: 8674, Train Loss: 97.96578216552734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([4, 5]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11])\n","Step: 8675, Train Loss: 117.0636215209961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  3,  5,  7, 10, 11, 12])\n","Step: 8676, Train Loss: 112.33717346191406\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 8677, Train Loss: 106.28404998779297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 10, 11]), tensor([ 2,  5, 10])\n","Step: 8678, Train Loss: 103.7637710571289\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 8679, Train Loss: 98.75200653076172\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10, 11])\n","Step: 8680, Train Loss: 106.35476684570312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8681, Train Loss: 100.447509765625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 2,  5, 10, 12])\n","Step: 8682, Train Loss: 102.00950622558594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8683, Train Loss: 101.95156860351562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8684, Train Loss: 101.22527313232422\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 11, 12]), tensor([ 2,  4,  5,  8, 10])\n","Step: 8685, Train Loss: 100.56346893310547\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8686, Train Loss: 101.65544128417969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 2,  4, 10, 11, 12])\n","Step: 8687, Train Loss: 107.40544128417969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  8, 11, 12]), tensor([2, 4])\n","Step: 8688, Train Loss: 97.09187316894531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11]), tensor([ 2,  3,  4,  7,  9, 10, 11])\n","Step: 8689, Train Loss: 107.33280944824219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8690, Train Loss: 95.23374938964844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8691, Train Loss: 100.88374328613281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  5, 10, 12])\n","Step: 8692, Train Loss: 98.36894226074219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 4,  5, 10, 11, 12])\n","Step: 8693, Train Loss: 107.772216796875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8694, Train Loss: 110.99372100830078\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([10])\n","Step: 8695, Train Loss: 98.6673355102539\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8696, Train Loss: 104.34654235839844\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8697, Train Loss: 101.97528839111328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12])\n","Step: 8698, Train Loss: 100.57865905761719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12])\n","Step: 8699, Train Loss: 105.49229431152344\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 11, 12])\n","Step: 8700, Train Loss: 105.9162826538086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7,  8, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8701, Train Loss: 101.423583984375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 8702, Train Loss: 102.82451629638672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  5,  7, 10, 11, 12])\n","Step: 8703, Train Loss: 96.23658752441406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  6, 10, 11]), tensor([ 2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 8704, Train Loss: 106.94268798828125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8705, Train Loss: 102.57482147216797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 1,  2,  4,  5,  8, 10, 11, 12])\n","Step: 8706, Train Loss: 97.04620361328125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8707, Train Loss: 96.9596939086914\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  5, 10, 11, 12]), tensor([ 2,  3,  5, 10, 11, 12])\n","Step: 8708, Train Loss: 93.80455017089844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  8, 10, 11, 12])\n","Step: 8709, Train Loss: 97.02582550048828\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 3,  7, 11, 12])\n","Step: 8710, Train Loss: 104.55326080322266\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8711, Train Loss: 111.15020751953125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 3,  4,  5,  7,  9, 10, 11])\n","Step: 8712, Train Loss: 105.41146087646484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  9, 10, 12]), tensor([ 0,  1,  2,  4,  8, 10, 12])\n","Step: 8713, Train Loss: 110.68382263183594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8714, Train Loss: 107.96826171875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8715, Train Loss: 116.1399917602539\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 8716, Train Loss: 113.88638305664062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2, 10, 11]), tensor([ 0,  1,  2,  3,  7, 10, 11, 12])\n","Step: 8717, Train Loss: 107.73794555664062\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  5, 10, 11, 12])\n","Step: 8718, Train Loss: 98.48825073242188\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12])\n","Step: 8719, Train Loss: 97.95439147949219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  5,  7, 10, 11, 12])\n","Step: 8720, Train Loss: 100.77532196044922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6, 10, 11, 12])\n","Step: 8721, Train Loss: 97.87387084960938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 8722, Train Loss: 101.9595718383789\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 1,  2, 10, 12]), tensor([ 2,  5, 10])\n","Step: 8723, Train Loss: 109.6835708618164\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  4,  8,  9, 12])\n","Step: 8724, Train Loss: 104.34977722167969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 10, 11, 12]), tensor([ 3,  7, 10, 11, 12])\n","Step: 8725, Train Loss: 108.6594009399414\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([10, 12]), tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 12])\n","Step: 8726, Train Loss: 102.09027862548828\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 11, 12]), tensor([ 2,  4,  5,  8, 10])\n","Step: 8727, Train Loss: 100.63832092285156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 8728, Train Loss: 109.20501708984375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11]), tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 11, 12])\n","Step: 8729, Train Loss: 103.8378677368164\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8730, Train Loss: 105.4992446899414\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n","Step: 8731, Train Loss: 107.0498046875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  5,  7,  8, 10, 11, 12])\n","Step: 8732, Train Loss: 110.10518646240234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 12])\n","Step: 8733, Train Loss: 112.40409851074219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 1,  3,  4,  7, 10, 11, 12])\n","Step: 8734, Train Loss: 102.7052993774414\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  6,  7,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8735, Train Loss: 111.38046264648438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8736, Train Loss: 106.97453308105469\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  3,  7, 10, 11, 12])\n","Step: 8737, Train Loss: 107.73748779296875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8738, Train Loss: 98.49482727050781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  6, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8739, Train Loss: 98.63899230957031\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 5, 10, 12])\n","Step: 8740, Train Loss: 89.17591857910156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 2,  3,  5,  7, 10, 11, 12])\n","Step: 8741, Train Loss: 105.02066040039062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  7, 11]), tensor([ 2,  3,  7, 10, 11, 12])\n","Step: 8742, Train Loss: 106.40568542480469\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7,  9, 11]), tensor([ 3,  7, 11, 12])\n","Step: 8743, Train Loss: 117.73546600341797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5, 11]), tensor([2, 4, 5])\n","Step: 8744, Train Loss: 108.40521240234375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5, 10, 11]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8745, Train Loss: 111.43976593017578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 8746, Train Loss: 106.07688903808594\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 5, 10])\n","Step: 8747, Train Loss: 101.85330200195312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 8748, Train Loss: 94.5728530883789\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8749, Train Loss: 102.16694641113281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  7, 10, 11, 12]), tensor([ 4, 10, 12])\n","Step: 8750, Train Loss: 95.81062316894531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 5, 10, 12])\n","Step: 8751, Train Loss: 105.1353759765625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2, 10, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8752, Train Loss: 117.5141830444336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n","Step: 8753, Train Loss: 115.23346710205078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8754, Train Loss: 103.36491394042969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10]), tensor([0, 1, 2, 3, 4, 7])\n","Step: 8755, Train Loss: 103.37577819824219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10]), tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11])\n","Step: 8756, Train Loss: 108.9849853515625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  1,  3,  4,  7, 11])\n","Step: 8757, Train Loss: 104.07832336425781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  5, 10])\n","Step: 8758, Train Loss: 106.45989990234375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8759, Train Loss: 104.44441986083984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8760, Train Loss: 118.34947967529297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8761, Train Loss: 105.85562133789062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8762, Train Loss: 108.1835708618164\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8763, Train Loss: 105.09494018554688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8764, Train Loss: 102.51158905029297\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8765, Train Loss: 88.93767547607422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8766, Train Loss: 101.28797912597656\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 4,  5, 10])\n","Step: 8767, Train Loss: 92.54730224609375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 5, 10, 12])\n","Step: 8768, Train Loss: 95.78401947021484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11]), tensor([ 2,  3,  7, 11])\n","Step: 8769, Train Loss: 98.64555358886719\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 11])\n","Step: 8770, Train Loss: 110.7788314819336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 11, 12]), tensor([ 2,  4,  5,  9, 10, 12])\n","Step: 8771, Train Loss: 102.8800048828125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  7,  9, 10, 11, 12])\n","Step: 8772, Train Loss: 107.2149887084961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  6,  8, 10, 11, 12]), tensor([ 0,  1,  2,  4,  6,  8, 10, 12])\n","Step: 8773, Train Loss: 87.10650634765625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  7, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 8774, Train Loss: 121.4165267944336\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  7, 11, 12]), tensor([ 2, 11, 12])\n","Step: 8775, Train Loss: 102.59664154052734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8776, Train Loss: 108.06249237060547\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8777, Train Loss: 104.46533966064453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([2, 4, 5]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 11])\n","Step: 8778, Train Loss: 104.08509826660156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  6,  7, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8779, Train Loss: 104.24805450439453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  3, 11]), tensor([ 2,  4, 10])\n","Step: 8780, Train Loss: 97.53007507324219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8781, Train Loss: 101.23163604736328\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8782, Train Loss: 103.750732421875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  2,  4,  5,  6,  8, 10, 11, 12])\n","Step: 8783, Train Loss: 99.3598861694336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8784, Train Loss: 104.73500061035156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 1,  2, 10]), tensor([1, 2])\n","Step: 8785, Train Loss: 102.61951446533203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2, 11]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8786, Train Loss: 99.73648071289062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8787, Train Loss: 104.79401397705078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8788, Train Loss: 98.17092895507812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  3,  5,  7, 10, 11])\n","Step: 8789, Train Loss: 107.3428955078125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 11, 12]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8790, Train Loss: 107.53247833251953\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  9, 10]), tensor([ 2,  4,  5, 10, 11, 12])\n","Step: 8791, Train Loss: 97.72499084472656\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2, 12])\n","Step: 8792, Train Loss: 107.3382568359375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2, 10, 12]), tensor([ 2,  5, 10, 12])\n","Step: 8793, Train Loss: 109.16352844238281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7,  8,  9, 10, 11, 12])\n","Step: 8794, Train Loss: 105.27542114257812\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11])\n","Step: 8795, Train Loss: 102.35163879394531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  6,  7,  8,  9, 12])\n","Step: 8796, Train Loss: 97.40009307861328\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([0, 2, 3, 6, 7, 9]), tensor([0, 2, 4, 9])\n","Step: 8797, Train Loss: 96.1483154296875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12])\n","Step: 8798, Train Loss: 106.3650894165039\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8799, Train Loss: 109.27372741699219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8800, Train Loss: 110.25798797607422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8801, Train Loss: 95.69485473632812\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 8802, Train Loss: 97.61621856689453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11])\n","Step: 8803, Train Loss: 91.8037338256836\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  8, 11, 12])\n","Step: 8804, Train Loss: 106.2291259765625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8805, Train Loss: 103.87760162353516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8806, Train Loss: 114.1662368774414\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8807, Train Loss: 109.7027816772461\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  9, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 8808, Train Loss: 105.82157135009766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 4, 10, 12])\n","Step: 8809, Train Loss: 109.54457092285156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4, 10, 11, 12])\n","Step: 8810, Train Loss: 102.85726928710938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8811, Train Loss: 100.19868469238281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 12])\n","Step: 8812, Train Loss: 95.57320404052734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 3,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8813, Train Loss: 108.68738555908203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  5,  7, 10, 11, 12]), tensor([ 2,  5, 10, 12])\n","Step: 8814, Train Loss: 100.05249786376953\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 8815, Train Loss: 108.38525390625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  2,  3,  5,  7,  8, 10, 11, 12])\n","Step: 8816, Train Loss: 118.65962219238281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  5,  7,  8, 10, 11, 12])\n","Step: 8817, Train Loss: 108.63690185546875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 8818, Train Loss: 104.11709594726562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8819, Train Loss: 103.03388977050781\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8820, Train Loss: 101.12493133544922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8821, Train Loss: 107.23934936523438\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  5, 10, 11, 12])\n","Step: 8822, Train Loss: 100.5788345336914\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8823, Train Loss: 104.45873260498047\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 2,  5, 10, 12])\n","Step: 8824, Train Loss: 85.955810546875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([0, 1, 3, 7]), tensor([0, 3, 7])\n","Step: 8825, Train Loss: 114.12025451660156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([0, 1, 2, 3, 4, 6, 7, 8]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8826, Train Loss: 103.31934356689453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5, 10, 11, 12])\n","Step: 8827, Train Loss: 105.66736602783203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  2,  5,  9, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8828, Train Loss: 103.58905792236328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 1,  2,  4,  8, 12])\n","Step: 8829, Train Loss: 110.47728729248047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8830, Train Loss: 101.98884582519531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7,  9, 10, 11]), tensor([ 2,  4,  5,  8, 10])\n","Step: 8831, Train Loss: 102.19097900390625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8832, Train Loss: 111.20817565917969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8833, Train Loss: 109.041259765625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 12]), tensor([ 2,  4,  5,  8, 10, 12])\n","Step: 8834, Train Loss: 99.82499694824219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  4,  5,  8, 10, 12])\n","Step: 8835, Train Loss: 112.01533508300781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 8836, Train Loss: 102.56050872802734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8837, Train Loss: 110.24174499511719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8838, Train Loss: 108.21835327148438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  8, 10, 12])\n","Step: 8839, Train Loss: 102.97119140625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8840, Train Loss: 105.23834991455078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8841, Train Loss: 102.05230712890625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8842, Train Loss: 106.64921569824219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 3,  5,  7,  9, 10, 11]), tensor([ 1,  2,  3,  5,  7,  9, 10, 11, 12])\n","Step: 8843, Train Loss: 100.69636535644531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8844, Train Loss: 100.70531463623047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  4, 10, 11, 12]), tensor([ 2,  3,  7, 10, 11, 12])\n","Step: 8845, Train Loss: 113.28097534179688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  5, 10, 11, 12]), tensor([ 1,  2,  4,  5, 10, 11, 12])\n","Step: 8846, Train Loss: 106.7440185546875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8847, Train Loss: 105.41087341308594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10]), tensor([2, 4, 5])\n","Step: 8848, Train Loss: 94.09894561767578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  7, 10, 11, 12]), tensor([ 0,  1, 10, 11, 12])\n","Step: 8849, Train Loss: 93.805908203125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8850, Train Loss: 107.12539672851562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([10, 12]), tensor([ 2,  4,  5,  9, 10])\n","Step: 8851, Train Loss: 107.87466430664062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11])\n","Step: 8852, Train Loss: 106.52711486816406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7, 12])\n","Step: 8853, Train Loss: 111.86723327636719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  5,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  5,  7,  8, 10, 11])\n","Step: 8854, Train Loss: 107.44355773925781\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4, 10])\n","Step: 8855, Train Loss: 108.79011535644531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12])\n","Step: 8856, Train Loss: 109.41616821289062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  3,  4,  6,  7, 11, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 8857, Train Loss: 102.68203735351562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  6,  8, 10, 12]), tensor([2, 4, 5, 8])\n","Step: 8858, Train Loss: 93.72057342529297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2,  9, 10, 11, 12]), tensor([ 1,  2,  9, 10, 11, 12])\n","Step: 8859, Train Loss: 104.70245361328125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  4, 10, 12]), tensor([ 1,  2,  5,  8, 10, 11, 12])\n","Step: 8860, Train Loss: 103.83639526367188\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  4,  5, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11])\n","Step: 8861, Train Loss: 104.076904296875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8862, Train Loss: 99.62667083740234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8863, Train Loss: 105.40838623046875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11, 12]), tensor([ 0,  1,  3,  4,  7, 10, 11, 12])\n","Step: 8864, Train Loss: 102.97689056396484\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 12])\n","Step: 8865, Train Loss: 115.40316772460938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 11]), tensor([ 1,  2,  4, 10, 12])\n","Step: 8866, Train Loss: 101.45426177978516\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8867, Train Loss: 110.98760986328125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 1,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 8868, Train Loss: 101.4565658569336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8869, Train Loss: 102.56963348388672\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  4,  5, 10, 11, 12])\n","Step: 8870, Train Loss: 110.44434356689453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5, 10, 11])\n","Step: 8871, Train Loss: 104.9200210571289\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8872, Train Loss: 106.1959228515625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 11, 12]), tensor([ 2, 11, 12])\n","Step: 8873, Train Loss: 109.43034362792969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 4, 10, 12]), tensor([10, 12])\n","Step: 8874, Train Loss: 79.79254913330078\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8875, Train Loss: 105.48371887207031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8876, Train Loss: 105.81648254394531\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 8877, Train Loss: 105.9588394165039\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  7,  8, 10, 11, 12])\n","Step: 8878, Train Loss: 111.40076446533203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 2,  3,  7, 10, 11, 12])\n","Step: 8879, Train Loss: 80.01998138427734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 11]), tensor([ 2,  3,  4,  7,  9, 11, 12])\n","Step: 8880, Train Loss: 108.61334228515625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 3,  7, 11])\n","Step: 8881, Train Loss: 105.62251281738281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8882, Train Loss: 102.31483459472656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8883, Train Loss: 106.96800231933594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11]), tensor([ 1,  2,  4, 10])\n","Step: 8884, Train Loss: 104.83289337158203\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6,  9, 10, 11, 12])\n","Step: 8885, Train Loss: 94.50840759277344\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11])\n","Step: 8886, Train Loss: 100.88128662109375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 8887, Train Loss: 108.29620361328125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 3,  4,  5,  7, 10, 11])\n","Step: 8888, Train Loss: 94.6479263305664\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 4,  8,  9, 10, 11]), tensor([ 5,  8,  9, 10])\n","Step: 8889, Train Loss: 86.61349487304688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10]), tensor([ 0,  1,  2,  3,  7,  8,  9, 10])\n","Step: 8890, Train Loss: 106.25495147705078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([0, 2, 3, 7, 8, 9]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12])\n","Step: 8891, Train Loss: 104.0671615600586\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12])\n","Step: 8892, Train Loss: 110.16681671142578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  9, 11, 12]), tensor([ 1,  2,  4,  6, 10, 11, 12])\n","Step: 8893, Train Loss: 103.41629791259766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  6, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 8894, Train Loss: 104.8488540649414\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 4, 10])\n","Step: 8895, Train Loss: 117.07312774658203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 4, 10, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8896, Train Loss: 102.90365600585938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([ 2, 10, 11, 12]), tensor([2])\n","Step: 8897, Train Loss: 96.1261978149414\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([0, 1, 2, 3, 4, 6, 7]), tensor([0, 1, 2, 3, 6, 7, 8])\n","Step: 8898, Train Loss: 94.02098083496094\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8899, Train Loss: 105.9303970336914\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8900, Train Loss: 104.82793426513672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 8901, Train Loss: 106.57636260986328\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 4,  5, 10, 11])\n","Step: 8902, Train Loss: 118.1936264038086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  7, 10, 11])\n","Step: 8903, Train Loss: 105.72161102294922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7,  9, 10, 11]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8904, Train Loss: 109.48004913330078\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8,  9, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12])\n","Step: 8905, Train Loss: 101.07963562011719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8906, Train Loss: 94.95125579833984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  3,  5,  9, 11, 12]), tensor([ 5,  9, 10])\n","Step: 8907, Train Loss: 105.13037872314453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8908, Train Loss: 107.9075927734375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 4, 10])\n","Step: 8909, Train Loss: 98.90194702148438\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 8910, Train Loss: 107.08430480957031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 8911, Train Loss: 94.7610092163086\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8912, Train Loss: 104.89237976074219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  7, 10, 11, 12])\n","Step: 8913, Train Loss: 99.73733520507812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 2,  4,  5,  8, 10])\n","Step: 8914, Train Loss: 104.4332504272461\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8915, Train Loss: 105.81040954589844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8916, Train Loss: 103.07134246826172\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8917, Train Loss: 107.82386779785156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  7,  8, 12]), tensor([ 0,  1,  4, 10, 12])\n","Step: 8918, Train Loss: 100.82486724853516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8919, Train Loss: 105.43634033203125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8920, Train Loss: 106.66522979736328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11]), tensor([ 0,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8921, Train Loss: 106.27621459960938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 8922, Train Loss: 111.82012939453125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  4,  5,  8, 10, 11, 12])\n","Step: 8923, Train Loss: 107.43501281738281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8924, Train Loss: 101.91619110107422\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8925, Train Loss: 111.56669616699219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 11, 12]), tensor([ 3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8926, Train Loss: 102.04756164550781\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 5, 10, 11, 12]), tensor([ 2,  5, 10])\n","Step: 8927, Train Loss: 93.63864135742188\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4, 10, 11, 12])\n","Step: 8928, Train Loss: 107.68997192382812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10]), tensor([ 1,  2, 12])\n","Step: 8929, Train Loss: 103.36498260498047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8930, Train Loss: 106.64835357666016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8931, Train Loss: 105.47432708740234\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 8932, Train Loss: 105.6999740600586\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8933, Train Loss: 106.97999572753906\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8934, Train Loss: 104.30045318603516\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8935, Train Loss: 102.2433853149414\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  9, 10, 11, 12]), tensor([ 3,  4,  5,  7, 11, 12])\n","Step: 8936, Train Loss: 103.88211822509766\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8937, Train Loss: 109.22686004638672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  6,  7, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 12])\n","Step: 8938, Train Loss: 103.85548400878906\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 8939, Train Loss: 108.45877075195312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8940, Train Loss: 106.24742889404297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 1,  2,  4,  5,  9, 10])\n","Step: 8941, Train Loss: 103.7646484375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  9, 11]), tensor([ 1,  2,  4,  5,  9, 10, 11])\n","Step: 8942, Train Loss: 104.15724182128906\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 4, 10, 11, 12])\n","Step: 8943, Train Loss: 106.84285736083984\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  4,  5, 10, 12])\n","Step: 8944, Train Loss: 104.86933135986328\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10]), tensor([ 1,  2,  4,  5, 10, 11, 12])\n","Step: 8945, Train Loss: 99.1931381225586\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 8946, Train Loss: 111.70606231689453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 3,  5,  7, 10, 11]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8947, Train Loss: 114.4549560546875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  9, 10]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8948, Train Loss: 103.28678131103516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2, 10, 12])\n","Step: 8949, Train Loss: 114.75381469726562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8950, Train Loss: 102.51014709472656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12])\n","Step: 8951, Train Loss: 106.03658294677734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([0, 1, 2, 4]), tensor([ 0,  1,  3,  7, 11])\n","Step: 8952, Train Loss: 107.59779357910156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8953, Train Loss: 107.47607421875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12])\n","Step: 8954, Train Loss: 111.92279815673828\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 8955, Train Loss: 105.14881134033203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 11, 12])\n","Step: 8956, Train Loss: 109.63644409179688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8957, Train Loss: 100.2364730834961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8958, Train Loss: 106.80651092529297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12]), tensor([ 1,  2,  4,  6, 10, 11])\n","Step: 8959, Train Loss: 99.0749740600586\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8960, Train Loss: 108.28277587890625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8961, Train Loss: 114.13490295410156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8962, Train Loss: 105.91227722167969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8963, Train Loss: 103.6760482788086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8964, Train Loss: 109.1407699584961\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 4, 10, 12])\n","Step: 8965, Train Loss: 100.49308013916016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 4, 10]), tensor([ 0,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8966, Train Loss: 93.28333282470703\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11, 12]), tensor([ 1,  2,  4,  5,  6, 10, 11, 12])\n","Step: 8967, Train Loss: 105.82071685791016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 8968, Train Loss: 103.90669250488281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 8969, Train Loss: 106.0882339477539\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0, 10, 12])\n","Step: 8970, Train Loss: 112.29408264160156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  4,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11])\n","Step: 8971, Train Loss: 97.04237365722656\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  3,  4,  5,  7, 10, 11])\n","Step: 8972, Train Loss: 106.3714370727539\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11]), tensor([ 0,  1,  2,  3,  7, 11])\n","Step: 8973, Train Loss: 100.50804138183594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([1, 2, 5, 6, 9]), tensor([1, 2, 6, 9])\n","Step: 8974, Train Loss: 115.14894104003906\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  4,  9, 10, 11]), tensor([ 2,  4,  5,  9, 10, 11])\n","Step: 8975, Train Loss: 93.78424835205078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8976, Train Loss: 111.83952331542969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8977, Train Loss: 103.44122314453125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8978, Train Loss: 113.36713409423828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  5,  7, 10, 11, 12])\n","Step: 8979, Train Loss: 106.9105453491211\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8980, Train Loss: 95.2374496459961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8981, Train Loss: 96.33089447021484\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  4, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5, 10, 12])\n","Step: 8982, Train Loss: 108.53699493408203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4, 12]), tensor([ 2,  4,  5, 10])\n","Step: 8983, Train Loss: 108.85674285888672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 8984, Train Loss: 105.54192352294922\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 8985, Train Loss: 106.75615692138672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 0,  1,  2,  4,  5,  8, 10])\n","Step: 8986, Train Loss: 98.58164978027344\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  4,  5, 10])\n","Step: 8987, Train Loss: 102.06349182128906\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2, 10, 11, 12]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 8988, Train Loss: 108.87045288085938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4, 10, 11, 12])\n","Step: 8989, Train Loss: 103.49244689941406\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([4, 5]), tensor([4, 5])\n","Step: 8990, Train Loss: 82.44815063476562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 8991, Train Loss: 98.7498779296875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8992, Train Loss: 108.7850112915039\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 4, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8993, Train Loss: 103.19680786132812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8994, Train Loss: 108.20941925048828\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 8995, Train Loss: 100.33455657958984\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([13, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n","Step: 8996, Train Loss: 104.08279418945312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 8997, Train Loss: 109.60869598388672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  6,  7,  9, 11, 12])\n","Step: 8998, Train Loss: 106.88994598388672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 8999, Train Loss: 117.37870788574219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  4,  5, 10, 11])\n","Step: 9000, Train Loss: 109.34722137451172\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 2,  3,  4,  7, 10, 11])\n","Step: 9001, Train Loss: 109.22979736328125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 9002, Train Loss: 110.16077423095703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9003, Train Loss: 100.79731750488281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9004, Train Loss: 104.30058288574219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 9005, Train Loss: 99.43465423583984\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([10]), tensor([0, 1, 2, 4, 6, 8])\n","Step: 9006, Train Loss: 71.52010345458984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([0, 3, 7]), tensor([ 0,  1,  4,  6,  8, 12])\n","Step: 9007, Train Loss: 103.93705749511719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9008, Train Loss: 112.27279663085938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 10, 11]), tensor([ 1,  2,  3,  7, 10, 11])\n","Step: 9009, Train Loss: 97.90038299560547\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  3,  4,  5, 10, 11])\n","Step: 9010, Train Loss: 101.4931869506836\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 11, 12]), tensor([ 1,  2,  3,  5,  7, 10, 11, 12])\n","Step: 9011, Train Loss: 108.48348236083984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9012, Train Loss: 100.7998046875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9013, Train Loss: 98.90433502197266\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 12]), tensor([ 0,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9014, Train Loss: 93.50346374511719\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9015, Train Loss: 113.02593994140625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 0,  3,  4,  7, 10, 11, 12])\n","Step: 9016, Train Loss: 112.206787109375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  4,  5, 10, 11, 12]), tensor([ 0,  3,  4,  7, 10, 11, 12])\n","Step: 9017, Train Loss: 102.5242919921875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10]), tensor([0, 1, 2, 4, 6, 8, 9])\n","Step: 9018, Train Loss: 101.61344909667969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  2,  5, 10, 12])\n","Step: 9019, Train Loss: 103.70601654052734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 12])\n","Step: 9020, Train Loss: 98.51335906982422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10]), tensor([ 2, 10, 11, 12])\n","Step: 9021, Train Loss: 106.24234008789062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  7, 10, 11, 12])\n","Step: 9022, Train Loss: 109.55534362792969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n","Step: 9023, Train Loss: 101.65798950195312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9024, Train Loss: 106.6974105834961\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  4,  5, 10, 11, 12]), tensor([ 2,  4,  5, 10, 11, 12])\n","Step: 9025, Train Loss: 106.49491119384766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 11, 12])\n","Step: 9026, Train Loss: 98.6358642578125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5,  8, 10]), tensor([ 0,  1,  2,  3,  4,  5,  8, 10, 11, 12])\n","Step: 9027, Train Loss: 97.75176239013672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  3,  5,  7, 10, 11, 12]), tensor([ 3,  7, 10, 11, 12])\n","Step: 9028, Train Loss: 92.34984588623047\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 12]), tensor([ 0,  1,  2,  4,  8, 10, 12])\n","Step: 9029, Train Loss: 102.89812469482422\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  5,  7, 10, 11, 12]), tensor([ 2,  5, 10, 12])\n","Step: 9030, Train Loss: 106.93486785888672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9031, Train Loss: 108.71404266357422\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9032, Train Loss: 110.9442367553711\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  7, 10, 11, 12])\n","Step: 9033, Train Loss: 107.99134063720703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 11, 12]), tensor([ 1,  2,  4, 10, 12])\n","Step: 9034, Train Loss: 96.2708969116211\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7,  9, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9035, Train Loss: 111.05751037597656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 1,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9036, Train Loss: 96.43087768554688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 5, 10, 11, 12]), tensor([ 1,  4,  5, 10, 11, 12])\n","Step: 9037, Train Loss: 99.75267791748047\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10]), tensor([1, 2, 4, 6])\n","Step: 9038, Train Loss: 97.95805358886719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4, 10, 11, 12])\n","Step: 9039, Train Loss: 91.02481079101562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([10, 12])\n","Step: 9040, Train Loss: 86.22927856445312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12])\n","Step: 9041, Train Loss: 96.08016204833984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10, 12]), tensor([ 0,  2,  4,  5,  6,  8,  9, 10, 12])\n","Step: 9042, Train Loss: 97.65364074707031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([10, 12]), tensor([ 3,  7, 10, 11, 12])\n","Step: 9043, Train Loss: 106.52649688720703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 4, 10]), tensor([ 2,  4, 10])\n","Step: 9044, Train Loss: 82.37921142578125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11, 12]), tensor([ 0,  3,  7, 10, 11, 12])\n","Step: 9045, Train Loss: 103.7583999633789\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9046, Train Loss: 101.13799285888672\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7,  9, 11, 12])\n","Step: 9047, Train Loss: 107.93819427490234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9048, Train Loss: 100.71701049804688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9049, Train Loss: 105.02769470214844\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([2, 4, 5, 9]), tensor([0, 2, 3, 4, 7, 9])\n","Step: 9050, Train Loss: 117.99227905273438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([2, 4, 5, 9]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9051, Train Loss: 105.16439819335938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 9052, Train Loss: 108.88597106933594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9053, Train Loss: 99.79004669189453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  5,  7, 10, 11, 12]), tensor([ 2, 10])\n","Step: 9054, Train Loss: 105.22968292236328\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10])\n","Step: 9055, Train Loss: 95.00019073486328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9056, Train Loss: 110.43688201904297\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  4,  5,  9, 10])\n","Step: 9057, Train Loss: 97.5039291381836\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 9058, Train Loss: 108.70268249511719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11])\n","Step: 9059, Train Loss: 110.65202331542969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([2, 4, 6]), tensor([2])\n","Step: 9060, Train Loss: 76.19640350341797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([0, 1, 2, 3, 7]), tensor([ 0,  1,  2,  3,  4,  5,  8, 10, 11, 12])\n","Step: 9061, Train Loss: 94.28697204589844\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  4,  8, 10, 12])\n","Step: 9062, Train Loss: 104.13308715820312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11])\n","Step: 9063, Train Loss: 102.82398986816406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  7,  8, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12])\n","Step: 9064, Train Loss: 88.06132507324219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9065, Train Loss: 104.82594299316406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  9, 10, 11, 12]), tensor([ 0,  1,  2,  4,  8, 10, 12])\n","Step: 9066, Train Loss: 97.29739379882812\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 12])\n","Step: 9067, Train Loss: 105.55048370361328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 12]), tensor([ 0,  1,  2,  3,  5,  7,  8,  9, 10, 12])\n","Step: 9068, Train Loss: 111.79143524169922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 5, 10, 12]), tensor([ 0,  5, 10, 12])\n","Step: 9069, Train Loss: 94.02788543701172\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 9070, Train Loss: 99.43824005126953\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 12]), tensor([ 2,  4,  5,  8, 10, 11, 12])\n","Step: 9071, Train Loss: 96.65249633789062\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  4, 10, 11, 12])\n","Step: 9072, Train Loss: 108.55950927734375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9073, Train Loss: 101.60226440429688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([10]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 9074, Train Loss: 91.65096282958984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([2]), tensor([2])\n","Step: 9075, Train Loss: 62.97016143798828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 11]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9076, Train Loss: 103.47863006591797\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9077, Train Loss: 105.5823974609375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11])\n","Step: 9078, Train Loss: 111.84473419189453\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  3,  7, 10, 11, 12])\n","Step: 9079, Train Loss: 102.05628204345703\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  5,  7, 10, 11, 12]), tensor([ 0,  3,  4,  7, 10, 11, 12])\n","Step: 9080, Train Loss: 104.2012710571289\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([10]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9081, Train Loss: 106.33285522460938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9082, Train Loss: 99.66068267822266\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  6, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9083, Train Loss: 105.46959686279297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 4,  5, 10])\n","Step: 9084, Train Loss: 99.09845733642578\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  8,  9, 10, 11])\n","Step: 9085, Train Loss: 102.15250396728516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9086, Train Loss: 102.55400085449219\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11])\n","Step: 9087, Train Loss: 100.59963989257812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  6,  8, 10, 12]), tensor([ 0,  1,  2,  4,  6, 10, 12])\n","Step: 9088, Train Loss: 100.07302856445312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  5,  7, 10, 11, 12])\n","Step: 9089, Train Loss: 104.20381164550781\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5, 10, 12])\n","Step: 9090, Train Loss: 103.44206237792969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  4,  8, 10])\n","Step: 9091, Train Loss: 107.43689727783203\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9092, Train Loss: 105.70494079589844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  5,  7, 10, 11, 12]), tensor([ 2,  3,  7, 11, 12])\n","Step: 9093, Train Loss: 108.74576568603516\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 2,  4, 10, 12])\n","Step: 9094, Train Loss: 104.6825942993164\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11]), tensor([2])\n","Step: 9095, Train Loss: 105.36541748046875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 5, 10, 12])\n","Step: 9096, Train Loss: 108.72703552246094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 2,  4,  5,  9, 10, 12])\n","Step: 9097, Train Loss: 106.0889892578125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  9, 10]), tensor([ 2,  4,  5,  9, 10, 12])\n","Step: 9098, Train Loss: 99.24302673339844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([10, 11, 12]), tensor([ 4, 10, 11, 12])\n","Step: 9099, Train Loss: 102.41114044189453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9100, Train Loss: 97.85244750976562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9101, Train Loss: 98.40199279785156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  8, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9102, Train Loss: 102.86483764648438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11])\n","Step: 9103, Train Loss: 96.02316284179688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 12]), tensor([ 2,  4,  8, 10, 11, 12])\n","Step: 9104, Train Loss: 85.20402526855469\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([ 0,  3,  4,  7,  9, 10, 11, 12])\n","Step: 9105, Train Loss: 110.26260375976562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9106, Train Loss: 113.30702209472656\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  6,  7,  8, 10, 11, 12])\n","Step: 9107, Train Loss: 104.8311996459961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 11]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 9108, Train Loss: 98.90726470947266\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([1, 2, 6]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 11])\n","Step: 9109, Train Loss: 82.06319427490234\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 10]), tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12])\n","Step: 9110, Train Loss: 105.46639251708984\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9111, Train Loss: 105.62472534179688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5, 10, 12])\n","Step: 9112, Train Loss: 104.91273498535156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6, 10, 11, 12])\n","Step: 9113, Train Loss: 103.23114013671875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 1,  2,  4, 10, 11, 12])\n","Step: 9114, Train Loss: 107.90826416015625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12])\n","Step: 9115, Train Loss: 106.54069519042969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9116, Train Loss: 109.07041931152344\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4, 10]), tensor([ 0,  2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 9117, Train Loss: 107.4348373413086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9118, Train Loss: 103.33154296875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9119, Train Loss: 99.58747863769531\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 12])\n","Step: 9120, Train Loss: 94.4800033569336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 9121, Train Loss: 109.39937591552734\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 9122, Train Loss: 106.58436584472656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9123, Train Loss: 112.69700622558594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9124, Train Loss: 117.06973266601562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9125, Train Loss: 102.07955169677734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9126, Train Loss: 98.36068725585938\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9127, Train Loss: 112.19853973388672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 11])\n","Step: 9128, Train Loss: 105.4765396118164\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11])\n","Step: 9129, Train Loss: 106.08152770996094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11])\n","Step: 9130, Train Loss: 104.46879577636719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 9131, Train Loss: 107.6211166381836\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 9132, Train Loss: 109.34760284423828\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9133, Train Loss: 111.97635650634766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11]), tensor([ 5, 10, 12])\n","Step: 9134, Train Loss: 102.6825180053711\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12])\n","Step: 9135, Train Loss: 100.91541290283203\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12]), tensor([ 4,  5, 10, 11, 12])\n","Step: 9136, Train Loss: 101.65625762939453\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9137, Train Loss: 99.42561340332031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9138, Train Loss: 101.8266372680664\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11])\n","Step: 9139, Train Loss: 107.16731262207031\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 11]), tensor([2, 4, 5])\n","Step: 9140, Train Loss: 105.12680053710938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 9141, Train Loss: 102.85823822021484\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9142, Train Loss: 108.77654266357422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9143, Train Loss: 113.89768981933594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  5,  7, 10, 11, 12]), tensor([ 2, 10, 11])\n","Step: 9144, Train Loss: 97.34172821044922\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 5, 10])\n","Step: 9145, Train Loss: 100.70497131347656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 2,  4,  5, 10, 11, 12])\n","Step: 9146, Train Loss: 112.36902618408203\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9147, Train Loss: 104.87820434570312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4, 10, 11, 12])\n","Step: 9148, Train Loss: 97.57728576660156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  8, 10, 11, 12]), tensor([ 1,  2,  4,  5,  8, 10, 11, 12])\n","Step: 9149, Train Loss: 91.93102264404297\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  3,  7, 10, 11, 12]), tensor([ 2,  4, 10, 12])\n","Step: 9150, Train Loss: 100.52809143066406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 3,  7, 10, 11, 12]), tensor([ 1,  2,  4,  5,  8, 10, 11, 12])\n","Step: 9151, Train Loss: 114.23101806640625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  5,  8, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9152, Train Loss: 114.5899887084961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7, 10, 11]), tensor([ 0,  2,  3,  7, 10, 11])\n","Step: 9153, Train Loss: 105.14559936523438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 11])\n","Step: 9154, Train Loss: 104.38108825683594\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9155, Train Loss: 104.96066284179688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9156, Train Loss: 108.05015563964844\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9157, Train Loss: 105.53229522705078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 5,  9, 10]), tensor([ 5,  9, 10])\n","Step: 9158, Train Loss: 95.13124084472656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 1,  2,  4,  5,  6,  8, 10, 11, 12])\n","Step: 9159, Train Loss: 99.87107849121094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 9160, Train Loss: 100.92255401611328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 12])\n","Step: 9161, Train Loss: 94.1702651977539\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 12]), tensor([ 0,  1,  2,  4,  6,  8, 10])\n","Step: 9162, Train Loss: 96.02411651611328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 11]), tensor([ 1,  2,  4, 11])\n","Step: 9163, Train Loss: 110.41361236572266\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9164, Train Loss: 99.99372100830078\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11]), tensor([ 1,  2,  3,  4,  6,  7,  8, 10, 11, 12])\n","Step: 9165, Train Loss: 110.3421401977539\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11, 12])\n","Step: 9166, Train Loss: 101.56413269042969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 0,  1,  2,  5,  8, 10, 12])\n","Step: 9167, Train Loss: 100.18934631347656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9168, Train Loss: 103.69462585449219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9169, Train Loss: 106.46863555908203\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 1,  4, 10, 12]), tensor([ 5, 10])\n","Step: 9170, Train Loss: 81.70130157470703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 9171, Train Loss: 104.07867431640625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9172, Train Loss: 99.25460052490234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9173, Train Loss: 110.33863067626953\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9174, Train Loss: 99.46388244628906\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  4,  7, 10, 11]), tensor([ 4, 10, 11])\n","Step: 9175, Train Loss: 106.55538940429688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9176, Train Loss: 107.11460876464844\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10, 11])\n","Step: 9177, Train Loss: 92.13591003417969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9178, Train Loss: 105.30840301513672\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9179, Train Loss: 100.0360336303711\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  3,  4,  7, 10, 11, 12])\n","Step: 9180, Train Loss: 108.47230529785156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  3,  7, 12])\n","Step: 9181, Train Loss: 104.966552734375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  7, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 12])\n","Step: 9182, Train Loss: 107.05039978027344\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9183, Train Loss: 107.35012817382812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  6,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12])\n","Step: 9184, Train Loss: 100.4731216430664\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9185, Train Loss: 109.00850677490234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2, 10, 12])\n","Step: 9186, Train Loss: 118.1300048828125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 2,  5, 10, 12]), tensor([ 2, 10])\n","Step: 9187, Train Loss: 98.72481536865234\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9188, Train Loss: 96.80606079101562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  7, 10, 11]), tensor([ 1,  2,  3,  7, 11])\n","Step: 9189, Train Loss: 100.74508666992188\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 9190, Train Loss: 104.1869888305664\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9191, Train Loss: 99.64672088623047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9192, Train Loss: 106.57037353515625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  9, 11]), tensor([ 1,  2,  3,  4,  5,  7, 11])\n","Step: 9193, Train Loss: 105.3008041381836\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9194, Train Loss: 98.41729736328125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 4,  5,  8, 12]), tensor([ 0,  3,  7,  8, 11, 12])\n","Step: 9195, Train Loss: 106.93484497070312\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11])\n","Step: 9196, Train Loss: 106.4288558959961\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11]), tensor([ 0,  1,  2,  4,  5,  8, 10, 11, 12])\n","Step: 9197, Train Loss: 106.48052215576172\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 9, 10])\n","Step: 9198, Train Loss: 90.91648864746094\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9199, Train Loss: 105.67376708984375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9200, Train Loss: 103.5166015625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9201, Train Loss: 102.3163070678711\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  8,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  7,  8,  9, 10, 11, 12])\n","Step: 9202, Train Loss: 99.9227294921875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9203, Train Loss: 116.40569305419922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 3,  4,  7, 10, 11, 12]), tensor([ 5, 10, 11, 12])\n","Step: 9204, Train Loss: 106.45401763916016\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 4, 10]), tensor([ 3,  5,  7, 10, 11, 12])\n","Step: 9205, Train Loss: 112.77681732177734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9206, Train Loss: 109.86515045166016\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9207, Train Loss: 101.23095703125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 3,  7, 11, 12])\n","Step: 9208, Train Loss: 96.2919921875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12])\n","Step: 9209, Train Loss: 99.44837951660156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 11, 12]), tensor([ 1,  2,  3,  7, 10, 11, 12])\n","Step: 9210, Train Loss: 107.39196014404297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  7, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9211, Train Loss: 112.04630279541016\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9212, Train Loss: 98.16385650634766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  5,  7,  8, 10, 11])\n","Step: 9213, Train Loss: 109.97242736816406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9214, Train Loss: 106.14646911621094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 4,  5, 10, 12])\n","Step: 9215, Train Loss: 104.9739990234375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2,  4, 10, 11, 12])\n","Step: 9216, Train Loss: 106.2248306274414\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 3,  4, 10, 11]), tensor([ 0,  3,  5,  7, 10, 11])\n","Step: 9217, Train Loss: 98.6395492553711\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11])\n","Step: 9218, Train Loss: 109.6297836303711\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12])\n","Step: 9219, Train Loss: 103.83251190185547\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 4,  5, 10])\n","Step: 9220, Train Loss: 93.41246032714844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9221, Train Loss: 113.35687255859375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9222, Train Loss: 105.09344482421875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9223, Train Loss: 108.797607421875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  6, 10]), tensor([ 1,  2,  4,  5,  6, 10, 12])\n","Step: 9224, Train Loss: 85.8110580444336\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 1,  2,  4,  9, 10])\n","Step: 9225, Train Loss: 107.81396484375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([0, 1, 2, 3, 7, 8, 9])\n","Step: 9226, Train Loss: 107.75611877441406\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([0, 1, 2, 4]), tensor([0, 1, 2, 3, 7, 8, 9])\n","Step: 9227, Train Loss: 98.24781799316406\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9228, Train Loss: 103.63340759277344\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9229, Train Loss: 102.88164520263672\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  5,  6,  8, 10, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9230, Train Loss: 112.048095703125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  6,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 11])\n","Step: 9231, Train Loss: 109.49800109863281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 11]), tensor([2, 4])\n","Step: 9232, Train Loss: 88.07608795166016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 5, 10, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9233, Train Loss: 100.70663452148438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9234, Train Loss: 101.92520141601562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9235, Train Loss: 100.63873291015625\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 4,  5, 10])\n","Step: 9236, Train Loss: 99.42916870117188\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 1,  4,  5, 10, 11, 12]), tensor([ 1,  2,  4,  5, 10, 11, 12])\n","Step: 9237, Train Loss: 98.8468246459961\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9238, Train Loss: 103.3359146118164\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11, 12])\n","Step: 9239, Train Loss: 113.0480728149414\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9240, Train Loss: 105.38981628417969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  4,  6,  8, 10, 12])\n","Step: 9241, Train Loss: 94.08268737792969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 12])\n","Step: 9242, Train Loss: 109.3613052368164\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  9, 10, 11]), tensor([10])\n","Step: 9243, Train Loss: 94.9951171875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9244, Train Loss: 101.62298583984375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 12])\n","Step: 9245, Train Loss: 103.66202545166016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 1,  2, 11, 12])\n","Step: 9246, Train Loss: 104.9671401977539\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2, 11]), tensor([ 1,  2,  4,  5, 11, 12])\n","Step: 9247, Train Loss: 82.38536071777344\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([1, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([2]), tensor([0, 2])\n","Step: 9248, Train Loss: 97.11754608154297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  7, 10, 11, 12])\n","Step: 9249, Train Loss: 114.5615463256836\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 2,  4, 10, 12])\n","Step: 9250, Train Loss: 101.02703094482422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 9251, Train Loss: 105.61807250976562\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8,  9, 10, 11]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9252, Train Loss: 110.10858917236328\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9253, Train Loss: 96.99535369873047\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 12]), tensor([5])\n","Step: 9254, Train Loss: 96.3948974609375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11])\n","Step: 9255, Train Loss: 104.67608642578125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  7, 11, 12])\n","Step: 9256, Train Loss: 101.2793197631836\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12]), tensor([ 2, 10, 11, 12])\n","Step: 9257, Train Loss: 108.35392761230469\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9258, Train Loss: 99.95872497558594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  4,  5,  9, 10])\n","Step: 9259, Train Loss: 103.12969970703125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 10, 12]), tensor([0, 1, 3, 4, 7, 9])\n","Step: 9260, Train Loss: 99.03893280029297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9261, Train Loss: 104.37814331054688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  4,  5, 10])\n","Step: 9262, Train Loss: 105.73214721679688\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5, 10, 11, 12]), tensor([ 2,  5, 10, 12])\n","Step: 9263, Train Loss: 106.96621704101562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([1, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 11]), tensor([2])\n","Step: 9264, Train Loss: 104.84835815429688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  2,  5,  8, 10, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n","Step: 9265, Train Loss: 92.30146789550781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9266, Train Loss: 101.32755279541016\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  4,  5, 10, 11, 12])\n","Step: 9267, Train Loss: 105.12992858886719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 4,  5, 10, 12])\n","Step: 9268, Train Loss: 99.42444610595703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5,  8, 10, 12]), tensor([ 0,  2,  4,  5,  6,  8, 10, 12])\n","Step: 9269, Train Loss: 99.32806396484375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9270, Train Loss: 102.77952575683594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2, 10, 11, 12])\n","Step: 9271, Train Loss: 101.1678237915039\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  4, 10, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9272, Train Loss: 108.86766052246094\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  4,  5, 10, 11, 12])\n","Step: 9273, Train Loss: 103.54409790039062\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  6,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9274, Train Loss: 111.446044921875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  4,  5, 10, 11]), tensor([ 1,  2,  5, 10, 12])\n","Step: 9275, Train Loss: 106.12252044677734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11])\n","Step: 9276, Train Loss: 107.56158447265625\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 9277, Train Loss: 98.50890350341797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 12]), tensor([ 0,  1,  2,  4,  8,  9, 12])\n","Step: 9278, Train Loss: 103.2424087524414\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9279, Train Loss: 108.43113708496094\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 0,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9280, Train Loss: 105.35868072509766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 5, 10, 12]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9281, Train Loss: 103.33631134033203\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9282, Train Loss: 107.72483825683594\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2, 10]), tensor([ 2,  5, 10])\n","Step: 9283, Train Loss: 95.14192962646484\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9284, Train Loss: 102.50460815429688\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9285, Train Loss: 109.60871887207031\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 11]), tensor([ 0,  1,  2,  3,  4,  7, 12])\n","Step: 9286, Train Loss: 103.90013122558594\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 12])\n","Step: 9287, Train Loss: 109.03946685791016\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  4,  5,  8, 10, 11, 12]), tensor([ 2,  4,  5, 10, 11, 12])\n","Step: 9288, Train Loss: 99.46687316894531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9289, Train Loss: 105.1844482421875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 12])\n","Step: 9290, Train Loss: 102.78636932373047\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9291, Train Loss: 106.4530029296875\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9292, Train Loss: 105.36343383789062\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11])\n","Step: 9293, Train Loss: 103.14717102050781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9294, Train Loss: 102.3568115234375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12])\n","Step: 9295, Train Loss: 93.12844848632812\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9296, Train Loss: 92.81383514404297\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9297, Train Loss: 99.86592102050781\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([2, 4]), tensor([ 0,  2,  3,  4,  7, 10, 11])\n","Step: 9298, Train Loss: 102.68666076660156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  3,  4,  5,  7,  9, 10, 11]), tensor([ 3,  4,  5,  7, 10, 11])\n","Step: 9299, Train Loss: 110.80560302734375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9300, Train Loss: 105.68618774414062\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  8, 10, 11])\n","Step: 9301, Train Loss: 114.88734436035156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 1,  2,  3,  4,  5,  7,  8, 10, 11])\n","Step: 9302, Train Loss: 112.60560607910156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 2,  3,  4,  7,  9, 11])\n","Step: 9303, Train Loss: 112.63169860839844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5, 10, 11])\n","Step: 9304, Train Loss: 106.17240142822266\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9305, Train Loss: 103.20197296142578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12]), tensor([ 2,  5, 10, 12])\n","Step: 9306, Train Loss: 111.94461822509766\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9307, Train Loss: 103.93358612060547\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([0, 1, 2, 6]), tensor([0, 1, 2, 6])\n","Step: 9308, Train Loss: 93.7841796875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 3,  4,  5,  7, 10, 11, 12])\n","Step: 9309, Train Loss: 100.67140197753906\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  3,  4,  7, 10, 11, 12])\n","Step: 9310, Train Loss: 111.16586303710938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9311, Train Loss: 103.08805847167969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4, 11, 12]), tensor([ 0,  1,  2,  4,  5,  6,  8, 10, 12])\n","Step: 9312, Train Loss: 105.51116180419922\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9313, Train Loss: 101.06871032714844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9314, Train Loss: 104.57218170166016\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  3,  5,  7, 10, 11, 12]), tensor([ 2, 10, 11, 12])\n","Step: 9315, Train Loss: 101.38516235351562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  3,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9316, Train Loss: 110.13301086425781\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9317, Train Loss: 108.24324035644531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11])\n","Step: 9318, Train Loss: 102.0946044921875\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 4,  5, 10]), tensor([ 4, 10, 11, 12])\n","Step: 9319, Train Loss: 103.56031799316406\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 9320, Train Loss: 104.57266235351562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7, 11]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9321, Train Loss: 105.64895629882812\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([2, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 5, 10]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9322, Train Loss: 99.13365173339844\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 2,  3,  4,  7,  8, 10, 11, 12])\n","Step: 9323, Train Loss: 107.94054412841797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9324, Train Loss: 108.62712097167969\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 4,  5, 10])\n","Step: 9325, Train Loss: 110.13862609863281\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9326, Train Loss: 108.31414031982422\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  5, 10, 12])\n","Step: 9327, Train Loss: 103.86627960205078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8, 10, 11])\n","Step: 9328, Train Loss: 100.46127319335938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9329, Train Loss: 99.59353637695312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  4, 10]), tensor([ 0,  1,  2,  3,  4,  5, 10, 11, 12])\n","Step: 9330, Train Loss: 90.43376922607422\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9331, Train Loss: 101.86710357666016\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9332, Train Loss: 108.27191162109375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 4,  5, 10, 12]), tensor([ 4,  5, 10, 11, 12])\n","Step: 9333, Train Loss: 104.92933654785156\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  2,  3,  7,  9, 10, 11])\n","Step: 9334, Train Loss: 109.6407470703125\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9335, Train Loss: 108.51210021972656\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9336, Train Loss: 99.20527648925781\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9337, Train Loss: 99.43512725830078\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9338, Train Loss: 106.1331787109375\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  7,  9, 10, 11, 12])\n","Step: 9339, Train Loss: 106.23176574707031\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([6, 512, 512])\n","class_labels: tensor([ 1,  2, 10, 11, 12]), tensor([ 3,  5,  7, 10, 11, 12])\n","Step: 9340, Train Loss: 112.29358673095703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([6, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 1,  2,  4, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7,  8, 10, 11, 12])\n","Step: 9341, Train Loss: 98.22864532470703\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9342, Train Loss: 92.40068054199219\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9343, Train Loss: 97.57862854003906\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 11, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7, 11, 12])\n","Step: 9344, Train Loss: 103.35765075683594\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 0,  1,  2,  4,  5,  8, 10, 12])\n","Step: 9345, Train Loss: 106.50822448730469\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), tensor([ 0,  1,  3,  4,  7, 10, 11, 12])\n","Step: 9346, Train Loss: 106.2529525756836\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  5,  7, 10, 11, 12]), tensor([ 0,  3,  7, 11])\n","Step: 9347, Train Loss: 109.0649642944336\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8, 10, 11, 12]), tensor([ 2,  4,  8, 10, 12])\n","Step: 9348, Train Loss: 108.90360260009766\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5, 10, 11, 12])\n","Step: 9349, Train Loss: 106.1856460571289\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12])\n","Step: 9350, Train Loss: 108.04450988769531\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  9, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9351, Train Loss: 100.17655181884766\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 4,  5, 10])\n","Step: 9352, Train Loss: 99.77037811279297\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  5,  7, 10, 11, 12]), tensor([ 0,  1,  2,  3,  7, 10, 11, 12])\n","Step: 9353, Train Loss: 106.88312530517578\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 12])\n","Step: 9354, Train Loss: 112.09185028076172\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([ 2,  3,  4,  7, 10, 11, 12])\n","Step: 9355, Train Loss: 95.91055297851562\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([3, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  7, 10, 11, 12]), tensor([2, 4, 5])\n","Step: 9356, Train Loss: 106.13519287109375\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9357, Train Loss: 110.40132904052734\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([7, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11]), tensor([ 2,  3,  4,  5,  7, 10, 11])\n","Step: 9358, Train Loss: 109.5354232788086\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","Step: 9359, Train Loss: 104.07661437988281\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9360, Train Loss: 113.2322769165039\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7, 10, 11, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9361, Train Loss: 103.9874038696289\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9362, Train Loss: 103.67546081542969\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([2, 512, 512])\n","class_labels: tensor([ 5, 10, 12]), tensor([ 4, 10])\n","Step: 9363, Train Loss: 99.1719970703125\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 12])\n","Step: 9364, Train Loss: 98.93728637695312\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  5,  8, 10, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9365, Train Loss: 97.6015396118164\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([7, 512, 512]), torch.Size([4, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  8, 10, 12]), tensor([ 2,  4,  5, 10])\n","Step: 9366, Train Loss: 99.86192321777344\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([11, 512, 512]), torch.Size([11, 512, 512])\n","class_labels: tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), tensor([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9367, Train Loss: 92.81283569335938\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9368, Train Loss: 101.84143829345703\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  7,  8, 10, 12])\n","Step: 9369, Train Loss: 100.72078704833984\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([9, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 0,  2,  3,  5,  8,  9, 10, 11, 12])\n","Step: 9370, Train Loss: 89.22209167480469\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([3, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 2,  5, 10]), tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9371, Train Loss: 95.61634826660156\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  5,  7, 10, 11]), tensor([ 1,  2,  3,  4,  7, 10, 11, 12])\n","Step: 9372, Train Loss: 97.74858093261719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([5, 512, 512]), torch.Size([5, 512, 512])\n","class_labels: tensor([ 2,  4,  5, 10, 12]), tensor([ 2,  4,  5, 10, 12])\n","Step: 9373, Train Loss: 100.51124572753906\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 2,  3,  4,  5,  7,  9, 10, 11])\n","Step: 9374, Train Loss: 111.98314666748047\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([8, 512, 512]), torch.Size([12, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  4,  6,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12])\n","Step: 9375, Train Loss: 100.86241912841797\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([12, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9376, Train Loss: 102.49613189697266\n","[WARN]: Patch List is empty...\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([4, 512, 512]), torch.Size([8, 512, 512])\n","class_labels: tensor([ 2,  3,  7, 11]), tensor([ 2,  3,  4,  5,  7, 10, 11, 12])\n","Step: 9377, Train Loss: 104.09916687011719\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([9, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 1,  2,  3,  4,  5,  6,  7, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11])\n","Step: 9378, Train Loss: 101.15048217773438\n","dict_keys(['pixel_values', 'pixel_mask', 'mask_labels', 'class_labels', 'original_images', 'original_segmentation_maps'])\n","pixel_values: torch.Size([4, 3, 512, 512])\n","mask_labels: torch.Size([10, 512, 512]), torch.Size([10, 512, 512])\n","class_labels: tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 12]), tensor([ 0,  1,  2,  3,  4,  6,  7,  8, 10, 12])\n","Step: 9379, Train Loss: 98.6959457397461\n"]}]},{"cell_type":"code","source":["print(guyyyhjkuijklh)\n","ik"],"metadata":{"id":"Jmr7o1vRKCha","executionInfo":{"status":"aborted","timestamp":1709719957354,"user_tz":-60,"elapsed":3,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation,  AutoConfig\n","import torch.nn.functional as F\n","from torch import nn\n","import gc\n","from torch.cuda.amp import GradScaler, autocast\n","\n","\n","# id2label\n","id2label, label2id, labels = get_modified_labels()\n","# model and processor\n","model_ckpt = \"facebook/mask2former-swin-tiny-cityscapes-semantic\"\n","model_config = AutoConfig.from_pretrained(model_ckpt, id2label=id2label, label2id=label2id, num_labels=len(id2label))\n","model = AutoModelForUniversalSegmentation.from_pretrained(model_ckpt, ignore_mismatched_sizes=True, config=model_config)\n","\n","# # Freeze the model backbone params\n","# for name, params in model.named_parameters():\n","#     if name.startswith(\"model.pixel_level_module\"):\n","#         params.requires_grad = False\n","\n","processor = AutoImageProcessor.from_pretrained(model_ckpt, ignore_index=255, do_reduce_labels=False)\n","#default - \"do_normalize\": true, \"do_rescale\": true, \"do_resize\": true, \"ignore_index\": 255, \"reduce_labels\": false,\n","processor.num_labels = len(id2label)\n","\n","#dataset\n","mydataset = load_railsem_dataset()\n","total_size = len(mydataset[\"data\"])\n","print(f\"[INFO]: Total images: {total_size}\")\n","train_size = 8160\n","train_percentage = train_size / total_size\n","# Use train_test_split with specified percentages\n","splits = mydataset[\"data\"].train_test_split(train_size=train_percentage, shuffle=True)\n","train_split = splits[\"train\"]\n","val_split = splits[\"test\"].select(indices=(range(320))) #320\n","test_split = splits[\"test\"].select(indices=(range(20)))\n","print(f\"[INFO]: Total Training images: {len(train_split)}\")\n","print(f\"[INFO]: Total Validation images: {len(val_split)}\")\n","print(f\"[INFO]: Total Test images: {len(test_split)}\")\n","\n","# transforms\n","transforms = get_transforms()\n","# customdataset = CustomDataset(train_split.select(range(0, 6)), transforms)\n","customdataset = CustomDataset(train_split, transforms)\n","\n","# patch_size = [512, 512]\n","# train_queue = PatchQueue(customdataset, max_length=10, samples_per_image=5, patch_size=patch_size)\n","dataloader = _prepare_dataloader(customdataset) #train_queue\n","\n","# print(customdataset[0].keys(), customdataset[0][\"image\"].shape, customdataset[0][\"mask\"].shape)\n","# batch = next(iter(dataloader))\n","# for k,v in batch.items():\n","#   if isinstance(v, torch.Tensor):\n","#     print(k,v.shape)\n","#   else:\n","#     print(k,v[0].shape)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","if torch.cuda.is_available():\n","    torch.cuda.reset_max_memory_allocated()\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","optimizer = AdamW(params=model.parameters(), lr=1e-4)\n","scaler = GradScaler()\n","epochs = 2\n","\n","model.to(device)\n","model.train()\n","for i in range(epochs):\n","    print(f\"------------Epoch: {i}-----------------\")\n","    running_train_loss = 0.0\n","    for step, batch in enumerate(dataloader):\n","        print(batch.keys())\n","        batch_dict = {\n","                \"pixel_values\": batch[\"pixel_values\"].to(device),\n","                \"mask_labels\": [labels.to(device)\n","                                for labels in batch[\"mask_labels\"]],\n","                \"class_labels\": [labels.to(device)\n","                                    for labels in batch[\"class_labels\"]],\n","                \"pixel_mask\": batch[\"pixel_mask\"].to(device),}\n","        # with torch.autocast(device_type='cuda', dtype=torch.float16):\n","        with autocast():\n","            # print(f'mask_labels: {batch[\"mask_labels\"][0].shape}, {batch[\"mask_labels\"][1].shape}') # mask_labels: torch.Size([8, 384, 384]), torch.Size([11, 384, 384])\n","            # print(f'class_labels: {batch[\"class_labels\"][0]}, {batch[\"class_labels\"][1]}') # class_labels: tensor([ 2,  3,  4,  5,  7,  9, 10, 11]), tensor([ 0,  1,  2,  3,  4,  5,  7,  9, 10, 11, 12])\n","            outputs = model(**batch_dict)\n","            train_loss = outputs.loss\n","        # print(outputs.keys()) # odict_keys(['loss', 'class_queries_logits', 'masks_queries_logits', 'encoder_last_hidden_state', 'pixel_decoder_last_hidden_state', 'transformer_decoder_last_hidden_state'])\n","        print(f\"Step: {step}, Train Loss: {train_loss.item()}\")\n","        batch_size = batch[\"pixel_values\"].size(0)\n","        running_train_loss += train_loss.item() * batch_size\n","\n","        scaler.scale(train_loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        del batch, outputs\n","    running_train_loss = torch.tensor([running_train_loss], device=device)\n","    train_epoch_loss = running_train_loss.item() / len(customdataset)\n","    print(f\"Epoch: {i}, Train Loss: {train_epoch_loss}\")\n",""],"metadata":{"id":"Up8-vxcaqMwN","executionInfo":{"status":"aborted","timestamp":1709719957355,"user_tz":-60,"elapsed":4,"user":{"displayName":"Bhavana Malla","userId":"13569433150164017713"}}},"execution_count":null,"outputs":[]}]}